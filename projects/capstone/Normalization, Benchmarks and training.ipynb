{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "# import the relevant Keras modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "import keras\n",
    "print (keras.__version__)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [12, 8] # width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration \n",
    "\n",
    "# Data sources\n",
    "include_bitcoin = 1\n",
    "include_ethereum = 1\n",
    "include_litecoin = 1\n",
    "include_ripple = 1\n",
    "include_goog_trends = 1\n",
    "include_stocktwits = 0\n",
    "\n",
    "# Data duration (training + test)\n",
    "start_date_ = '2015-08-07'\n",
    "end_date_ = '2018-04-18'\n",
    "\n",
    "start_date = start_date_.replace(\"-\", \"\")\n",
    "end_date = end_date_.replace(\"-\", \"\")\n",
    "\n",
    "split_date = '2018-01-20'  # >10% of full dataset\n",
    "\n",
    "# Target : Predict bitcoin (OR ethereum) daily returns OR volatility \n",
    "# target = 'btc_daily_ret'\n",
    "target = 'btc_volatility'\n",
    "\n",
    "# target = 'eth_daily_ret'\n",
    "# target = 'eth_volatility'\n",
    "\n",
    "# Explore further\n",
    "# target = 'ltc_daily_ret'\n",
    "# target = 'xrp_daily_ret'\n",
    "\n",
    "coins = ['bitcoin', 'ethereum', 'litecoin', 'ripple']\n",
    "coin_symbol = {'bitcoin': 'btc', 'ethereum': 'eth', 'litecoin': 'ltc', 'ripple': 'xrp'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_df = pd.read_pickle(\"data/full_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>btc_Close</th>\n",
       "      <th>btc_Volume</th>\n",
       "      <th>eth_Close</th>\n",
       "      <th>eth_Volume</th>\n",
       "      <th>ltc_Close</th>\n",
       "      <th>ltc_Volume</th>\n",
       "      <th>xrp_Close</th>\n",
       "      <th>xrp_Volume</th>\n",
       "      <th>btc_close_off_high</th>\n",
       "      <th>...</th>\n",
       "      <th>ltc_30day_ret</th>\n",
       "      <th>xrp_close_off_high</th>\n",
       "      <th>xrp_volatility</th>\n",
       "      <th>xrp_daily_ret</th>\n",
       "      <th>xrp_7day_ret</th>\n",
       "      <th>xrp_30day_ret</th>\n",
       "      <th>btc_trends</th>\n",
       "      <th>eth_trends</th>\n",
       "      <th>ltc_trends</th>\n",
       "      <th>xrp_trends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>279.58</td>\n",
       "      <td>42484800</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>164329</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4192810</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>363643</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.020449</td>\n",
       "      <td>0.016459</td>\n",
       "      <td>0.016459</td>\n",
       "      <td>0.016459</td>\n",
       "      <td>29.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>261.00</td>\n",
       "      <td>58533000</td>\n",
       "      <td>0.753325</td>\n",
       "      <td>674188</td>\n",
       "      <td>3.85</td>\n",
       "      <td>4917730</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>678295</td>\n",
       "      <td>-0.969823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087678</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.066634</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-09</td>\n",
       "      <td>265.08</td>\n",
       "      <td>23789600</td>\n",
       "      <td>0.701897</td>\n",
       "      <td>532170</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3064680</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>531969</td>\n",
       "      <td>0.411945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.041372</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>30.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>264.47</td>\n",
       "      <td>20979400</td>\n",
       "      <td>0.708448</td>\n",
       "      <td>405283</td>\n",
       "      <td>3.95</td>\n",
       "      <td>2239890</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>472973</td>\n",
       "      <td>-0.155756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>-0.949686</td>\n",
       "      <td>0.018044</td>\n",
       "      <td>-0.007036</td>\n",
       "      <td>-0.007036</td>\n",
       "      <td>-0.007036</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-11</td>\n",
       "      <td>270.39</td>\n",
       "      <td>25433900</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>1463100</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3426300</td>\n",
       "      <td>0.008591</td>\n",
       "      <td>282461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053165</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.019998</td>\n",
       "      <td>-0.018284</td>\n",
       "      <td>-0.018284</td>\n",
       "      <td>-0.018284</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  btc_Close  btc_Volume  eth_Close  eth_Volume  ltc_Close  \\\n",
       "0 2015-08-07     279.58    42484800   2.770000      164329       4.21   \n",
       "1 2015-08-08     261.00    58533000   0.753325      674188       3.85   \n",
       "2 2015-08-09     265.08    23789600   0.701897      532170       3.90   \n",
       "3 2015-08-10     264.47    20979400   0.708448      405283       3.95   \n",
       "4 2015-08-11     270.39    25433900   1.070000     1463100       4.16   \n",
       "\n",
       "   ltc_Volume  xrp_Close  xrp_Volume  btc_close_off_high     ...      \\\n",
       "0     4192810   0.008152      363643            0.597015     ...       \n",
       "1     4917730   0.008476      678295           -0.969823     ...       \n",
       "2     3064680   0.008808      531969            0.411945     ...       \n",
       "3     2239890   0.008750      472973           -0.155756     ...       \n",
       "4     3426300   0.008591      282461            1.000000     ...       \n",
       "\n",
       "   ltc_30day_ret  xrp_close_off_high  xrp_volatility  xrp_daily_ret  \\\n",
       "0       0.036946            0.987805        0.020449       0.016459   \n",
       "1      -0.087678            0.147059        0.066634       0.038217   \n",
       "2       0.015625            0.914530        0.041372       0.038190   \n",
       "3       0.012821           -0.949686        0.018044      -0.007036   \n",
       "4       0.053165           -1.000000        0.019998      -0.018284   \n",
       "\n",
       "   xrp_7day_ret  xrp_30day_ret  btc_trends  eth_trends  ltc_trends  xrp_trends  \n",
       "0      0.016459       0.016459        29.0        62.0        69.0        78.0  \n",
       "1      0.038217       0.038217        33.0        35.0        42.0        64.0  \n",
       "2      0.038190       0.038190        30.0        42.0        45.0        70.0  \n",
       "3     -0.007036      -0.007036        32.0        38.0        45.0        67.0  \n",
       "4     -0.018284      -0.018284        29.0        40.0        48.0        59.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsvXd4XNWZ+P+ZGXVZli03ucr9uAtjG2wwSSimGBxIsuG3CaRASIIJKbvZ7CZL9km+m91NNrubkB5CICGBBAIBDMRgjDFgGRe5Vx1Jlqzee9e03x9TdGfmzsyd0YxG5Xyex481t5137tx73vOW8x6T0+lEoVAoFIrRhjnRAigUCoVCoYdSUAqFQqEYlSgFpVAoFIpRiVJQCoVCoRiVKAWlUCgUilGJUlAKhUKhGJUoBaVQKBSKUUmS0QOFEHmAAOyAlFJWx00qhUKhUEx4TOEm6gohbge+BywBygErkAeUAt+TUr4ebyEVCoVCMfEIqaCEEI8BFuBxKeURv32bgIcAh5Tyc3GVUqFQKBQTjnAK6kop5YlQFzByjEKhUCgUkRLWxeePEGKqlLItTvIoFAqFQgGEt6C+DfRKKX8khJgG7AHygTrg76SUR0dGTIVCoVBMNIKmmbuTI+4C/ube9C3gGJAKfAH4ZdylUygUCsWEJagFJYQ4AfQDRYAJuBU4ATS4P98JvCylvH9kRFUoFArFRCLUPKgngRlSyu8IIVYBm6SUtwMIIXKADynlpFAoFIp4EUpBPQscFUJ8EFgFfBVACPER4EfAM/EXT6FQKBQTlXBJEtnA9UCNlLLQve0aIFdK+eLIiKhQKBSKiUg4BXWTlPKtUBcQQtwspXwz5pIpFAqFYkITrhbfTUKIh4HfAG9KKW0AQogUXJbVl3ElUSgFpVAoFIqYYqQW39XAd4GtuOY/mYFZwAFctfgOxVnGkAghUoFNbtnsiZRFoVAoFBFjAWYDhVLKAe0Ow5Uk3PGopYATuCSl7Ii1lNEghNiKS1kqFAqFYuxynZSyQLvB8HIbboV0POYiDZ86gGeeeYbc3NxEy6JQKBSKCKivr+eee+4Bd1+uxbCCGsXYAXJzc5k3b16iZVEoFApFdASEaNSKugqFQjEKOPvuZUqP1yZajFFFxApKCJEihFgQD2EUCoViolJ2sp7zByoTLcaowpCCEkJ8RAjxMyFEFlAMnBZCfDW+oikUCoVxHA4nvZ0D4Q8chUS67NFEwagF9S1cc6E+BhwCFgCfipdQCl+++c1vIoQI+u/FFyMr6lFdXY0QgoqKirDHHjlyBCEENpstWvEVihHh6KuSvU+epKu1L9GiRIzToRSUHkaTJExSyrNCiH8BXpdSdgkhVPxqhHjkkUf4+te/DsCxY8f42te+RkHBUDZmVlZWRNebPXs2BQUF5OTkhD12/fr1FBQUkJQ0HvJpFOOZhvJ2ADqbesjKSU+wNJFhtzkSLcKoxGiv4xBC3A3cAvyTEGI7oO7oCJGVleVVQtnZ2QDMmDEj6utZLBbD56ekpAyrLYVCER6HXVlQehi1gr6Oa5HCR6SU9cAjuKubKxLPz372Mx588EE+9alPsWnTJt577z0aGxv5yle+wqZNm1izZg133XUXhYWFQKCLTwjByy+/zI4dO1i/fj2f+tSnqKx0BWu1Lj7PeXv27GHbtm1s2LCBBx98kNbWVq8sBQUF7Nixg3Xr1vHAAw/wve99j29+85sjf1MUijGEsqD0MWRBuWf33qT5fG3cJEoA5w9UUFPcMqJtzl0+jdXX5cXsevv37+ff/u3feOSRR5g3bx4PP/wwGRkZPPvsszidTv73f/+X73znO+zevVv3/J///Od873vfY9KkSfzzP/8zP/rRj3j00Ud1j33sscf43//9XwYHB/nqV7/KE088wTe+8Q2qqqrYuXMnX/ziF9m+fTuvvvoqv/rVr7jrrrti9j0VivGIw64UlB6GFJQQYgvwX0AOrtV0AZBSrouTXIoImTJlCvfee6/38/XXX8/NN9/M7NmzAbjnnnt44IEHgmYLfeYzn2HLli0AfOITn+Cpp54K2tbDDz9Mfn4+ADt27ODs2bMAPP/886xevZqHH34YgK9+9ascOpTQUo2KiYjJFP6YUYayoPQxGoN6DPg9riXfh+UsdSdX/BLIBwaAB6SUpZr9/wD8vfvjbinl/xtOe0ZYfV1eTK2ZRDB37lyfz5/4xCfYvXs3J06coLy8nHPnzgFgt+vX012wYGhq26RJk0Jm7QU7VkrJmjVrfI7Nz8+no2NUlG1UKEYtKgalj1EFZZNS/ihGbd4FpEkptwghNgP/B9wJIIRYDNwDXI1LER4QQrwkpTwTo7bHLampqd6/HQ4H999/Px0dHWzfvp0bbrgBq9XqtWz0SE5O9vkcal5GsGMtFkvAsWp+h0IRHmVB6WM0SeKcEGJtjNrcCrwBIKU8DGzU7KsCbpVS2qWUDiAZ6I9RuxOG0tJSCgsLeeKJJ9i5cycf+tCHaGxsBOKrMJYtW+a11DycP38+bu0pFOMFFYPSx6gFtRg4LoSoALyz4KKMQU0GtD4fuxAiSUppk1JagWYhhAn4H+CklLI4ijYmNJMnT8ZsNrN79262bdvG2bNn+dnPfgbA4OBg3Nq9++67eeKJJ/j1r3/NLbfcwptvvsmxY8d8XIIKhSIQh5qoq4tRC+rfgW3AA7hW0fX8i4ZOQDuz1OxZqRdACJEGPOM+5qEo25jQ5Obm8t3vfpff/e533H777Tz22GN8+9vfJjk5mYsXL8at3blz5/LTn/6Ul156iR07dnDixAluuummAJegQqHwRVWS0MfQgoVCiFNSyiti0aAQ4mPADinlZ90xqO9IKW9z7zPhcv+9LaX8b4PXWwiU79u3Ty23kWCKi4ux2WysWrXKu+0LX/gCa9eu5ctfjnY8o1AYY9ejhwHYuH0Zc5dPS7A0kVFX2srR11zOoju/tjnB0ows1dXV3HjjjQCLpJSXtfuMWlA9QohY9f4vAf1CiPeBHwP/IIT4RyHEh3ElUHwQuE0I8Y7735YYtauIM5WVlXz2s5/l4MGD1NTU8Pzzz3Po0CG2bduWaNEUE4gxmGWukomCYDQGlQmUCyGqgG7PxmhiUO7khwf9Nhdp/k6L9JqK0cFNN91ESUkJjzzyCC0tLSxatIgf//jHrFixItGiKRSjGqWf9DGqoFRZI4Uhdu7cyc6dOxMthkIxplAWlD5GFdTZuEqhUCgUExmln3QxqqCacd1CE0O3sg5QWQkKhSLhjHULZKzLHy+MFov1JlMIIVKATwIiXkIpFApFJBzbXRLza7bUdDJ5egbJqfFfCy2cfnI6nZjGYvbHMIl40UEp5aCU8ve45kUpFApFwqktaQ1/UAS01nVR8PwF3n8xfvMGtYSyoKqLmnnlJ0fG5ErBw8VoNXPt0qsmXOWJpsZFIoVCoUgw3W2uCmvtDT0j02AIC+rk3ksAVJ5vHPNFrSMlmhgUQCMqs0+hUIxTRtqbNtYqSZyvaWLm5ExmZGXEtR2jCirJPX/JixBCWVAjxDe/+U1eeumloPu///3v89GPfjSqa3d3d7N3714+8pGPRCueQjHu0MZ7zuwvZ931i3SP627vJyXVQkr68Mp5GUqSGCUxqK7+AfZeKAPga9uujmtbRmNQx3S2HYilIIrgPPLIIxQUFFBQUOBd5dbzuaCggO3bt0d97d/+9re8+OKLsRJVoUg8fh15Z0svNqv+OmhGKD/doLvd6XSy7/eneP2x41Ffe+haxo5z2B3s+e0Jig5VDbvNaLGOYOX1kBaUEGIfsAnIEEJ0anZZgMJ4CqYYIisri6wsV33d7OxsAGbMmBGTa4/G9FZ5pJqejgGuvHlJokVRjHF62vvZ/8czZM/M5EOfNL5ikCFjJYavjtH3sKdjgP7uQeSRGlZsmR87ASJhBLuMcBbUR4B1wHvAWs2/5cAN8RVtfGMdsHH89RLaG7rDH2yAPXv2sH37dvLz8/noRz/KwYMHvfsuXrzIJz7xCfLz89m6dSv//d//jd1u5/nnn+fXv/41R48e9SnwmmiKDlVTdaEp0WIoxgE97a5kh47GCJMdDGiomC6REeJSHt1lYnQOKONJSAtKStmJa3mMG9zFYtcBe4C5/jGpscyB4kqKG1pGtM2pg0lYZA+dLX1cf280y2oNce7cOb71rW/x3e9+l/z8fAoKCti5cycvvPACy5cv5+tf/zpXrt/AD3/4Q2pra/nKV77C4sWL2bFjByUlJZw5c4af//znMfpmipFmos6RMUK0HbqR2xlLZWEsBhV8V7/VRpLZTJIl4plDEeMcQRPK0LcRQmwH3gd+AcwELggh7oynYOOdgV4rAEkpgcukR8qTTz7J3XffzYc//GHy8vK45557uOWWW3j66acBqKqsprW8n1kzcrn66qt54oknuOaaa0hLSyM9PZ3k5GSmT58+bDniSWtdF+Wn6xMtxqhDHqnmlZ8cYbDfFv5ghXEMaKhIMu+cDieHdxVxfE+p7uq5w9V1zxw+y+tnS4Pub+vp460L5QzYxtZzYjSL7zvA1cBuKWWdEGIr8BSwK26SjSDXLV/AdctHdtXX9547RxuDWJKGP+K5dOkSb775Js8995x3m9VqZf369QDcdvXHeaXgGa774AE++MEPcPvtt7NmzZphtxtvtJbBgedcS8ef2X+Zaz+2kunzsxMp2qih6FA1AG313cxaOCXB0owSNL19PMf6kSiV9sYeGsrbAZg8LYNlG+f4Xkuj7CrPN5KR7VrUYfq8yd7tnc297P/jGd3r9w5a6fFbLdtqt/Pa6RKuzMtl95lSBmx20pOTuHbZ8GJXI+lkNKqgLG7FBICU8pQQYmI5Q2NNDO+e3W7n85//PHfddZfP9tTUVACuXbuNVQvXY5vVyPuHC3jwwQf58pe/zEMPje4Fi51O/YHsmXcuc8On8kdeoFGMyey6UU6nk8oLTcxckE16VmqCpUoMPoojyvfMUI5ElDGo1tquwGtp/j65t8z7t3bxQo+C08OEKUBhljS0UtHSQUVLh3dbz6A1coH9ZR3BOJjR4XuvEGIB7vsohLgO6I+bVApdrIN2ys8EprwuWrSI6upq8vLyvP9efPFF9u3bR19fH7sKnsZstvDJv7+HJ598koceeojXX38dYFTHLsba5MVE4vkZm6o6ObW3jPfcFueERGtBRduZGngtIkqS0FzPbtMJ3w/zWTeZjH3XC7VN9FuH5+YbydfSqIL6JvAmsEQIcQjXqrj/EjepFLqUFNZQVxpYc+yzn/0su3fv5qmnnqKyspJnnnmGxx9/nAULFpCenk5ZbRG7DjxNWXkZRUVFFBQUsHr1agAyMjJobGykurp6pL9OWIIpqNGsVBOF2W1B9XcP+vw/EXEG+dBU1UGfwfti5BmLZAClvZptMHBO1nCtEpPJFGAsBvsOR8pqdLfXtHXR0t0bti3HKLSgLgGbgb8H/hNYIaV8N25STQA8D6TnGWq83M5AX2jze7BPf+SzYcMGfvCDH/Dss8+yfft2/vjHP/KDH/yA6667DoB7b36YQVs/n7nvXu69917y8vL413/9VwBuvfVWHA4Ht99+O+3twV0IiWCipdQOB09nFO97ZrPa6esaiPi89sYe3v3zWbrbR8Dx4tT9k/f/epE3nzhh7Bp+fbvD4eTQy0VUFTUPXTuSe61RFv4WVFdrH/09Id59A+2YdA4LpmJtQSbaPn/sAn88FH7pv5F8L43GoN6VUq4AXo+nMBOVtvpuDr1cRObUNG76zBWAy09duLuEzXcKsmdkAq4HY9m81fz0G38OuMaOHTvYsWOH7vVnTMnlgTu+wY2fvYJJU9J89i1YsIC9e/fG+BtFj/bhD25BjZQ0YwjPPYlz3/H2H07T1zXI7V/aRFKy8QzUE3tK6Wrp40JBJVfdsTyOEvpbUM4QO4Pj/4h1NPbQeLmdxsvtzF/hyngNZUH5p/5rn1ltVQun08nbfzhtTKhQ8ppMAenfwSwokwkGbDYu1Dazes4MUpIiyySO6fyvMBi1oCqEENcIIeKfZD8B8YxIe9qGRpen3y6nv3uQokPVtNV3s+vRwzRWdAS7hA8DvVbdl2csxHS0MgZ9ESawhhrotepO7jabR8aC6utyucj03FSRECwt/tjrJRzeVTSsa/vGoKK7hH/n3t0WuNRFsGv3dQ3wyk+OcFknXgxDz3hjZYehJTSMfIVILCiTycSB4irelRUcLI28ZNJIuviMWlArgQLAKoQYwH0/pJSTQ5+mCIcrUy10h1t81OUzNhJXGOi18sZvjjNjQTbXfHSlT8xqLLjMtEopmLgmE9SXtVF5vpGN25dhHoHJiaOFvb87id3qYPvOjfoL6cXhJ7YO2Cg6VM3U3EnDv5jTSU1xC8d2l5AzJ4ukZDNX7RDe6RY10jVhvq9rIOosRO1zozcoqzjXSN6amaEv4vdKnthzKbCdIAOoukttgGuQuXDdrACZTCYTdpuDQ0bXmjJYR9b//Q7WrZyuamDeVFfptOauXrd8xh+c0aigrourFKOUgV4rSSmWmMxVCobT4fSmCPts96lv4rsvlD7zlHZpquxgsN/G0deKfdoa7TjtQzLKw9X0dw+y+a4VAccdeUUC0FrX7TNXZLxjt7riB3abg2RN/+15XOLxC5995zJVF5t9thl9lpxOZ8Cx1dJ1LU+6ddXFJhauneVzTH+PlfSsVNrqu7H225gZyRwvZ2gr/NRbZeEVlIGv5/QZTIWu5uF/D+zDKF6rhwmdJIkQqYhmt6yeibuRKJ1RF4OSUlbEW5DRht3m4I3fHGfS1DRudMeFYonngXU4nCEVjslkivqB8J+xrr1MS20XVReaWHfDIq97aDSg7VAqzjUCgUFlbUdgG7RTXdTMXDFtQmX3BYRWvBoq8Flpru6k8LVirvnYSm88Mxx2m4Ojr0ry1s6iXaeOncPuxOl00lzdSc7srKCDuPeePUdHUy9ZOeku8SAgdtVQ3s7sJTmUFA5ll3nej/eePQfADZ/O914jHBcPVdPW0EPe6hkRD8raG3vIykk3pOi1nXp/j5Xjr5ew6toFPtZXU1UHM+Zn+8ZWnU79VHMdqouawx9EZBYUDOnf5u4+iuqaWTozJ/jBbnoHraQmWUZlFt+Ew/MAdbfFPuvIbnPQ0+GKOzkdQWajat0Ufg9EX9cg5w/ojxm0R/pbZtqXteAv56k410jj5dGVuadXBsY6EHzexpFXJMffKKW5ujPoMaMVu81BSWEN/T2Rp4QHdLzB9RNn3i5nsN+GPKKfXux0OrH6xZTa6rtprOig8LViXReqzWqn8nwT7//1ImffuRxUzvaGHh9Z6y+1BXS69WVtvPGb41w6OVTKyt/yiSSRoL97kMtnGnj3z+dCBvRrS1o4vqfU+37Vl7fx7p/Our6PgU5Y+72Kj9bQUtPl47EAuHiwCpvVHhBzs1mNKajjbwQvX6QlkjRz8L2/Jyvrw9bX6+jr5zfvnmDPubJhl2WKBKMuPkUMKXyt2Btkdtgd+vrJLw3dn9LjdREv/6w3mjQ6khsp9DoU/5db75601XeTlpmC0+Fk8vThr/LpdDoZ7LORmjG8heg82G0O6svayF081WttlJ+u58LBKurL27nu7tVhr+Gp3wiw98mTzF4ytGao567pWdveKhNBOutTb5VReb6Jmz+33hv3SU4dsnIslsAb/s4zZ7Eku75HfXlbWNkjdWkd213CJr9sv2iK4upVbQDo7xmk8G8lALRUd5I5Jc3rSagpbiF3SfD1WNsausmenkHl+aGK+57MvIFeK3UlQ3HftvpuXv/1MRx233sfi/fO6XBitzu8Fmln3wAHSirZunQ+JlMoB59vwVeH0+nz3tW1d3GxrpkPiDySzO7YYJvrPhY3tNDQOZSk09jZw8zJxqzyaDBaLPbLQogJ4+ivPN/ImbfLY3Y9rVUw2G+jQWO1uFx8Q4/SoN9cqNqS1sisA58Ise+uA385T2NFoMXkdDopOVZLV2sfp98up6UmcdaIXWdkaR3w69x0OqmLB6t4+w+n2f+0fq2ySLl0oo43fnNc934Fw9pvo768zaskzuwvp+D58zjsDg785TzHdpdQdHhoQnRvp8uK7moJPzkSoPR4rc9nTzAeAKeTE3tKOfduoGXtUVDBrAlPR1tX1kbFuUaX/JpDzUHcd97fysCI2t9CC8dAr5WCv/hWw4gmhhrMRXbuvaH71Nc1SHNVpzdLNjU9KeR3eu/P5yg7Ve91QYPvc+v/vvorp76uwaisZn+OvV7C335RiHXQ7u1Djl+uo7a9G7vDwfuXgk++r20fUjLN3b0+X/flk5Iz1Y2cqhyyaLsHhuTt6BuaB/enI+eG/T1CYdTFtw4oFkL8VgixMZ4CjQZO7i2jpnho+Y3hPEytdV28+rOjVLrXN/KvyN3V0sfZdy97P3tW59Q+MHqddjAcfoFbf84fqAzYVlvSyoWCSt7+w2kun2mg4PkLhtuLNXrpy1YDFpRRzr572adjCYbH3eTJKjPC0deKObJLet2m5acbaKlx/f6e9YhaNcrfmwdjMAYYqvK900lAIoNn4rc5hAXVWjdkYZzdf5lTb5VRV9rKIU2qd6RZkgO9VnY9etibfQrBJ5lHgs3qoKWmE6fT6fOcRKO4QsmTnBbesaS1ZoGIXeVHdsmIjtej1m2ptTd0+3TkdocDWd9CU5exgY/TCX2aGn0eq+lgyVAKeu/A8Gv4RYOhJ09K+XlgGa6l338phCgUQtwvhEgLc+q4YM/j4WeftzV0c+iliwz0WXHYHV6Tv8k9Kjv55iV2PXqYslOBS0Z0tfjOhbDbHIbTsS6drOPSyTpKj9fS3dbnM1rT8xV73DLagzwj+ZHCYXe4MvR0FL/e0tyRLiVRd6mVmuKWAIvD6XRSdrKeU2+VBTlzCLPbraUXEwuGZ+QcqlqCXfv7ODxuXF8FVXa6nuLCwHhRuImh/rzhHuyEcvHp3Yuulj4GtJUNIgw6eCzwi+/HdlnyokNVFDx/gVd+coS//bKQno5+2uq7eeWnRyK+VigXm9MZPlPNPykkka7ytrpun4HpK6eKudwcmcLs09Tnm5fjcpb5DJJDPHsnKuoiaisSDA+NpJRdwPPAn4BpwJcAKYTQL18wxjj+egkHngturloHbJzeV0atTi08gMMvF9FY0cGlE3W8++dz/O0XhS6fud/o2MhIcrDParhTOPduBefereD8gUree+68b4eqcw3/DCongRaKP6Fe1sbL7TRVhZ5A7O9aKj1eR9Hhagr9Asqgb0H5u8DCxSGOvlrMsd0lnD9QGbQyhb/y8sfithr6e60RW9ChLKKOxh76ewbp6x4MGmc8u/8yFw8Gdu4Brk4tQX4iV9zG9XdzdSe1pa10NrvuZ1tDd8DgCAioVxfppFxLBBUmIqHBz0opPlLDwb9GZ+0Hi02B+zkJ8/oFSzhJBBffr6JPM8i0ORwUN+j3U8EYtIX+jUNl7lW1xi8kYDQGdaMQ4jmgGFgB3CWl3IBr2ffH4ibdCDHYb6NattBaF3z59dqSVi6fbaTwtWKfDqurtY9djx72Kh6nwznUAdR3RzWKrDjX6M3yC4XWjw4uRRPWgvIb+Vn7bT71xTzs/d1JigtrcDqc7HvqNEdekbqK6tDLRbz/1+ATDt/+42le/ekRdj16mLb6bpxOp7dyhp6lodcZlh73HaFFNKkwyP3wuDqLC2vY9ejhAJeNJ+7SXNXJnsdPRNRmOAW65/ETvPnbE17LsL/HysX3q+hu7/d1Xbnb9PwfSlEEk+/wy0W01Ax1xoWvFbP/6TOUna7nvT/rD8j8FUE4C3ag10rj5XacTiflp+upPB/ehRoN/gOpygtNEbm/jeKwO0Z0zaOYMEyBBzQKSjugPH65jgu1TXT2B++P4rmKr9Esvl8AvwK+IKX0DpellJeEEI/HRbIR5NjuEu/fwVw6Wl/9sd0lbP24K+vq/RCzwUN13KEwOjq7dCLQtNYqT71Oy5JspqdjSDGc2X9Z99q9HQNcPFjFjAXZ9LT309Pez8m9Zay6dj5pmSlUnGuk6mKT7rngmmdV8Px5nxfHM6fFg7Yj72zu5cz+cp/ONOi1DRzjwTpgo6NxgKm5kwIsOYfD6bVUTuwpJW/NTOYsmwYEZq7ZBuze2ERTZQfH95SSlZPO5jtXBCh9k8mYa1BbGaT4aA1t9d3MWTo0H8Vhd1Jf1up+3laFTLcP1kEFK491Nsjv7i8XQIqBmMyhl4uYvTRHt9p+rAhpQcaQwX4bzWG8AuMN7RIcdk2/caAkMGbtjydmFQ+MTtQNnMo/tO87kTbqrun3SyAfGAAekFKWavZ/HvgiYAP+Q0r5WqRtRII2ay2YxaNNKW2p6aK+rI0pszIDXmbtaD8RfmmfLC6dTqtGtvgkgIRDO8quutBE1QV9pXTqrTIqzjUyZ1kOU2ZmckHHReXPQK+VM/vLyZmdxbn3KgKsmFhw+OUiOpp6yVszk+VXzfXZ96omdtFY0UFjRQcLVrV7E1q09PdaGRywIQ9Xe5MRBnqsvPbzoyy5crZPx3x6X7mhSaWeunYebIN2zhcMdQi7f1XotQDDJa4cenmY9etCEMqzoCWYcsqcmuZTZ3K0M9hno/y0fh29eJI5Jc1bCSZShjtFXWshRToRN2EWlBCiC/2x2XBr8d0FpEkptwghNgP/B9zpbjMX+AqwEUgDCoQQe6WUcYnkD/RafdxA/u6kYHhK7Yxmgs5PiYP/wpMZV1vS6s0uMkL56Ya4dgYdTS53a8W5RkPZe3rKCUJPFNWzZI1kQvor5LZ6X0Xgn548Vll17QLSMpOx9ts4HIPstfHIsk1z6Grti1pBDfedPn556BmONMEinhZUuCuvAdbq/PNsj5atwBsAUsrDuJSRh6uAg1LKAbc7sRRXmntciDRDbLh88JNrWXnN/BFpS29OzFjAaEmbiUhK+tibWz9j/mRyZmcZTqcfKyxcN4vMKcETmT2FYo0we0nOmC3VFU8LKtyVl7jr8G0I8i9aJgNaJ69dCJEUZF8XkD2MtkKiN0t+2Nf0T+XWEG1r0+cndp60XueSnpXi8/nqO4X37+EU2L3mYyu9f0+bmxX1dUYCT9WKUMVHZ4eoSmCURfn6ApiLAAAgAElEQVSz2PrxVSzfNDf8wX7ME9PYolNwN1YsWD3D+7e4eki+FVvmceNnr/BWXR9NNR89mMwmpsyKrhLCkvW5bP34qqD7F64NU5BWw3ALUoeuGxFfEhmD+gTwNvBlnX1O4MUo2+0EtD2PWUppC7IvC4hbwThTGO2flGIhKcVCf/cgi6/I9ZnHlH/jIk7vc1WcuOm+K3jrd6cQV8+lu72fGtnC9HmTWf2BPN7909AqlSkZyYatce3181bPZONty3jjN8dDnjNnWU5ELjaApRtme12bV2xbzKm9rrkxk6ameWsRLlg1I8BFdtN967l0oo4L7rhJ7qKp3Py59disDrJy0mmu7qSno5+W6s6ASaQ+bd602DsfJ2/NTNIyU7jj4atwOp1RJ5qEImdOFlfdsZwLBZVel96Nn8nHYXd6K1Hc9NkrSJuUgtli4pWfuGJVG25diiXZzNFXi1l3/UIW5efidDpx2J1Ykszk37iI8tMN5C6eyt4nTwKwfedGbIN236oPGlZeO98npXzVtfOZOjuLgy+4XITXf2odDpuDKbNcS100VUYevM+/abHu4oIbbl3KpJx0HDZXpYtoMJlg8RW53hjt0o1zvEk+KWlJPgtkjkYL6sbP5JOZncauRw8bOn7dDYu8VWYsyZaQk5jTJ6UE3eePyWwa1gT0RBpfyYmKQbkn6CKlvD7G7R4EdgB/ccegtOsMHwX+0z0JOBXXWlRxq6cRzoKav3I6665fBLgnemoUVNa0oZpvmdlp3Pm1zYArky41I5kVm+f5rNmz5gN5rofWQBDyurtXkzMny6ugklItPvXRgrHp9uX0dQ/y5m8NLm0NrL4uz6sstB2Z1uWQmhlYk85sNnldTh7ZtGv4TJ83menzJpO3eibWATv1ZUOd9JIrhxTUvBXTvQpq3fULgaERpbh6Lod3SabNzYooe2/+qhnkrZ7hjQVd/WHhjRtmTkkjNSPZ5ztNmurrVtRz3UzNnUTmlDS23b/eaz2aTCYsSSbv34uvyAXg+nvXYRu0u35/v597/c1LuHymgbb6bmblTfEqKM/zoyUrJ923FJbbJZ2camHDrUvpau3TrQ6ixXMvp8+b7J1MPHl6BvPcK8NqsxuzpqXrzo3SkjE5lYFeKzd+Jp/ktCSf9HetJeAfQ/NXUOtvXsLJNwPXWRpJIrVcZuUNOXOSksyYQvQfRipSaBnWcjgJVFCWRGfxCSGWAQ8Dk3DdCguwVEp5bZTtvgRsE0K8777efUKIfwRKpZSvCCF+ChzA5YJ8REoZtxQgrQV1/b3rOLyryCe7SvvQaDuKtEkp7jRjEZC+nJaZwtoPLgxoa1oE6xZlTvXtIJNTLGFHoHc8fBXgGrlNnp7hnY9lhA23LsVuc/i4J7XtpQUpmjp/xXQ63VlyRsicksa1H1tJWqarg09OtXirNvi3CTBr0VTu/NpmbFY7f/tFoaE2Vl47n2Ub5nhL/UyamuYTu/G6mjw/m6bJmx+4MmhHkeRWwhmTwy+kpy1Ym5yWxJa7Vngz7TKzU9nykRX091iZNFU/hrHmg3kM9FoD4hKe+XYpaUnMWjSVnhBVQBaum0V/96D3Gls+upLDLxcFWGFa19s1H10ZtnLKhtuWMjV3kve6WivCZDKx9vqFnN1/OaDgqv9vu2DVDKouNPnUrtNa06EwW0yGk0jmrZgetCZfqPJReqRmuqxqs8WMJcUSVC9MnT1JN6Y0a9EUJk/PoKTQNVH8ipsW01LbxaSpacOqEu50N7Vw+pSokhxsjugzjiNdMj4SjKr4P+Eqc3QN8Gdc1k9oX1MIpJQO4EG/zUWa/Y8DIzK/SvtypmYkBzxU/g/NtvvXY7aYvB3srEXG4wtGffDJaUkBc0+SUiw+sulZFNrRoFZBJaVYAiZ5zl0+jZriFu8L6hlNa2uKic3zvNUepsyaxMpr5jMpJ53C14q9Hb7ZYmbthxYa+l4eGT1W1vaHNmEy+Sr+YIFiSwRuhKUb5mAyu36jGz6dT1pGckB1BHC5Q0uO1brW8HGj55bxdIbJEXZmWrQL7pnMJpJTk/RXxHWzZP1s3e2L1+dSU9zCGvc917tbuYun0t8zSP4Ni3y2m82moBbDlo+uxOJ+rj3PRjDMZpPP7+T/XC/Oz2XRulkBv6Xe8x+wJIyBXnrOshzmLJvmM38xFGazia0fX0Vf16DP8hVL1ufquj5DYUkyc8vnN3ivq0VrpX/g/1uje/7c5dOYv3IGOXOyaK3tIm/NTO/gbjgWlEdBJUdhzaQkWbANRq+gJqdFt/KxEYwqqCwp5U4hxKPA68BPgXfjJtUIEmr0DoFleoyMnoNh1Ae//cHAerz+I71Zi6aGdHnl37DIO2q0JJkDFNTG7cu44qbFgT2cRsY5S3O8Vpklyexd8nv7gxtDujaMEkmHbzKb+OAn15KSamHv706FPFbbcXgyArXZmp6K8VNmTeL2L20K6+a5+XNXMthvi9nS8v4d27V/t8rnOQxFzuwsH1egnkK/+sMiYFs4Zi4Ycl2Fe0712rz1Cxt8ztM7Ru+6AdsM9NFX3LQ4ot/CbDExba7Le6FVUMuuiizhxKPw/QePH/j7Na4BmwHZPfcld9FUcv0Gt0arlehZj55PlgjjfB/fuIq3i8rpHQycg/jlGzfxs33hvRbZ6fFTUEZ/Zc9wqhRYI6VsJz6rS484PiNBnU4iFssbb7pjOQtWzxhy50RxSf8XMpxcSSkWrzIN1gEnpVgCRpD+/YolyRxwfnJaUsQjz3AsuXI2i/JDp+VOmZlJRnZ09Yl9Mis1XzIp2RI2vTc1Izmmqe/+nfL0ea407OguFtnh4dYZA/33wKdJnU4wNSM5bMUJvfusVdazFk4x9GqYLa5n0mj2ndaNv+WjQxmikVjlEDxtfGruJDKz04IuS+IjS4hbG2pxRS2LdaxrjwVljtCCmjs1C4tJ/5xwsaW7N63ixpWLmJRmPBkkUoxaUKVu6+kp4AkhxCQgNiu5jSJ0XXDDCVy6mbM0x6eETbC5LJOmprHhtmU+2zbcupTGyg7S3AH9DbctJS0j2acqdji0Cmbrx1eRkh78p5s2J8uV2GAwphQr1nwgssUXI0V7D2Ix6BgOsbLEIHzdv2gIN/iINhtPq/g8Uwk84luSzWy+a0XAcjTaNj0uMM97uvG2Zbz1+xDWtAlw+r7XMxdkc8On8+lu6zMUf5qZlx20XJQ/RqashFRCBh/LJB1F6FFQoSyo2dmTqOsIrAoSqdW1Incaa+fNZM6ULOZMie80EKNvyk7ggJTyJK7Y0A3AF+ImVYIw4uKLBXlrZiI2zwvYvvKa+UyZ6TsqnLdiOlfevMTbEc0T05k+P5uZedlsvXs1q69bEHAdL55RleaBnjZ3ckhrwGwxc+3frfLGpGKFZ07I0g36sZV449PpJtj2j2m6dbSXCqHYtNmieodFqxO1p82Y73IpepY+9xR91cuevPULG1iy3pUdOX3+ZO/9CzXf0CWnO7vS735n5aQze0mO3ikBRJJEYcSC6u8JXs7LaF+j6+nxKKgQP056iu/AdOF0V1w0lKX091cFrvS8ddkC5k4dmXmZRhWUGbgshFgJPCGl/IiU8mAc5UoIeqPReAy2zRYzKzbPY+rsSWHbD4bJZGLanKyQ8RPP1YY7CTAWzFo0lTsevor5K2eEPzgOmMwmsme4MuuGlc4bA2I5YTViC8rAV9cmbyTpJHJErWB1ZPXPKJyxINtnwje4OuSV18znurtXc43WRRfG0vNM8s4KkilphEjur55l7D+AtOusd+bB6HOp185QDCr4uz7ZL1Z0x7pl7nMCv+NHrnT9BrnZkwL2RWpxDYeQPZcQwuJO+W4GdgPvAK1CiO8LIUbfrLs4EE930OYPC5+AdswnMrpfrtGgoCA+cqy9fqHP5813Bk8Q8LzY8bCKIyGRE1aNxKC088PSdOa/xdKtmOaXNWkymQKSB8wWM2aLmZw5WT5t67m6tGzavowrb1kyrEFRJF9Vb+CxdMMcNt621Pt5yZXBPQiRJEkEnOuNQQXu8yiZ1XNmcP/WK4au47EwPf2E5ty8aVMIxkhWBAnXY/wLMB9XyaNZUspZwGpgFfCteAuXEPzvfRz7spT0ZHIXa17GaH53A2/QaFFQsWbJlbNZnJ/r/Zx/46KQaf/elWUTHIOKZdgoHhUE5izN8bq2xNWBruhYtqm1iIIRLGnDZDb5lFnKmJzKbJ9YbzLzV84Y3oAgBl9Wa5GGmlpg1ILSnQDsFlOv7NAV82fxlRuvYkZWBllpKczPmcy0zHTvV7PZXVad0Wy8YEkV8SBcksTdwBYppXdquZSyQgjxGVwlkP4rnsKNFOlZKbrzZGBkR9vRjExDnuEZVVlMJKdamLV4+DXhRhOe27XlrhWUHKtlrggdN/Pe3nGRf+oi0mdm1dYFdLcXe6uj6GG2mLn9oU0A3sUlfdqMssNPz0ph5sIp5C4aGp2HKrbqbS/Ed1y/bQm2QTu1Ja2Yk8xcdcdynyVLjLJx+zLdeVVG1sIKi8Hb5Rk35czJYvOdgt2/OqZ7XGqQSfOgr6BMJpPX6jGZTHxsw0r3SsuubZ7MP6Nd3UhaUGHvvlY5aba1CyFGfrGjOLHtvvVBR9UjGa+I9WhYe7nbHtw4Zqsl++PN6HJ/n5kLp/hMhA16nimxFpSn1FCoUXTERPiTZs/IZNt96w0frxfnifY5MplMAUVrzWYTmdmpZM+MrmCrVh7Pu7p6a4jEoSDMXa4/8Tdn9iQysvOYmRf++QK49mMrA++ZwfvlUTwOu4Pk1KSAOo0eQilNvcri+okuGlepOTLXt3kE+5Fwb0ooJTRu/EYmsymgGrAlyYzd5vDWVhspOSI/yeBh40Q5gatTszucEWeweF18CYpBXfOxla5yUjF0ucb7d9WTNdYxtBs/e8Wwvkdcf1eTKWhVDz2mzw9ceGHyNFfW7LyVoS18z7xFzzphi9bO0lVQnio2euhaUCFbhfz5MylramPTojnsu1ge5uiRJZyCShdCrEf/O47rRXtmL81h/bbIZqwPl2heUk9pHl1XyThSSlo8HVKkC/p5bkeiQlAmkynmE5zj/RPrxX9ibumHuKD/Ksi658cotnjHw1dRdbGJi+9XeWsexuK7pmWmcPtDm8Kmxa+8Zj5drX1eC1BbrWXFlnkUHaoGXJZWsEK7ehl24ZbiyJs2hZ3XbyDFYgmpoK5fkUdXv34oJF6EVVAEX1JjHHny9RlJ5QSRF64El3tr/bbFzNBxQYxP9aRRUBGOmKM9b1QTZw1ltGRRvDAyt8gco9/VkmRm4dpZLFw7y/DyG0Yx8m6nZiRz3d1D8460sZ6ps3zTvWcFcWnrLn1h4OdKTQrvds6fP3LeJA/hlttYOEJyKMDQchr+mEwmFqwOXfUhwUlrMcdiMWEl9JwSPUyJNqHiwHgdhESC92eNk4svUfgMBPzFCCKWbgxqDD8l4yaONB6IafAchh7icdQhA956fD0dwZea0GPFlnmkZiRHVH191DOCfc/SDbPJnpExItMWZrrXXZpsoAZiPGNQiezafazXMIrS5P7qmamB8amx7OmPcY+oGA7RuPiMML7Uk2ueTmttl8+aS0bInpHJrV/YECepEsNIJr+s2rpgxNrbePty2mq7mJEXmHTgz6xFUyk/3cDCtaGLDY9l9Io4a1nWkMLim+YzfVLgOxHJLzYzK4MpGb7x7KsXzaXfZgtyRnxRCmoUEev5BUMurZheNuEsXp9L5tQ0pkewAOR4ZSRHxyOpDJNTLIamDoArHnPz59YHVKWIBYme1O3B/84nJVv40CfXcu5ABc1VnaTYTayY7coS/MTVazhSVkNZk3sF6wh+t09uXhuwbcvSwMnaI4VhBSWESAEy0dwrKWVrPISaaKRNSvGmlirCo1cOZ6Jit42b6YjDwrMIZqwZJfpJV8lkz8wk1bMygWb3rMmZfPiK5Ty694j/rjGH0SXfHwR+DHiGKCZc4/L4rfU7gdh23xXhD4qCsex7VhijN8SS77Hiti9uwDoYWULKuGGUaKipuZPInJo2ovMyRwNGLahvANdKKU/EU5jRQCL69Hins48WN4Ui9sxcOIXzBypJzUiOmxWekp4ccg2x8cxoeXUsSWZu+kx0A1nHaPkSUWC0Z6yfCMpp3KFMqHHP5GkZ7PjK1SGrZCuiZ6x07aHe9LGsoIxaUG8KIXYCrwDawrEqBjUWGLvPp8IAZrNJjUXiRYI791s+f+Ww0+ftY3hiulEF9U0gFfiFZpuKQY1yxmkSn0IxYiR6cctQdffAmPve4Ri7iTSGFJSUclzX3VMoxjrzV82g8nwTK6+dn2hRxhXjYXA3bl18Qoh7pZRPCyH+UW+/lPJH8RFrFDCGf1QPnsKkliALvinGD6npydzw6fxEizH+GPvdwLh28S1z/x84e0sx6rnipsWcO1DBmg8uTLQoCsWYJNEuPsOECEKOWwtKSvkd9//3AQgh8oBkKWXpCMimGCaZU9K4eodItBgKxZhlLE/R+PAVy3m/tNpbYWIsYnSi7lJgFzAHMAshmoHbpZRF8RROoVAoEsnYVU+weMZUFs8Y2xVXjM6D+jnwQynlVCllNvAfwC/jJ5ZCoVAkntHu4hOb55E2KYUrblyUaFHiglEFNUtK+ZTng5Tyd8CM+Ig0Ohjdj6VCoRgRRnlHMHlaBrc8cCXT5o7PwslGFVSSECLH80EIMZ1R/9NFx5zl0wCYsSB8mX+FQjG+GZed3BjC6ETdnwGHhRDP4frN/h5X8diIEUKkA08DM4Eu4DNSyia/Y/4H2OqW7zdSysejaSsaVm6ZzzwxnaxpauqXQjFREZvnIQ9XexdOVCQGQxaUlPI3wBdxVTPPAHZKKX8VZZs7gbNSyuuAPwDf1u4UQlwPLJVSbsGlpP5FCDFikT6T2cTk6RkjuvaNQqEYXazYPI87Hr6KydMiWxRTEVsMKSghxFzg41LKfwEeB74shIi27vtW4A33368DN/ntPwTc7/7bU05JLZakUChGlJFY2l4RGqMuvqdwFYoFqADeAZ4Etoc6SQjxOeAf/DY3AB3uv7sAHxtaStkP9Ashkt3t/kZK2R2iGQtAfX192C+hUCgUitGFpu8OqO1qVEFNl1L+FLwK5FEhxGfCnSSlfAJ4QrtNCPEikOX+mAW0+5/ndum9ALwjpfx+mGZmA9xzzz3hxFEoFArF6GU2cEm7waiCShJCzJFS1gIIIWYR/dp+B3FZXkeB24AD2p3uJIp9wP9JKZ8xcL1C4DqgDpigy34qFArFmMWCSzkV+u8wGSnlIYS4H/gBrtiRE1fc6BtSyj9FKokQIgOX6242MAh8UkpZL4T4IS6r6VrgO8ApzWn3SSnLI21LoVAoFGMXQwoKQAiRD9wA2ID9Uspz8RRMoVAoFBMboxbUE1LKz/lte0FK+Xdxk0yhUCgUE5pw60H9CpgLXCeE0JY2SgYWx1MwhUKhUExswiVJPAGsAfKBv2q224DD8RJKoVAoFAqjLr65UsqaEZBHoVAoFAogjIISQvxFSnm3EOIsOnUTpZTr4imcQqFQKCYu4Vx8/+3+/+F4C6JQKBQKhRbDaebgXfL9KuCkWvZdoVAoFPEknIvvGuD3QC3wfVwTaUuBPODzUsq/Bj1ZoVAoFIphEK5c7/8BjwDPAbuAu6SU64HNwL/FWTaFQqFQTGDCKahMKeXz7rWf6qWU+wCklMWoxSYVCoVCEUfCKSht8dU2v31KQSkUCoUiboRTUM4gfysUCoVCEVfCJUnYgF73xwzN3yYgTUqZHF/xFAqFQjFRCTcPasmISKFQKBQKhR8RzYNSKBQKhWKkCBeDUigUCoUiISgFpVAoFIpRiVJQCoVCoRiVKAWlUCgUilGJUlAKhUKhGJWESzMHQAixDvgIIHBVlygCXpBSyjjKplAoFIoJTLiJutOBXwGrgLeAcsAKLAJuBi4CX5FSNsRfVIVCoVBMJMJZUL8DfiilPKC3UwjxIeAJ4I4Yy6VQKBSKCU44C8ospXSEuoCRYxQKhUKhiJRwCioZmC6lrHN/zgduAM54lt5QKBQKhSIeBM3iE0JkA6eAL7o/Xwe8DawFfiGE+NcRkVChUCgUE5JQaeb3APuklN91f/4q8DUp5f3AVcCn4yybQqFQKCYwQV18QogTQBdwCbAAdwN/1hzyMeCvboWlUCgUCkVMCWVBfQ8YBP4dOIfLmrrfrZD+BlQo5aRQKBSKeBEqzfxl4HpccagqYAeAEOLbwFeAv4u7dAqFQqGYsES8HpQQYjLQL6UcjI9ICoVCoVCETzN/AnhESlkfZP9s4L+klPfFST6FQqFQTFDCVZL4GfCaEKIMeA0oxRW3WgLcBiwHPh9XCRUKhUIxIQnr4hNCmHBl8P0dsAJwAhJ4AXheVZFQKBQKRTyIOAalUCgUCsVIoNaDUigUCsWoRCkohUKhUIxKlIJSKBQKxajEsIISQix2/3+7EOLf3MVkFQqFQqGIC4aSJIQQj7n/fBTYB+wBJkspPxZH2RQKhUIxgQk3D8rDBlwVzL8JPCWl/JYQ4lj8xDKOECIV2ATUAfYEi6NQKBSKyLAAs4FCKeWAdodRBWWWUjqEENuA/3Jvy4ihgMNhE6C7JL1CoVAoxgzXAQXaDUYVVKkQYjewGHhHCPEMcCbGwkVLHcAzzzxDbm5uomVRKBQKRQTU19dzzz33gLsv12JUQd0HfAQokFJahRAHgD/ETsRhYQfIzc1l3rx5iZZFoVAoFNEREKIxpKCklD1upZQjhMgBjuIqe3QiGimEEGbgl0A+MAA8IKUs1ez/KXAtrgUTAe6UUnZE05ZRrIN2HHYHqenJ8WxGoVAoFAYxpKCEEP8O/BPQiKsWH+7/F0fZ7l1AmpRyixBiM/B/wJ2a/VcCt0gpm6O8fsTs/mUhANvuX0/G5NSRalahUCgUQTDq4vsUsFRKWRujdrcCbwBIKQ8LITZ6dritq2XAb4QQs4AnpJRPxqjdsLz9x9Pc8aWrRqo5hUKhUATB6ETdqhgqJ4DJgNZlZxdCeJRlJq5lPu4FbgUeEkKsi2HbIbFbVXF2hUKhGA0YtaD2CSF+COwC+jwbpZRRxaCATiBL89kspbS5/+4FfiKl7AUQQryNK1Y1WrIGFQqFQjECGFVQn3X//3HNtuHEoA4CO4C/uGNQZzX7lgPPCiGuxGXhbQWeirIdhUKhUIxRjCqof5BSvhzDdl8Ctgkh3gdMwH1CiH8ESqWUr7jnWR0GrMAfpJTnY9i2QqFQKMYARhXUfwIxU1DuVXgf9NtcpNn/Q+CHsWpPoVAoFGMPowrqrBDiEVwlhbo9G4cRg1IoFAqFIiRGFdTV7n8PaLYNJwalUCgUCkVIjFaSWBRvQRQKhUKh0GK0ksQ/6m2XUv4otuIoFAqFQuHCqItvrebvFOCDuBYuVIwDBvqspKQlYTKZEi2KYoLgdDpx2J1Ykgwv6q2YgBh18d2n/SyEmAM8EReJFCNKZ3Mv+58+Q96amVxxkwopKkaGo68WU1/Wxu0PbSIpxZJocRSjlKiGL+6yRwtjK4oinrTUdCKPVAdsb67pBKDiXONIi6QYA1j7bVScb8Rhj20JsPqyNgD6ewZjel3F+CKaGJQJ2IirsrlijFDw/AUA5orpTJqS5t3udDiDnaJQcOLNS9SXtWEbtLNk/exEi6OYYEQTg3IClbiW31BEgMPhxGxObJzHbvVbE0zpJ0UImqtdFnZv50B8GlBxT0UIjCqol6WUu7QbhBCfAv4Ye5HGJy01nRQ8f4H12xazYPXMxAnip5DOvVeRGDkUYwLPgCZeyQxKPSlCEVJBCSF2AMnA/7jXafI8T8nA/0MpKMN4YjxFh6sTqqCcTmUyKYzjeVxKCmuZt2I6k6dlxPj66nn0x25zqOxGN+EsqCuAG4CZwFc0223Aj+Ml1HjE8xomOpXboWJOiigpPlrDxtuWxfSa7Q09TJqaHtNrjmXaG3t4909nWXnNfJZfNTfR4iSckApKSvk94HtCiIeklL8cIZnGJ2690Ns5wPkDFazauiAxykrpJ0WUOB1OnE5nVM9tsPOOv1HKvBXTYyHeuKC2pAWAi+9XKQWF8TTzx4QQ/ySE+L0QIksI8S0hxLiZvDAibgZNG6XH62it7Yp/mzqESxd22B10NPbgdDppqemk4lwjTqeT9549x65HD3P+gIpZTRSqi5p9PteWtPLqT49EnPl5bHcJb/3uVCxFC6C3c4DqouYx7zJ02F3yKxefC6N34YfAOlwFY824lmIfPy6+kdBPfp+rLjbrHhdvtC4+vZf53HsVvPOns9SWtFLw/AVOvVWGdcBOW72riH3p8boRk1WRWE7tKwvY5nSCPcI5UTXFLRFlATrsDs7sL6e9oTv8wW4uFFRy/I1Syk7VRyTbaMNuc91bs0Wlj4BxBXUjrlV1+6WUHcDNwLZ4CTXSjIwF5fsxURNjPSM00J8D5VGcWgvPOmCLSduD/TbO7C+PX8qyIqYEs5SMWlBdrX3YNNMaQr1np94q4+L7VQDUlbZSfrqBd/98zrCsngnn7Y09hs8ZjTjcCkpZUC6M3gWre5FBAKSUA7gSJcYF/u9NfVkbxYU1iREmzvR1DSmHng5fReGZkAlg0szXGuyLzU9ddKiK8tMNnNhTGpPrRcNYdwH509PRH7dqDMESaowoqO62Pt7+w2kOv+xdh9RncORzPaeTinONFB91vXPWgSGl1ljRHrKdvu5BCp4/z0CPFYht2npjZQe1pa0M9o9cV+exTs1KQQHGFdQ5IcSXAItw8RgQX6fyCOLfaR15RXLxYFVMqyzodYyeSZAjyZn9l71/H3jOd4R65BXp/Vsbz9Z7QesutUYs/0Cv1ef/eGO3OXj9sWNcPOQamTudTv72y0KOvCrDnJl4Giva2fPbE/R09Ic8ruAv59nz+AnvwCKS659953JohR1kl5FMUI+V3FIzZIkHe5/sVl+XobHYVHUAACAASURBVEMjk8e1HIziI9U+behReb6RnvbQ99Gf1touDr14kcLXijn4woWIzjWCddDOpZN1Ad4Jzz0yBZnQ73Q6R8Uga8Bq8/md4oVRBfVV4EpgFlAAZAJfi5dQI84wXkTtscd2l1Bf3mb4nHg8+JGgHan6o824GuwLVChHX43+xe1u6/f62uNJT3s/g302io+4rWGnqzOsv2T8N0oUx3aX0N89yKUToWN+/W7Loa87Mivq0EtFlJ2qp6u1L2LZjAzczJbAriXY++Q/APK5fpiMwYA+0u/49sYeTu4tY98fToe8jj89Gjd0Z3NvROca4cKBCs69W8GFgkqf7V7FpHOrrIN2XvnJEU7tLaO/ZzCiGF0sGbDZ+NU7x3npRFH4g4eJ0UoSn5JSfi6ukiQQ7YgkPSuFvi7Xy+6wOzBbTHQ09ZI9PSPoqAagq6WXmuIWaopbuPNrm3Xa0D+vo7GHS6fqMZkgb81McmZnDe/L6BCJ0vSg/a4n9lwKepzNaqe7rZ8pMzPDXlN7Dzpbepk6axKAt5PMygk9H8bab6O2tBVLkpn6sjY23LrUR85LJ+uw2xws3zTX3Z7vTR9Lc8AsSWasA/aQilybkRmttR/NeUbuo57cwTJI/S3qUAPz7rY+UtKTSUlLch/re7D/G+pRfpF+z3jPAOlocik9fze7Z2CoJ2+fW2lWXmii8kITAHc8fJVPvMrpdFLS2MqCnGxSkyxcampjzpQsMlKSYyZ7d7+rf6xqjb8HyKgFtTOuUiQY7TOu/dvhcFJxtpF3/3RWtxK4Fr0Ro28b+i/Igb+cp+pCE5Xnmzjw3Pmw16i62BSxO+fIrshdWp54QDA5PBT+rYR3/3SW1rrI0ubNmh7g7T+c5u0/nKbuUqt3W1/3oM/ovvJ8I7t/fYxTb5Vx/I1SaopbAtw/596t4OLBKo2cweUe7Xg6nVAKSrsv6mrjQW5JqHtlpLPXkzvYef7WX7DjBvqs7HvqNO89Gzx5wv8ZKjs5ZIFGco+M1swsPlrDm0+ciNgjYA+SDOH57kafVc91Gjp76Ojrp6i+hd1nSnnjbCnVbV28drqEvx67GJFs4RjJcZ5RBSWFEI8LIT4thPio519cJRtBtA+D9uVwOpw0VnYAUFvaGnCezzXC/WpBdvs/2DXFLUEfzrKT9ZzYc4lTbwWm/wZjwM89Nyknnf6eQfY95RtCzMhONXxNbcyg8bIriO0ZEYZC+730rNGjrxZ7/37ztyd4W+OW0fvO4Uby/h1SLGKKPR39NERhkUaKJdk1zTBYx1ctmzmkTUCI1oLS/CYdTT0U/q2Y9obukHEdQxaUf1HiEOf1adxpRYerfeNFGvk820PFk6wDdlrcGX1HdhXRUD6UZFH4t5KwcnswOhn54vtV9HUN0h2hqzSYgvI8s31dg+x69DAlx2qpON9IybFa3Wfh9V8fo62+m5dOFPHWhXKaOl1ZjNVtXXT1u+OAPX109Q9w+FI1thgsm2J3xN8978Goiy/H/W+pZpsTeDHmEiUCzXujTYt12J1eU9//5aotbcViMTFr0dSA/dpZ83abI6I07WO7S8i/cREL184K2NfR5Hr4WiKY5HvoJV8/sdPhpPxMA91tvi95+qQUejuMpX9b9Sw4p+/3Lz5ag8lsIjU9mbw17tqDPpaqsQ7V5WY1k5RiCRkz03JsdwmdLb2sunaBd9vuXxVyw6fzvZ/fePw4ObOzuOqO5Yau6cEz4fTWL24gNd2428Rhd2Aymwx3fJ55MI4gCur4676ZkNEqX09mncPu4OSbl7wDjVAuW6dONt7xN0pJy0xm9XV5QGDig7Yt/99eG0uRh4N7KnSTa3S+dm/nANPmBg6aPGtQGcF/AHXyzUus/dDCmC2uGKwIr38/o41RXfOxlbrXaq7uxO5wMGC1YXUroGSL2cdL8dTBM9gcDixmM5sWzYlK5rr2LqZkpHnbGAmMrqh7fbwFSSTaF0b7YjnsDq+p798BFL7mGu2v2rqA2UtzuHiwUnOeE0uS67z3nj1HZ3Mv0+dNNixPsNGY5+E14n7obuvj4vtVdPjNC+lp79c9PxLvl1Unq097fndbP0WHhjqaydMz6Grx7SwcDic2q90b7wNISQ98HO3W4AoqmJKrKXaVi9FmJVoH7D6d30CPlbowVnEo7FYHGCwhZ7c5eO3nR5m7fBobtxurZWfExafF82zYbQ6OvV7C4vxcZizIDi+bu7MpOlzt7dAH+2whB0HaTtRmtdPZ3OutOuFRULYQLj7/dPOQAy5NJ2s0+9PpcIada1dcWENDWRvXfnw1NbKZtMwUcuZkUVxYw4JVMwJiUJ64z+Y7hXdQqkXPOnQ4nAz0DJKe5fJONJS30dc1yMJ1s7zPsiXZ34IK/iL6v8va72sxm2ns6qWxy/UbJlnMPoMhm9vq6ewfoHfQyumqBq5ckEtqsjEbpbm7l+cKLzBtUjrXLp1v6JxYYNSCGtcE65wdDqd3JOV0OGmu7iRn9iQuajrfCwWVAZk4nnkpmdlp3gygSFKry07VM2/FdFrrummp6WTj9mWYTKahFFSdWeYOuwOTyYTJbKKve5B9TwXPWtIqDw+RjMD1YmA+7js/8fRiBt2tfcjD1T4uGE9nrI1n2WwOgtkpjZfbmTE/fCfsPd7trtWjraGbrJx0kpIDR8g2qx1Lkpkqd2BaK2swqouayZmTRcbkVG8WZE1xS1gF1dHUw6WT9T4WuBE8Vk1daSv1l9qov9Smm6zjj8dCKymsHdrmcNIfwo12+WwDDoeTaXOyOLJL+kw3uHy2gdzFU0O6+Pw9CtpBSuAX0wweNfeis7mXydP1K6uXHq+j5Fit7r6ejn4ys9O8scr+7kFvEtCS9blcOllPR2MPi/Nzdc8/vEty59c209c14GNN2XS+77n3Kig/Vc+KLfOou9TmVTBpk1K838VkMtFa20VKehKWZAtNIZ7R8wcqdbc77A4fawnAZndwsbYp8FiHk/1FlylpaGXAauNDKxZ69/31+EVyMtO5XrPNQ2u3a9Dc0t3nY0HtPV/GTasWxa2uqFJQhJgxb3fS4I6x9HUNcvCFC96HOBQeN9CHv3q1d5t2hGW2mEKOlJxOfGbRt9V309c16JWzp62fzpZe79IHToeTghcu0Nc1yKJ1s7wz8o2QlGLBYXdElECg9zL6BOwNKDu9zEDPPdEmi7Q3dHP01RrdTqz0eB2pGclMyklnZt6UsG3quZ3A5SI5+MIFZi/NYd31CxnosVJcWMO66xdhMpt4/dfHmL1kKnWa9PRQiqO1tovjb5SSmpHMrV/YYEj5e5TgwRcu+FiK7Q09vPPMGa7aIUjPSqGpokPXMjr0chH5Nyzy6TT9l21wagZc3mPsTm9GmFb+UFSedyX13Pm1zQFz4U7vK+f0vnIWrw/s4G1uxRTJxFftvdO+M/ufPsP2nRt1Q7uhUuf9awKWaCbke5JubIP2kO9DZ3Mv+58+Q9a0IRPa82wVHaoiKcVC3pqZlLvLLvkPCLWWfU9HPwf+cp6U9CSfla4jwW5zYPH7XfusNi63BCq7xq4eb6Zje+/QIKS8uZ2q1k6qWjt1FdSgbeiZfP3skHv5fG0TqUkWPiDyopI9HAlRUO61pX4J5AMDwANSylLN/s8DX8RVreI/pJSvxVWgIA/jxferAqooeBSWETo1PnBtYDclLck7f8UIh14qCrBaDjx3ntsf2uRqp7mXtrpur8yRYDK5/O2RuPj0LKiLB6vIzE6juaqD+atmRCSDB6fDGZCMok2c0MMzqrz9S5vCXj+Y5efpmOpKW6krbXXdD4cTS7KFOctyXPv85k41Xm6n/lIrS66cTVNVJzPmTyY51fU6eSbXeqxmrbur4Pnz5N+4mMzsVN579hzmJDPT5k6m9FgtMxdO0Y2zdTT1Io9Ukz4pBXmkJmg6/um3y7nyliXez+89e47r712H0+mk/HQD596rYPmmOaRmpniP6WnvD/AAGCXU3KsynUHc+y8Vsf7mJZx4w3glEXmkhp6OAfJvXBRQMaNatvhYtdFw+exQyTG7WwHarI6QSm7/02cA6GoZOsYzaJPuOXfBrB1/PB6EwT4brX3RzWvqbO7FOcXYC9zUNdQnXW7pYN/Fcj4k8th1ckhpOp1OLje3M3fqZFKSLLT19PHWxfKg1+waiE8lEzCooIQQJ3AplD9JKWMxa+0uIE1KuUUIsRn4P+BOd1u5uNae2gikAQVCiL3u8kpxIdhPq6eMPJ2QEd7501nd7UkpFohAQel1rJ5ttaWt3nhYNFgH7CSlWCJy8QVzVx7b7cqSGhhGaaRov0uwZAItelZP6fE6utt8OyPPvai60BT0up6BgKdDmrt8Giuvnc+B58773J+qi00+1mJLTRfn3r3M9PnZ3piPZ3DRGGLwM9BjpfK8qzMO1Xlq2+ps7kUeraG9vtubIOCR10O0yglcmZaR4HQ4I1JOHqqLmmmq6vCWM/Jw5u3gnWY0eFxwHY09QeM9wbBbHSMy+VyPxooOBpKAtMjdbGerGzlb7VsXtLK1g12nXO/h3ZtW8U7R5ZDXiOUcK3+M9rZfBr6Aa22o/7+9c4+SqyoT/a+6qrur3+9X+plOJ1+n091pmrwgb5IQEl6KoAgGwQHFgVH03jXeGb0LnYf3jnNZI7pGWSqu8cHVAUFH5l5GxBm4iGIYIIICn0AAE8ibhCTk1Un3/eNUVU5V1+NUdVV1Qb7fWr361HnU2bv2Ofvb32N/+17gDlX1nslxMsuAfwNQ1cdFZIHr2CLgsZBAOi4iL+FkUn9iCvdLinsklIpUqVe8kGzCbzo8fNcznsK7U+Er8qU1W96dLike8TJP5Jr/fCCz/H6pOuhwwEUqwtMDYoV3PFPm7tfeYvdriX0N8UhHc3fzQjoatY+o0VoqU3Q+iRVOhcaWX2zNW2aHpZcPTMri4stiM/34qdPa1N1PpM4WU+Yx0CITPM2DUtXHVPXDwFzgOeBfRORREbkiw/tWA+439JSIBBIcOwR494SnycT4RJRNOC9k6WHKhnBqaK/K+qz5VLnRckEy53K+eOPFzKMC80GquW5LL4sOYw5WlnD2hr4EZ7+zqG+rzO0NJqLNhbmktmXyFICirKbJTc3MxtM+37IcalCeU+aKSC2wCUeTegu4G9gkIt/M4L4HAXdOnyJVPZngWBWQ2fDRA4ddvqHy6vgvcMfc7K74mYsx6YzZ9ay9boTqxnKaumpY/aFhNt64gPU3jCa8pv+cDpa8pz9ptvLRC3LbQcULLQ8zY3Y9Q6t6aGjPbvqnjv5GOmPa1FfkY/WmYUbXz6KiNhjpBIpLTwcdLIwzZ2rG7Poovw+QNHpu6eUDDK6YukM5WFmS9Pjgim4qaoOsumqIi25exCWfXMzaa0eorHMc8VX1ZcxdejpceM2H59MYExE5duwkLT2pg0/ilq+ieEprGrXPacj42ngs/8BgpO7gaIcVdUFWXjXkKdrRjc8H/Us6Ip/bZkWHnfcMNTOytjfy2f2Md85tZMWVg9Q0lVPhKk/sfKh2aeCsdb3EI1DsZ2BZV/TO0G/dWe99OstUuPQsiWzXV2QW3OEFrz6o7wMXAfcDH1fVX4f2fx3YDdyQ5n0fAy4G7g75oNzOms3A34pIECjF0dqmYk70TElZYNL8iUCJn5rGchJNH+w7uy1ri/iNrO3l2NsneOHx7QmlmL+4iM65Tbz6zC7AmWO09PKBSG6y1R8aji7/+ATFpfEnuc6Y3RA3rBqiO9lM/AbgCILYVVndlJYXs+aa+bzx8pts+fnkTBELL3QEQsvMWrY8tJXa5orIb93YUc3RwycSZhXwFxdxamwcn29yDExJWYD2OQ1Ri0YuvkSobiinuqGczrlNHD8yxh9/v5tZo23c/9XNADR1VjOwtJPnQiHKQ6t66B1xotUmxid4+udbWXHlYML69i2YQWNHNY0d1bzyzK60M2y7WXbFAMGKEv74+92TTK5rrh2hsjbIrNG2SdeNrO3ll/c8x/w1M2lor6Z7XjMH9x6hss4JvHD/XmMnTnkyR1c1lE0yk6+4cpCnHnyZvducKD9/oIhTJ8fZ+PEF7Nl2kL3bDzK0spuH73qWg3uPEKws4djhEwws7aRrXjOBEr9n82oqln9gHgAd0ui8Wzg57NINjd5w4wLe2vM2jR3VTIxPoJtfZ0ZffWQuU3Gpn8GVPbTMrGWPy4R79vq+SNaP0fXOgG/V1c57+i9ffhxwnkl3pOqCDbOTBqGUVUUPUMYCTqPVlgXZRvwceWXFAY6OnR6MXnPuMCdPjfPYS9t4LU7EXyJWhSL2GivL2Xv4CE1VqfNwZopX4+FzwKdUNSpkRlVPisjSDO77Y2CdiPwKx/J9nYh8GnhJVX8qIl8BHsXR8D6rqpm/yWkQ7uTdTIxP0DPUwrG3x+gdaeWpn70UMWG19dUzsKwrsYCKsemDM7J99dld8U8v8iGLO+g7ewa/uu952vrqeePFfezfcZjW3jqGV/fgL/ZzaN8RXn1mF/3ndCCLO+J+l/s7N9y4AJ/PF3kZwvsTaYyZMG9516TIperGcs69bC47tu6PhNy6OfeyuRQHA3TPa44roMJU1ARZ+r4BDu49EvmtZ53dxr7tB3npyR2RqDsAWdxOdWM59TOqOHVynIfvenZSkInP56O+rYoLb1qIP1AUt6MqLS9mdijp7NkX9HFg99tO+PBQC4fePEr/kg7Ka06PHLvmNdM1rznyeeGFszl2ZAx/oOh03VyScuUHByPLlCcb4FzyicXse/0gm//Piyy7YoDH7nmOE8dOUlpejD9QFNdHlCxcuaG9OmrwUVpeHBW2vuKDQzwSDu6ZiJ4UvnrTMDu37qd3pJVf3ft8xB+79PIB9r1+iJeefIP61kr8JX7KqkpZsHE221/YS2d/IxM4gT3FpQFm9NUzo8+JjgwHFjTMqHLC5Ev9WZ1Tc/71o5SFtM05i9tp7qmltqXC8z1ae+siASYlwUBk3p3P7+PimxeBz0nVtO/1Q4ys7Y1MyG/rq6d7sJnuwWZPmWRKgoFJUyncGuja60bY8tBWukIRsqXl0Wa1UyEFrKossWZ90fw53POfjk9pfmcL9RXOoKS+oiyugPrgonn8YPPk/KD9bY714fIFczl+8iTBHPqgkn6zK9/eC8ByEYk6rqr3qWramQhDix/eGLP7BdfxbwKZmA7Txv2cNrRXT3Jej58aJ1Dij5hlymuCEQFVEgzEfdB7hpp59dndDK7o5nePvBZ1bNZoW0IBFe4M/IEilr/fGfV1DzTx/OPbkcXtkdQ6De3VnH/9KMFyb7bf2DIuvHA2jZ01EbNCRU3ppKzK8ahprogb3XThTQsJFPsnCajxU+M0ddXQ1FVDQ1tlVCBDcTCQcKJl4oq4Nl118vlOjwP6z4me5e4PFMURUM7/RNpjLB39jXT0Oy9lSTAQGQUnY8bs0yaq1pl16ObXmbOoPbKvuDRATZPzGwws62LXqwd48Yk38AeKovxpviIfjZ01bLzRiSNae+0Ix46MRcoeL2PDVKhtrogabLg1qOISfyRTfHi+VV1rJaVlxVFCJ0xpWTGzzmqL+hyLe4nz4jgDRIDl75/Hkz97KSoVV4c0sF2Ta1hrrx2JCCdwnpm61vR8UcnMlOHfprwmyNprR6KO+QNFETNfWBNq7Z2cgSJMZV1ZxKdcERpguBNQF5cGWPq+gcjnWAEVpqJksoDaONRHd2MNpYEAt6xbzKlQyqMwgaL4np6Wmvi/VYnfaftgcSCnwglSa1B/luTYuyMXn6ujc3eYxcEAY8dOUj8j2v/hHlHGqtngmFC6B5uZv6Y34YTHRD6oeOaU4mCA4VU9k/aXpfBBJCNYWRKlLa66eph//95vIyO41ZuG417nlnPl1aURc2i4s1x/wygT4xM8eOfTQPSE3XZp5OjbY+zbfpCdW/dP8m3MHGnllS0742piYdy/vTuv3cREyFcWZzJXvKWz080GP1VKy4vjtiGcFrStM+toDaXQCWu68TrT4mAgqiN3h8FX1AYn+yYywN0xRg1uXNth39xUlzBp6qph23N7kg5W6mdUse66syK/S1NXDSPrZiUUUGGfUEWGE1/dJBIE6VBWWcIFHz07roUmzJxF7ZTXlNIz1BJ5t/0u4RibnizRd5WXTi5vUZGP0sDp8/0xAmleexNb9+xnpXRzX2iNp3Do+OLedn6zNXpqgtdM79kgqYB6t+fgg+hO192Z9S/p4NC+I5NG5G4hUhdn7Sb3DPSEiSUzWOIgG5SUBThx9CTBimjhFijxR0wMrb11kQwVsbjrHq9jCn9vODw5dg5R32gbvSOt7Hpl/6RsCEMru51JpOXFnDxxitZZ0aNxmKw1RTSqiQk6++MHsriXzg77QU4VSOh0Ii74mJN9Irad4tEz3MKOl99kcEW3p2waXogn1CH6XRlc2cPxI2MMnzdzSveaf95MWnvraPaQNzDMOe/px1fko3NuY5QfMcyiiyXOVclJFFLfMKOK8pogzd1TCyROJOhqmsp5a4/jg3MnN4bo9y128BqsKKH/3E7+8JvtjJ+aoOtAMUV9FXTWVzO/s4XfbjttpYlNgxRLbXmQTecOR/U/H1nmaIRLXALq/QsHOHoi8zmOmZDKxPdlVb1FRO4nTreqqpfkrGR5wt107hezrKok4gCPOt/1oIRfqnXXjfDzUAoVd8cdmwgy3qgnUOKPjOhzPdHvvE3zObz/aHzfU0QbSdx5u0dOwYpiVl01FDdE3Vfkg1MTcYVYUZGPtgTCJ9whxw4KYooY+R63BpWIgaWdkWwUgRI/p06Oe5rUO52kkyW9rLKE8zbNT31iGiQytbkHCGWVJSy7Yt6U7+UPFE0yDYbZcOOCqCVT1lw7wvG3T0TewbPOnxVXQGXCedfMj6RBWrBxdmTSOT4ffXGCTbLF8g8McuLoWNy+wf17xzM1yqJ2Duw6zM6X91N3PMDqUGTdKunm+R17I+mJUgmo2Pv5cJLNxpZhRm32F1NNRSoT3y9C/3+U64JMG+5RueshSDSKDHfSbu3I7Sx3L0Xg/o7zrx8lEPocTtnSIQ2cdf6sSJRYrjvO0vLixCaLUC+fzHnsPrZgw+yE3+X3OxF02Z7kGTWi9Plo6qrhD5tfZ+b8yUuThHELw3B7ZLy43xlCa28dPcMtEYd8mFyvMhtLbKddWRuMCgDx+XysvGqIF594fcpz0Cpc73D7nIaIgMrGGmLJ8AeKItnOk5FO4IjP5+Oac4b51qOOqd2rgAK4YcUogTya8FKRysR3f+j/d9z7RcRH9NpQ71iiTeypBVRkfagEnVyUBuXWyFw+o57BZl5+eiczR1qj7P3TlSoFnPxjMFnrc9PQXsXe7QeZOb8lqX1/zuJ2fvfIa5E8dtki1uTROKOKdR85K64v0M2SS4UDu99m59b9HDl4vOBNfNNNUZGP+fFMd/mWUB6oba6gvq0qZ5OkC30V5tNW7uhyVgbdwSHev68ijg+rKljCkRPTk8nD6zyojwF/D7gD3vcA8XPSv5Nwa1Cu3f4EEV4d/Y289OQO5iWYbOkWXMWlAYZW91AT4wAeWNbFrNG2yMgpHB1X6sHnkCvCZsZkkW3dg800dtakjISadVYb3aG5LNlkkg+KxJOr3bTMrKNlZl0kQtM0qMwoQPkEOAE2ExMT7HvjUGQ+Vyb0DDVPsgpMNQgk53holLePT024XLdsZNoEtdcYwf8GrAM+C3wOZ5Jt8gk47xCi2jdBwISbmqYKLv7E4oSRLLEPdLx1ZYr80Wr9kkuFXa8coCPLs+fTIZyNORBHgxo+bya7tu4nWFniyRwBSQJEpkAyp7EXIqvUmgaVEbla82eqFBX56Dt7Bn1nT+175q+Jk7nhHfyoXL5gLptfeYPepsTh7V4o8vmmbXTiNdXRm6r6G2AL0KKqfwuszF2xpgcvJj6IH2Y5lc4vWFFC92Bz1pLIZkLYBu/2p4WZOdzCkvf0T3sHlcgc65WwOdU0qAwpTPmUU6Zbg+oZak6a9ikcXRgv0KSjrprLRvspCWR/sJgvvGpQYyJSB7yIk23858A7t9Yuoud5nN5MJqDisfDCOWx5aCs9Q82pTy5AFl08h23P7Sno8k9Vg+oZbGb3qwfoGU4cVGEkZroHKNNBroMkUhFXq3PRPdhMXUtl+pPe3yF4FVDfAP4Vx7S3RUTeC6SdQaIgSTNIIhGtvXVc8NEp2himkYqaYMLw7kIhygeVgYBq66tn458upDgH5sczgTNQPk27gEqFz+ejpjl3ufCmG6/LbXwbOF9V3wTOAf4a+GAuC5YvEo0K0xVQRu5JkNQgLUw4Zc6ZpEGFE+02duYnO7gRn5QalIhUAlcBQyJyBCfz+N2qmrt1fvNIVIyEz0kvs3/n4Wn1BxnxcbdJPtOtGCHOoJ983vIuZFF7wknLRn5IqiaISB9OJvP3AeF8+h8BVESmvqhNIRAjoZZ/YB4X3bxo2opjJGaqJj5japxJGpTPlzh5rZE/UrXAF4C/VNXvu3eKyJ8AfwdcmauC5Y2YuTU+nw9/4Mx5Ed9pLL18gL3b3spKEk/DG+HEyYaRb1IJqGFVvTp2p6reKSI356hMeeUMGhS+Kwgv+Gfkj/XXj0bmyRlGPkkloJINmwo7vMUj0dkJTFoZRiz+QJEFDRnTQqqn7l0hhLxi8skwDKNwSKVBdYSWX49He4L97yh8sWF8hmEYRkGQSkD9Y5JjX8tmQaYNE0qGYRgFSarlNr6Qr4JMF9mY/GkYhmFkH/N8urAgCcMwjMLhjBdQiZLFGoZhGNPLGS+g3Jh8MgzDKBy8rqhbBlwKRC06oqrvjkCJMGbiMwzDKBi8Jpu6H6gFXnHtm+DdEskXwuSTYRhG4eBVQLWr6tyclqQQMAllGIZRMHgVUM+KSKuq7pzqDUPmwu8DzcAh4MOquifmnJ8CDcAYcFRVN0z1vl4w8WQYhlE4eBVQ9wAviMizOEIDAFU9dakM4AAACV1JREFUL4N7fhx4VlU/LyJXAp8DPhlzTh8wT1Xzm2rJJJRhGEbB4FVA3Qp8EXg5C/dcBnwptP0A8N/dB0WkBcffdb+I1AL/U1X/NQv3TYnNgzIMwygcvAqot1X1S6lPiya0btSnYnbvAt4KbR8CamKOlwC3AbfjRA0+JiKbVXV3uvdPF5NPhmEYhYNXAfWQiNwE3AccD+9U1TeTXaSqdwJ3uveJyH1AVehjFXAg5rKdwB2qehLYLSJPAwLkXEAZhmEYhYPXibqfBr4KvA7sDf3tSXpFYh4DNoa2NwCPxhxfC9wNICKVwCDwfIb3Sgsz8RmGYRQOnjQoVS3L4j2/DnxHRH4JnACuAhCRLwE/UtUHRGS9iDwOjOMsOb83i/dPjMknwzCMgsFrJonL4u1X1fvSvaGqHgGuiLP/z13bt6T7vdnANCjDMIzCwasP6s9c2yXAMPAIjk/KMAzDMLKOVxPfavdnERkAPp+LAhmGYRgGZJjNXFWfA/qzXBbDMAzDiJCJD8oHLABO5qREhmEYhkFmPqgJnBDzD2e/OIZhGIbhkJEPyjAMwzByjVcTXytORojZOLn0vgdcq6o7clg2wzAM4wzGa5DE14CfAEeB/cAW4Fu5KpRhGIZheBVQPar6TWBcVcdU9TNAVw7LZRiGYZzheBVQ4yISOVdEqtK41jAMwzDSxquQuQ+4C6gRkY8B/04ooathGIZh5AKvUXxfFJFNOAJtHfAN3kU+qLPOn8XYcZvWZRiGUUh4jeL7rqpegxO9966ja6BpuotgGIZhxODVxDciIpbq2zAMw8gbXjNJvAH8PrRG0+HwTlX9RE5KlR5+gJ07d053OQzDMIw0cfXd/thjXgXUr0N/hUgbwNVXXz3d5TAMwzAypw142b3DNzEx4elKESkD+oDfA8HQwoPTjoiUAguBHcCpaS6OYRiGkR5+HOH0hKoedx/wJKBEZDHwY5wM5ucCvwUuVtVfZb+shmEYhuE9SOJ/AWuBfaq6HdgE3J6zUhmGYRhnPF4FVHlokUIAVPX/4t1/ZRiGYRhp41VAjYlIHc5aUIiI5K5IhmEYhuFdC/ob4BGgVUR+AJwPfDRnpTIMwzDOeNKJ4uvDSXPkB36hqs/nsmCGYRjGmU06AqodaAYiGSVU9alcFEpEHgZuVNUXEhx/FehX1WOufWtwNL0xYDdwjaoeEZFbgQtxIhBvUdXNrmv+wamG3hH6/BVgKXAodMqlqvpWdmsXn1R19nB9DfB9oBooAT6tqr8WkSU4AS0ngQdV9QuuaxYDf6eqq0Kfm4FvAnU4A5FrVDVqXkKumMY23wDcGjr8FHCTqnp7KaZIgbT5D4HW0OEe4HFVvTKjCqVX9ofJc3uLyAjwZddtlgDvUdV/y2bdElEg7T0C3BE69w/A9ao6nnGlcownH5SI/A3wEk5W83tDfz/KYbky4Ws4D9sK4EXgehEZBVYCi4ErgX8EEJEmEXkAuCTmO0aB9aq6KvSXF+GUJT6No9muBK4lVFech/EqnJWQF4d+E0Tkz3ES/gZd3/El4K7Qb/g5oD8/Rc+YKbV5aNmYvwcuUtUlwKtAY15rMDWm3OaqemWo83ovcAD4VL4KnwFTam9V3RJ+t0Pn3Zcv4ZQlsvGO3wr8laouA0pxBHvB4tUH9SGcRQt35bIwsYjI54GdodFPP3BHeCQQh1Wu8gWAYzgN9mBoRPxHEQmISBNQCXwe2OC6VxHOkvbfEJEW4E5V/XYOqpUUEekAvo7zUDXgPEw/EZFncPyAwzjBKrHa3T8A4UluAeCYiFQDpWEtSER+BqzB0RReBi4jOgHwUuAZEXkIp7P+ZE4qmYR8tjnOnL5ngdtEpBf4lqruyXadUjHNbR7mC8BXVXVHtuuXjDy3d/ieFTj1XZHNunhlmtv7aaA+lFu1CkcbLVi8RvHtybdwSpfwiyUi7wVWA9/FUYXdDXwIqFHVV1T1NzFfUQF8FUcYXwD8qYgM57zgk+kHblPVdcDNwE2h/dXAD0Kjp9eJefFU9YCqHhWRVhwzwF+ErjnoOu0QUBM6/14mP5w9wH5VXQv8EfhMFuuVdbLQ5o2h6z6D83veIiJzcl7wyUxnm4dNu2uAf8pinbJOFto7zJ8A96jq3lyWNwnT2d4vAl8BngdagIezV63sk1RAichoSF18WkRuF5HF4X1hNTJbiEiliBS7dsX6AVJmUxeRTwH/FbggZLs+iDNKCFOFY8aIxxHgdlU9oqqHcBZlnO+1/JmQoM47gI+JyPeAGwH38adD/7cRrbaHv28I+AXwl6r6COnVH2Af8NPQ9v3AAu+1SZ8CaPN9OOlVdqrqYeD/ASNey58JBdjmAJcD/1tVc5oqrADaO8zV5Gk9uwJs79uB5arajyPgb0uvRvkllQYV9jetw7Hl/pDc+aC+AywLmdqagT04Knxb6HhSgSginwWWA2tdI6PHgPUiUiQiXUBRklHTHOCXIuIPPVDLcNTkXBKvzn8NfFdVNwH/QfRLm9B5LyIDwD3AVar6AICqHgROiMiskEq/Hng0SXl+CWwMba/AybuYS6a7zZ8EBkWkUUQCOE7z5xKcmy0Krc3ByRLzQIb1SYfpbu9woEGpqm6bWlU8U2jt/SanNa43cAKiCpakPihVnQmOzVSdFEcRRGRelstyG47qeQz4J1V9U0T+GbhbRFbgdCZxCfmMbsURKA+IM4/4n1X16yLyKE4m9iJOq9KTUNXnReQu4HEctfi7qprrDjpene8BviIiO3FGUV6d9v8DZ8R1e6j+b6nqpTgjtLtwovIeTGL2APgvwLdE5OM4ZpOrMqhTOkx3m+8Rkb8Afhbadbeq/i4L9UpGobU5gABb065J+kxre4eYg+NfzReF1t7XAz8UkZPACeCGDOqUN5KGmYtIfWjzP4BVOJJ+AifE8ZGQmmgYhmEYWSdVFN8PcMx74Njrw5yk8MLMDcMwjHcRXpfb+LaqfiQP5TEMwzAMIHUUXxdAPOEkIhfkqlCGYRiGkSqK7yfhDRG5N+bYF7NfHMMwDMNwSCWg3OGPvUmOGYZhGEZWSSWgJhJsx/tsGIZhGFkjHQ3KMAzDMPJGqjDzInFW0vUBftc2OJPCDMMwDCMnpBJQQ8BeTgsl91woM/EZhmEYOcPzgoWGYRiGkU+8LrdhGIZhGHnFBJRhGIZRkJiAMgzDMAoSE1CGYRhGQWICyjAMwyhI/j/uobKMJCTqAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e3a1efab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2,1)\n",
    "ax1.set_xticks([datetime.date(i,j,1) for i in range(2013,2019) for j in [1,7]])\n",
    "ax1.set_xticklabels('')\n",
    "ax2.set_xticks([datetime.date(i,j,1) for i in range(2013,2019) for j in [1,7]])\n",
    "ax2.set_xticklabels([datetime.date(i,j,1).strftime('%b %Y')  for i in range(2013,2019) for j in [1,7]])\n",
    "ax1.plot(dataset_df[dataset_df['Date'] < split_date]['Date'].astype(datetime.datetime),\n",
    "         dataset_df[dataset_df['Date'] < split_date]['btc_daily_ret'], \n",
    "         color='#B08FC7', label='Training')\n",
    "ax1.plot(dataset_df[dataset_df['Date'] >= split_date]['Date'].astype(datetime.datetime),\n",
    "         dataset_df[dataset_df['Date'] >= split_date]['btc_daily_ret'], \n",
    "         color='#8FBAC8', label='Test')\n",
    "ax2.plot(dataset_df[dataset_df['Date'] < split_date]['Date'].astype(datetime.datetime),\n",
    "         dataset_df[dataset_df['Date'] < split_date]['eth_daily_ret'], \n",
    "         color='#B08FC7')\n",
    "ax2.plot(dataset_df[dataset_df['Date'] >= split_date]['Date'].astype(datetime.datetime),\n",
    "         dataset_df[dataset_df['Date'] >= split_date]['eth_daily_ret'], color='#8FBAC8')\n",
    "ax1.set_xticklabels('')\n",
    "ax1.set_ylabel('Bitcoin Daily returns ($)',fontsize=12)\n",
    "ax2.set_ylabel('Ethereum Daily returns ($)',fontsize=12)\n",
    "plt.tight_layout()\n",
    "ax1.legend(bbox_to_anchor=(0.03, 1), loc=2, borderaxespad=0., prop={'size': 14})\n",
    "# fig.figimage(bitcoin_im.resize((int(bitcoin_im.size[0]*0.65), int(bitcoin_im.size[1]*0.65)), Image.ANTIALIAS), \n",
    "#              200, 260, zorder=3,alpha=.5)\n",
    "# fig.figimage(eth_im.resize((int(eth_im.size[0]*0.65), int(eth_im.size[1]*0.65)), Image.ANTIALIAS), \n",
    "#              350, 40, zorder=3,alpha=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e3a1f18ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2,1)\n",
    "ax1.set_xticks([datetime.date(i,j,1) for i in range(2013,2019) for j in [1,7]])\n",
    "ax1.set_xticklabels('')\n",
    "ax2.set_xticks([datetime.date(i,j,1) for i in range(2013,2019) for j in [1,7]])\n",
    "ax2.set_xticklabels([datetime.date(i,j,1).strftime('%b %Y')  for i in range(2013,2019) for j in [1,7]])\n",
    "ax1.plot(dataset_df[dataset_df['Date'] < split_date]['Date'].astype(datetime.datetime),\n",
    "         dataset_df[dataset_df['Date'] < split_date]['btc_volatility'], \n",
    "         color='#B08FC7', label='Training')\n",
    "ax1.plot(dataset_df[dataset_df['Date'] >= split_date]['Date'].astype(datetime.datetime),\n",
    "         dataset_df[dataset_df['Date'] >= split_date]['btc_volatility'], \n",
    "         color='#8FBAC8', label='Test')\n",
    "ax2.plot(dataset_df[dataset_df['Date'] < split_date]['Date'].astype(datetime.datetime),\n",
    "         dataset_df[dataset_df['Date'] < split_date]['eth_volatility'], \n",
    "         color='#B08FC7')\n",
    "ax2.plot(dataset_df[dataset_df['Date'] >= split_date]['Date'].astype(datetime.datetime),\n",
    "         dataset_df[dataset_df['Date'] >= split_date]['eth_volatility'], color='#8FBAC8')\n",
    "ax1.set_xticklabels('')\n",
    "ax1.set_ylabel('Bitcoin Daily Volatility ($)',fontsize=12)\n",
    "ax2.set_ylabel('Ethereum Daily Volatility ($)',fontsize=12)\n",
    "plt.tight_layout()\n",
    "ax1.legend(bbox_to_anchor=(0.03, 1), loc=2, borderaxespad=0., prop={'size': 14})\n",
    "# fig.figimage(bitcoin_im.resize((int(bitcoin_im.size[0]*0.65), int(bitcoin_im.size[1]*0.65)), Image.ANTIALIAS), \n",
    "#              200, 260, zorder=3,alpha=.5)\n",
    "# fig.figimage(eth_im.resize((int(eth_im.size[0]*0.65), int(eth_im.size[1]*0.65)), Image.ANTIALIAS), \n",
    "#              350, 40, zorder=3,alpha=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e3a1efa588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD3CAYAAADfYKXJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl01fWd//Hn3XKzLxCSkAUiIF8YF0RxpbiAuJ0uFqtDXX6jttN6OvbX2s50xs5ix+MwM6fLz1Z/6kxbftrWOq1b27GtUrFaRVBGUUDNB4JsIYQQyELWm7v8/ri5MSJJbpL7vd+7vB7ncEJyb773zT3wyof3Z/m6IpEIIiKSmtxOFyAiIqNTSIuIpDCFtIhIClNIi4ikMG8iL2ZZlh84GzgIhBJ5bRGRDOYBZgKbjTEDIx9IaEgTDeiXE3xNEZFssQx4ZeQXEh3SBwEeffRRqqqqEnxpEZHM1NLSwg033ABDGTpSokM6BFBVVUVtbW2CLy0ikvE+0ibWxKGISApTSIuIpDCFtIhIClNIi4ikMIW0iEgKU0iLiKQwhTQQDkfo7R90ugwRkY/I+pAOhsLc9Z8bufnudexq6nC6HBEZsnnzZhoaGgBYunRpwq//2muvcccdd4z6+MDAAI8//jgATz31FOvXr//Q99x+++0AGGPYvHlzwuuLyeqQjkQi/MfT23hr52H6BoL8y8Ov03FsYPxvFBHbPfnkk7S2tjr2+ocPHx4O6VWrVrFixYoPPX7//fcDsG7dOhobG22rI9E7DtPKbzfs5tmNezipupglCyt5fP1O/u0nm7nntgvwerL655dksbX//Q4b3j6Q0GsuXVTDrZ84ZdTHBwcHueuuu9i7dy/hcJiVK1fy8ssv88477zBv3jwCgQBf//rXaW5uprS0lB/84Af4fL6PXKehoYE1a9bwk5/8BIAvfvGLfOUrX6G9vZ17770Xv99PaWkpa9as+dD3/exnP2PdunUEg0GKioq47777eOihh2hsbOT+++8nEolQXl7OnDlzPvgzLV3KU089xdNPP43P5+OUU07h7rvv5oknngDgq1/9Krfeeiunn376lN67rA3prp4AP/7NdkoL/fzDrecyozSPA4e7eXXrQZ55ZTdXXzTX6RJFssbjjz9OWVkZa9asob29nRtvvJFly5Zx1VVXUV1dTW9vL3fccQe1tbXcdNNNvPfeeycMvwULFjAwMMCBAwfw+Xy0t7ezcOFCVqxYwWOPPUZlZSWPPPIIDz74IBdffDEA4XCYjo4OHn74YdxuN5/73OfYtm0bt912Gzt27OD222/nvvvuO2HdlZWVfPrTn6a8vJzTTz+d3NxcGhsbKS8vp6mpacoBDVkc0jv2tRMMRbji/HoqyvIB+KvPnMFr21v44xv7FdKStW79xCljjnrtsGPHDt544w22bt0KQDAYpKPjgzmikpKS4fOAysvL6evrG/Van/nMZ/jVr35FTk4Oq1ator29ncLCQiorKwE4++yz+d73vjcc0m63G5/Px9e+9jXy8/NpaWkhGAxO6s9x7bXX8tRTT1FdXc0nP/nJSV3jeFkb0mZvOwDW7LLhrxUX5LDYquB/3jtEU+sxaiuKnCpPJKvMmTOHqqoqbrvtNvr7+3nwwQdpbW0ldqNsl8sV97Wuuuoqbr75ZlwuF2vXrqWgoIDu7m5aW1upqKjg9ddfp76+fvj5DQ0NPP/88zz++OP09fWxatUqIpEIbrebcDg87uu5XK7h511xxRWsXbuW0tJSvv/970/sTRhF1jZed+yLhvTJdaUf+vqFi2sAeHlLYntyIjK61atX8/7773PjjTeyevVqampqWLRoEd/5znfYtWvXhK5VUFDAggULmDt3LoWFhbhcLu655x6+/OUvs3r1ajZu3MiXvvSl4efPnj2bvLw8Vq1axS233MKMGTNobW1l+vTpDA4O8u1vf3vM1zv11FN59NFH2bRpE36/n7PPPpvp06dTWlo65vfFyxX7SZUIlmXVA7vXr1+f0keVRiIRrv/H31OY7+OH31z5ocd6+we56a5nqZiWzwPfWD6hn+AiIt/61re4/PLLOf/88+P+nqamptjqkZOMMXtGPpaV7Y6DbT109w1y5oKKjzyWn+vj7D+rYsPWZnY3dzGnpsSBCkVkLFu3bj3hCPfKK6/k+uuvd6CiqFtvvZWKiooJBfR4sjKkzVCrw5pVdsLHly2uYcPWZv60pUkhLZKCTj/9dH760586XcZHrF27NuHXzMqe9I6hScP5s08c0ksWVpLn9/Lqto/cyUZEJKnGHUlbluUDHgHqid7a5S+NMQ0212Urs68dr8fFnOoTj5L9Pg+nzS3n9XdbONLZx/SSvCRXKCISFc9I+irAa4y5ALgb+Bd7S7JXYDDE7uZOTqouIcfnGfV5p8yZDsD2XUeSVZqIyEfEE9I7AK9lWW6gGEjr4+Leb+4kGIqM2o+OOXXuUEi/r5AWEefEM3HYTbTV0QCUAx+3syC77dwX3cU0Wj86Zm5NCXl+D++835aMskRETiiekfQdwHPGmPnAIuARy7Jy7S3LPi1HegCorSgc83kej5uF9dPZf6hbJ+OJiGPiCel2oHPo90cBHzB6MzfFHe6I7vkvLx1/MjDWl35nt1oeIuKMeEL6/wBnWpb1MvAC8E1jTI+9ZdmnraMPr8dNSYF/3OcOh7T60iLikHF70saYbuC6JNSSFG0dfZSX5uJ2j7/de/6sUnK8brbvUl9aRJyRVZtZBoNhOroH4mp1APi8HqzZ09hzsIvu3oDN1YmIfFRWhfSRzj4ikfj60TGnzJlOJAINQ7sURUSSKatCum1o0nDGBEL65FnR4wYbdZNaEXFAVob0REbS82qHQnq/QlpEki+rQnoiy+9iphXnMq04VyNpEXFEVoX0ZNodEB1NH+nsp/1Yvx1liYiMKstCOhqyExlJA8yrjZ6Wt6upc5xniogkVpaFdB/+HA+Feb4Jfd/cOk0eiogzsiqkD3f0UV6SN+H7FmryUESckjUh3R8Icqw3MOF+NMQmD/0aSYtI0mVNSB/pnFw/OmZebZkmD0Uk6bImpNvaJ778biRNHoqIE7ImpCezRnokTR6KiBOyJqTbOie3RjpGk4ci4oTsCenYRpayyYV0WZGfksIc9rZ0JbIsEZExZU1IT7Xd4XK5mF1VTMuRXvoGgoksTURkVOMe+m9Z1s3AzUOf5gJnAFXGmLT6f39bRx8FeT7y/PHce/fE6quL2drYxt6WLhbMnpbA6kRETiyeO7M8DDwMYFnW/wXWpltAA3QcG2Ba8fi3zBpLfVUxAHuaFdIikhxxtzssy1oCnGKM+U8b67FFKByhuzdAcRz3NRxLfXU0pPceVF9aRJJjIj3pbwL/bFchduruDRCOQHFBzpSuU1dZhNsFuxXSIpIkcYW0ZVmlwAJjzB9trscWXT3R+xNONaRzc7zMLC9g78EuIpFIIkoTERlTvCPpC4Hn7SzETokKaYD6mSV09w0ObzMXEbFTvCFtAe/bWYidunoGAKbck4YP+tJ71PIQkSSIaz2aMebbdhdip0SOpGdXfRDSSxZWTvl6IiJjyYrNLIkM6ZOqP1iGJyJit6wK6ZLCqYd0RVk+eX4Pew7qNDwRsV9WhHRnd+J60m63i1lVxTS1djMYDE/5eiIiY8mKkE5kuwOifelQOELz4e6EXE9EZDRZE9I+r5vcHE9Crje7qgiAfS3HEnI9EZHRZE1IlxTkTPgGtKOZNRTSew9p8lBE7JUlIT2QkH50zKyhZXgaSYuI3TI+pAODIfoGQgnrR0P0BgCFeT726QYAImKzjA/pY72JnTSE6A0AZlUVcbCth8BgKGHXFRE5XsaH9PDKjgSskR5pVlUx4Qgc0AoPEbFRxod0ItdIjzSrcmjyUH1pEbFRxod0otdIx8waXoanvrSI2EchPUmztcJDRJIga0I6Eed2jFRa5Ke4IEchLSK2yviQtqsnDdGWR8vRHvoDwYRfW0QEsiCk7Wp3QHTyMBKBplat8BARe8R16L9lWXcCnwRygAeMMT+2taoEioV0Ub4NIT2iLz2vtjTh1xcRGXckbVnWxcAFwFLgIqDO5poSqqsnQEGuF5838f9p0AoPEbFbPCPpy4FtwNNAMfA3tlaUYIk+t2Ok2FrpfYc0eSgi9ohneFkOLAGuBW4DHrUsKzHHydksEonQ1ROwpR8NUFLop7TQrw0tImKbeEL6CPCcMSZgjDFAPzDD3rISo28gSDAUocimkIZoy6P1aC99A1rhISKJF09IvwJcYVmWy7KsaqCAaHCnPLvWSI8U60vvV8tDRGwwbkgbY54BtgCvA/8N/JUxJi2OfrNzjXSMzpYWETvFtQTPGPMNuwuxw7HeQQCK8n22vYYmD0XEThm9mSV2lrQda6RjZmsZnojYKKNDuntoJF1o40i6MD+HacV+jaRFxBYZHtJDI+k8+0bSALMqiznc3kdv/6CtryMi2SezQ7ovGpoFNo6kYcTOQ42mRSTBsiKk7exJg1Z4iIh9MjqkYxOHhXn2jqQ/mDxUSItIYmV0SHf3DuJ2u8jPjWul4aTVVWqFh4jYI7NDui9AQa4Pl8veo0YK8nyUl+SqJy0iCZfZId07aOvyu5FmVRVzpLN/uA8uIpIIGRvSkUiEY72Dtu42HElnS4uIHTI2pAcGQwRDYQptXiMdM7w9XJOHIpJAGRvSydhtOJLWSouIHTI3pId6w3Yvv4vRCg8RsUPGhnQyDlcaKT/XR0VZntodIpJQGRvSyW53QHSFR/uxgeGbDYiITFUGh3Rst2FyRtIwcvJQLQ8RSYzMDek+J0bSmjwUkcSKa7+0ZVlbgM6hT3cbY26xr6TESNbhSiPN0hkeIpJg44a0ZVm5AMaYi22vJoGSdbjSSHUVCmkRSax4RtKLgHzLstYNPf+bxphN9pY1dT0OTBzm+r1UTstn3yH1pEUkMeLpSfcC3wEuB24DHrUsy95j5RJgeCSdxHYHwOyqYjq7A8N3KhcRmYp4QnoH8DNjTMQYswM4Asy0t6yp6+4bxOd14/d5kvq6sb70Xq3wEJEEiCekbwW+C2BZVjVQDBy0s6hE6E7i4Uoj1c+M3qVlT7NCWkSmLp6Q/jFQalnWK8AvgFuNMUF7y5q67r4ABUlcIx1TXz0U0gcV0iIydeP2lo0xAeD6JNSSMOFwhO6+weHzNJKpZkYhXo+b3QppEUmAjNzM0jsQJBJJ7m7DGK/HzazKIvYd7CIUjiT99UUks2RkSA9vCXegJw3RlkcgGOZgW7cjry8imSNDQzr5a6RHGp48VMtDRKYoI0M62ceUHk8rPEQkUTIypJN94P/xtMJDRBIls0PaoZF0WVEupYV+rfAQkSnLzJB24HCl49XPLKb1aC89Qz8wREQmI0NDOnZMqYMhrZaHiCRARoa0U4crjXSSQlpEEiAjQ9rpiUOA+pklAOxu7hznmSIio8vMkO51PqTrKgvxely8f0AhLSKTl5kh3Rcgz+/F43Huj+fzepg9s5g9B7sIhsKO1SEi6S0jQ/qYQ8eUHm9ebSmDwbBupyUik5aRId3TF3DkcKXjza0tBaCxqcPhSkQkXWVcSAdDYfoGQo6d2zHSvNro5KFCWkQmK+NC2unDlUaqn1mM1+Nil0JaRCYprhvKWpZVAbwBrDTGNNhb0tQ4fbjSSD6vh1lVxexujk4eeh2cyBSR9DRualiW5QP+A+izv5yp60mBNdIjza0pYTAYZv8hTR6KyMTFM7T7DvAQ0GxzLQnh9OFKx5tXF508VMtDRCZjzJC2LOtm4LAx5rnklDN1x1LgcKWR5g2v8NCmFhGZuPFG0rcCKy3LehE4A/iJZVlVtlc1BR8crpQaI+n6mcV43C6t8BCRSRlz4tAYc2Hs90NBfZsxpsXuoqYiFY4pHSnH52FWVRG7D3QSCoUd3QUpIukn4xLjg550aoQ0wPxZZQSCYXbrdloiMkFxh7Qx5uJUX34HqXFM6fEW1k8D4N09RxyuRETSTeaOpFOk3QGw8KRoSL+3+6jDlYhIusm8kO4dxO12kZ8b1z6dpJg5vYDSQj/v7TlKJBJxuhwRSSOZF9J9AQpyfbhcLqdLGeZyuVh40jSOdPZzuCMt9gSJSIrIuJBOlWNKjxfrS6vlISITkVEhHYlE6O4dTKmVHTHDIb1HIS0i8cuokB4IhAiGwim1siNmbm0JPq9bI2kRmZCMCulUXNkR4/N6OLmulD0HO+ntH3S6HBFJExkV0ql0TOmJLKyfRjgCZm+706WISJrIqJBO5ZE0wJ/NmQ7A9ve1qUVE4pNZId2bWseUHu/UOdPxuF1sMa1OlyIiaSLDQjq1Dlc6Xn6ujwX102hs6qCrJ+B0OSKSBjIrpPtix5SmZkgDnGlVEInA2zsOO12KiKSBjArpVDxc6XiLrRkAbNmhloeIjC+jQjrVJw4B5taUUpSfw5umVed4iMi4Miuke1PvLOnjud0uFs+fwZHOft2cVkTGlWEhnfrtDoDFVgUAW9SXFpFxjHuep2VZHuCHgAWEgFuMMbvsLmwyjvUNkuN14/d5nC5lTLG+9JsNrXzqwrkOVyMiqSyekfQnAIwxS4F/Ar5na0VT0JOihysdb3pJHnOqS9ja2DbcRxcROZFxQ9oY8yvgC0OfzgYO2VrRFBzrDaR8qyNm6aJqgqEwr20/6HQpIpLC4upJG2OClmU9AtwHPGFvSZMTDkfo6R9M6ZUdI31sUTUAr7zd7HAlIpLKJnIj2r8A5gM/tCyrwL6SJqe3f5BIBArz0mMkXT2jkDk1JWwxrcMTniIixxs3pC3LusmyrDuHPu0FwkQnEFNK59A265LC9AhpiI6mQ+EIm9TyEJFRxDOSfgpYbFnWn4DngK8aY/rtLWviOo4NAFBS6He4kvh9bFENAC+r5SEioxh3CZ4xpge4Lgm1TElXTyyk02ckPbO8gHm1Jby94zBdPQGKC9KndhFJjozZzNLZHWt3pM9IGmDZGbWEwhFefHO/06WISArKnJCOjaQL0iukV5xdh9fj4tmNe3SWh4h8ROaE9NBIujiN2h0QHflfcFo1+w91847u2CIix8mgkI6OpEvTrN0BcMUF9QA8u3Gvs4WISMrJmJDu6k6/JXgxp86ZTm1FIRu2Ng//sBERgQwK6Y7uAfL8Xnze1D5c6URcLhdXnl9PMBTm+df3OV2OiKSQjAnprp6BtBxFxyxfUoc/x8Mzr7zPYDDsdDkikiIyIqQjkQhdPYG0W343UmF+DpefO5u2zn5eerPJ6XJEJEVkREj39AcJhiJpt/zueJ+6aC4et4unXtxJOKzleCKSISEdm2xL53YHQEVZPhedWcv+Q91sfrfF6XJEJAVkWEin90gaYNUl8wB44oWd2twiIpkS0um7/O54s6uKOefPqmjY287bO3UPRJFslyEhHR1JF6d5Tzrms5dbAPzs2QaNpkWyXGaEdBqegDeWebWlnH/aTMzedt5oaHW6HBFxUEaEdFeanoA3lusvX4DLBY8++55G0yJZLCNCergnnSHtDoD6mcV8bFENjU2dbNqulR4i2SpDQjqz2h0xn73Mwu2Cnz/XoHXTIllqzDuzWJblA9YC9YAfuMcY85sk1DUhnT3RcztyfOl3bsdY6iqLuOjMWv74RhMbtjaz7Iwap0sSkSQbbyR9I3DEGLMMuBK43/6SJq6zO5Bxo+iY1ZdZuN0uHlvXQEijaZGsM15IPw7844jPgzbWMinRczsGMqofPVJ1eSErltSx/1A3L2/RmR4i2WbMkDbGdBtjjlmWVQQ8AfxDcsqKX+zcjnS7I8tE/PlKC6/HxWPrDKGQTsgTySbjThxallUH/BH4qTHm5/aXNDFdaXxHlnhVTstn5TmzaW7r4Y9v6Ia1ItlkzJC2LKsSWAf8rTFmbXJKmpjhexsWZO5IGuC6S+fj87p57A87dN60SBYZbyT9TaAM+EfLsl4c+pWXhLri1pFBhyuNpbw0jyvOr6f1aC/Pb9bdW0SyxZhL8IwxXwG+kqRaJqWrJztCGuDa5Sfz3Ka9/PIPhhVL6jJuyaGIfFTab2ZpP5b5PemYsuJcPr70JNo6+/n9xj1OlyMiSZD2IX24vQ+AGWUp1YWxzTXLTyY/18svn99Bb/+g0+WIiM0yIKR7AZhRmh0hXVyQw6pL5tHVE+DpF3c5XY6I2CztQ7q1vY+i/Bxy/WO21zPKp5bNpbTIz69eaqRjqN0jIpkprUM6EolwuKMva1odMbl+L6tXWvQHQjy2rsHpckTERmkd0l09AQKDISqyLKQBLj9vNjUzCnh24x72HOxyuhwRsUlah/QHk4b5DleSfF6Pm89/6jTCEfjhr7bpxgAiGSq9Q7ojuyYNj7dkYSVLFlaytbGNTdsPOl2OiNggvUN6aCRdkYUj6ZjPffIUPG4XP/rNO/QPpNwhhSIyRekd0h3ZtUb6RGorirj6orm0Hu3lkd+963Q5IpJgaR3SrVm2Rno011++gNqKQp55ZTfbGtucLkdEEiitQ/pwex9ejzsrzu0YS47Pwx2fPRO3C+79xRbtRBTJIOkd0kNrpN1ul9OlOG7+rDKuWX4yrUd7ufe/tujGtSIZIm1DOjAYouPYQNa3Okb67GULOHXudDZuO8jPnn3P6XJEJAHSNqTbNGn4ET6vmzv/4hxmlhfw+Pqd/OG1vU6XJCJTlLYhreV3J1ZckMM/fe5cCvJ8/OCXb/HkCzu10UUkjcUV0pZlnWtZ1os21zIh2b6RZSy1FUX865eWMr0kl4d/+y4PPLmVgcGQ02WJyCTEcyPabwA/AnLtLyd+rVl2jvREnVRdwne/ciEnVRfz7MY9fOnf1/Pq1maNqkXSTDwj6V3AKrsLmahsPrcjXtNL8vj325dxzSXzONrVz78+spmvfu8lfrthN919WqYnkg7GPYTZGPOkZVn1SahlQmLtjnK1O8aU5/dy88dP4dJzZvHT37/Hpu0tPPTUVn706+0sOrmc80+byTmnVFFWlFL/URKRIWl7Un7LkV5KC/34dTPWuNRWFHHnX5zD0a5+1m/ex8tvHeCNhlbeaGjF9cTbLKyfxoWLa7nkrFryc31OlysiQ9IypLt7Axw62ssZ82c4XUramVacy7Ur5nPtivm0HOlh0/aDbNx2kPf2HOXd3Ud5+Jl3uOSsOq5ZfjKV09RKEnFaWob0rgOdAMyrLXW4kvRWNb2Aqy+ax9UXRXvWz7++j2c37eH3G/ew7rW9rDx3NqtXzmd6iVpKIk6JK6SNMXuA8+wtJX67mjoAmFtb4nAlmWNacS7XXTqfa5afzMtvHeCx5xp4duMeXvif/VxzyTxWXTwvq+4jKZIq0nIzS2OTRtJ28bhdXHxmLQ98Yzlfvu4MCnK9PLbO8MV/W8/6zft0JohIkqVlSO9q6qAgz6eeqY08HjeXnTubh/5uBdddOp/u3gD3/tcWvv79l9i+S8ehiiRL2oV0T98gzW09zK0pweXS6Xd2y8/1cdOVC3nw71Zw0eJaGps6ufOBDax5+HUOtvU4XZ5Ixku7JuP7mjR0REVZPn9941l8fNlJ/OjX29m47SCb3z3EJ5bN4bpL51OYp2V7InZIu5F049CkoULaGQtmT+PbX17G39x4FmXFfp5+sZEvrHmeJ1/YqXssitgg7UJ619Ck4dw6rexwisvl4sLFtTz4tyu46cqFhMNhHv7tu3x+zR94+sVG+gMKa5FESbuQbmzqID/XS9W0AqdLyXp+n4frLp3Pj/5+JatXWgwGw6z973f4yzXP89QfG3U+iEgCpFVI9/YP0tzWzdyaUt0yK4UU5udwwxUL+NHfr+TPL53PQCDE/3vmHW65+zkefPJtdu5v1+l7IpOUVhOHDXvaiUS0iSVVFeXncOOVC7n6ork8t2kvz2zYze9e3cPvXt1DzYwCLlpcy0Vn1VJdXuh0qSJpI61Cev3mfQCcf9pMhyuRsRTm53DN8pO5+qK5vNHQyotvNvHaOy38fJ3h5+sM82pLOGtBJWfMn4E1exo+b1r9h04kqdImpLt6Ary67SC1FYUsrJ/mdDkSB4/HzTmnVHHOKVX09g+yaXsLL73ZxNs7D9PY1Mkvnt9Bbo6H0+aVc9rccubWljCnplTL+URGSJuQfvHN/QRDYS47d7Y2saSh/Fwfy5fUsXxJHb39g2zfdYQtO1rZYg6z+d1DbH730PBzq6bnM7emlFlVRcwsL6BqWgGlRX5Ki/zk+DzEpiNC4QjBYJjg0MfcHI/OF5GMkxZ/oyORCOs27cXrcXHJWXVOlyNTlJ/rGx5hQ/QuO2bfUXY1dbKrqYPGpk42bG1mw9aJX9uf46G8JJd5tWXMn13KWQsqqZmhHrikr7QI6Z37O9jbcoylp1dTWuR3uhxJsBllecwoq+Fji2qA6A/lto5+mlqP0dzWQ+vRXjq6B+jqCRAYDBEaOuTJ53Hj8bjwetx4PW76BoJ09gzQcqSXl7Y08dKWJn7Iduoqi/jYomouOauOmeVauinpJeVDOhQK8/PnGgC47NzZDlcjyeByuYaCO4/F1sS/PxKJcLCth3d3H2HT9ha2mFYeW2d4bJ1hYf00Vpxdx9JFNep9S1pI6ZCORCI88ORW3mho5YyTZ+hOLBIXl8tF9YxCqmcUcuk5s+kbCLJxWzMv/M9+tja28d6eo/zH09s479SZLF9Sx+L5M/B4tMJEUtO4IW1Zlht4AFgEDACfN8Y02l1Y/0CQR59rYN1re5lbW8KdN5+tDSwyKXl+L8uXzGL5klm0tvfy0ptNrN+8n5ffOsDLbx2guCCHM+bPYPH8GcyrK6NmRgE+74fvnRkKhWlt76O5rZvmwz00t3XTcqSXYz0BuvsGiUQi5Pq9FOb5mFleQF1lEXUVRdRWFjKjNE+T3SNEIhF6+gY50tXP0c5++gMhfF43OT43JYV+Sgv9FOXn6N/7kHhG0lcDucaY8y3LOg/4LvCpRBfSHwiyc38HrUd72bGvnRffbKK3P8jM6QXc9fnzdHNUSYiKsnyuXTGfzyw/mZ37O1i/eR+btrfwpy0H+NOWAwC4XVBcGF1J4nG76O6NBfFHr+f1uCjMy8HlgvZj/fQNhNja+OHztvP8HmoqiqirKKSiLJ/y0jxKCv3k+T3k5ngyL1CHAAAFBElEQVTJ9XvJzfHgcbuJZfkHH124AGKf42K8vB9ZZ4QPffLh533oe068I/T4L4917YHBEP2BIP0DIfoCQXr7BjnaNcDRrv4PfnX2c6Srn8BgaMw/g8ftorTIT1mRn9Ki3KGPfsqKcikrjn4sLsjB43Hhdrmi75MrWkcwFGYwGP0VDIUZCIToHQjSHwjSNxCkrz9I39Dv+wdC0Y+BIF6PO7pCKMeLf+hjQZ6Xglwf+Xk+CnN95Po9+LwevB4XXm90LsQz9MMk+vzE51Q8If0x4FkAY8wmy7KWjPFcD0BLS8uEC/n+L7awbcRf7pJCP1ecWcMlS+ro6Wyjp3PClxQZU74bPnHudD5+zjSaD/fw3t6jNB/uprmth2M9nfT2hQmHwuTn5VBe7mN6cS4V0/KpLMunYloeFWUF5Pk9HxolDwbDtBztoeVwLwePRK/VcqSHnY1HeM+EHfzTOs/lguL8HMqL/JRW5FJa5Kek0E9ujpdQOEwgEOJYX4Cu7gCd3QN09vTSeDjAYHDsQE8VHo+Lu79wwaRuRjIiMz3HPxZPSBcDIyMyZFmW1xhzoqPOZgLccMMNE63xhN76DfwgIVcSEbHf9X+Y8iVmArtGfiGekO4CikZ87h4loAE2A8uAg0B6/PgTEXGeh2hAbz7+gXhCegPwCeCXQz3pbaM90RgzALwyySJFRLLZrhN9MZ6QfhpYaVnWq0SnL25JZFUiIjI6l875FRFJXVrBLyKSwhTSIiIpTCEtIpLCUvrsjuONt0Xdsqy/BL4IBIF7jDHPOFKog+J4j+4AVg99+jtjzD8nv0pnxXPUwdBzfgv82hjzUPKrdFYcf4+uBO4a+vRN4K+MMVk1wRXHe/TXwGeBMLDGGPP0ZF4n3UbSw1vUgb8jukUdAMuyqoD/DSwFLgf+1bKsbDzXdKz3aA5wA3ABcD5wmWVZpztSpbNGfY9GuAfI5lsAjfX3qAj4NvBxY8x5wB6g3IkiHTbWe1RKNI/OBy4D7p3si6RbSH9oizowcov6OcAGY8yAMaYTaASyMYDGeo/2A1cYY0LGmDDgA/qTX6LjxnqPsCzrM0RHP79PfmkpY6z36AKi+yW+a1nWy8AhY8zh5JfouLHeox5gL1Aw9GvSZwKkW0ifcIv6KI8dA7LxtuKjvkfGmEFjTJtlWS7Lsr4DbDHG7HCkSmeN+h5ZlnUqcD3wT04UlkLG+rdWDlwC/C1wJfBVy7LmJ7m+VDDWewTRQdG7RNtBkz7hIt1Ceqwt6sc/VgR0JKuwFDLmNn7LsnKBR4ee86Uk15YqxnqP/hdQA7wA3Ax8zbKsK5JbXkoY6z06Amw2xrQYY7qBPwFnJLvAFDDWe3Ql0W3eJwGzgKstyzpnMi+SbiG9AbgK4ARb1F8HllmWlWtZVgmwENie/BIdN+p7ZFmWC/g18LYx5ovGmGw9X2XU98gY8w1jzLnGmIuBh4HvGWOedaJIh431b+0N4FTLssqHRo7nER0xZpux3qN2oA8YMMb0Ex0wlk7mRdJqx+GI2dTT+WCL+lVAozHmN0OrO75A9IfPGmPMk44V65Cx3iOih7g8Bmwa8S13GmM2JrtOJ43392jE874FtGT56o7R/q2tBv5m6Om/NMb8uzOVOieO9+ifgSuI9qNfAb4xmRUwaRXSIiLZJt3aHSIiWUUhLSKSwhTSIiIpTCEtIpLCFNIiIilMIS0iksIU0iIiKez/A18TvV2Bvs7WAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e3a1ec68d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(dataset_df['eth_volatility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e3a351ea90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e3a1f19ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(np.log(dataset_df['eth_volatility']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e3a35892e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e3a354b080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(dataset_df['btc_volatility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e3a360e0f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e3a35fc240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(np.log(dataset_df['btc_volatility']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['eth_volatility'] = np.log(dataset_df['eth_volatility'])\n",
    "dataset_df['btc_volatility'] = np.log(dataset_df['btc_volatility'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks\n",
    "\n",
    "Benchmark -I: Price-Persistent model, assumes the close price is same as the previous day. Implies that the estimated daily returns and volatility are both zero\n",
    "\n",
    "Benchmark - II: Market-Persistent model, assumes the daily returns is same as the previous day. Implies the estimated daily returns and volatility are same as the previous day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: btc_volatility\n",
      "Benchmark-I: MAE 2.634264923378126\n",
      "Benchmark-I: MSE 7.188424481804465\n"
     ]
    }
   ],
   "source": [
    "## Price-PERSISTENT MODEL: Benchmark-I\n",
    "\n",
    "print (\"Predicting:\", target)\n",
    "\n",
    "# Evaluate on test dataset\n",
    "# no change from previous day => pred_bitcoin = 0 (percent change) for persistence model\n",
    "actual_target = dataset_df[dataset_df['Date']>= split_date][target].values\n",
    "# pred_target = 0\n",
    "\n",
    "bm1_mae = np.mean(np.absolute((actual_target)))\n",
    "bm1_mse = np.mean(np.square((actual_target)))\n",
    "\n",
    "print(\"Benchmark-I: MAE\", bm1_mae)\n",
    "print(\"Benchmark-I: MSE\", bm1_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark-II: MAE 0.4218536832328074\n",
      "Benchmark-II: MSE 0.2821991334719368\n"
     ]
    }
   ],
   "source": [
    "## Market-PERSISTENT MODEL: Benchmark-II\n",
    "\n",
    "# Evaluate on test dataset\n",
    "# same market behavior as previous day\n",
    "pred_target = dataset_df[dataset_df['Date']>= datetime.datetime.strptime(split_date, '%Y-%m-%d') - \n",
    "                      datetime.timedelta(days=1)][target][:-1].values\n",
    "\n",
    "bm2_mae = np.mean(np.absolute((actual_target-pred_target)))\n",
    "bm2_mse = np.mean(np.square((actual_target-pred_target)))\n",
    "\n",
    "print(\"Benchmark-II: MAE\", bm2_mae)\n",
    "print(\"Benchmark-II: MSE\", bm2_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>btc_Close</th>\n",
       "      <th>btc_Volume</th>\n",
       "      <th>eth_Close</th>\n",
       "      <th>eth_Volume</th>\n",
       "      <th>ltc_Close</th>\n",
       "      <th>ltc_Volume</th>\n",
       "      <th>xrp_Close</th>\n",
       "      <th>xrp_Volume</th>\n",
       "      <th>btc_close_off_high</th>\n",
       "      <th>...</th>\n",
       "      <th>ltc_30day_ret</th>\n",
       "      <th>xrp_close_off_high</th>\n",
       "      <th>xrp_volatility</th>\n",
       "      <th>xrp_daily_ret</th>\n",
       "      <th>xrp_7day_ret</th>\n",
       "      <th>xrp_30day_ret</th>\n",
       "      <th>btc_trends</th>\n",
       "      <th>eth_trends</th>\n",
       "      <th>ltc_trends</th>\n",
       "      <th>xrp_trends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>279.58</td>\n",
       "      <td>42484800</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>164329</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4192810</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>363643</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.020449</td>\n",
       "      <td>0.016459</td>\n",
       "      <td>0.016459</td>\n",
       "      <td>0.016459</td>\n",
       "      <td>29.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>261.00</td>\n",
       "      <td>58533000</td>\n",
       "      <td>0.753325</td>\n",
       "      <td>674188</td>\n",
       "      <td>3.85</td>\n",
       "      <td>4917730</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>678295</td>\n",
       "      <td>-0.969823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087678</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.066634</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-09</td>\n",
       "      <td>265.08</td>\n",
       "      <td>23789600</td>\n",
       "      <td>0.701897</td>\n",
       "      <td>532170</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3064680</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>531969</td>\n",
       "      <td>0.411945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.041372</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>30.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>264.47</td>\n",
       "      <td>20979400</td>\n",
       "      <td>0.708448</td>\n",
       "      <td>405283</td>\n",
       "      <td>3.95</td>\n",
       "      <td>2239890</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>472973</td>\n",
       "      <td>-0.155756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>-0.949686</td>\n",
       "      <td>0.018044</td>\n",
       "      <td>-0.007036</td>\n",
       "      <td>-0.007036</td>\n",
       "      <td>-0.007036</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-11</td>\n",
       "      <td>270.39</td>\n",
       "      <td>25433900</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>1463100</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3426300</td>\n",
       "      <td>0.008591</td>\n",
       "      <td>282461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053165</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.019998</td>\n",
       "      <td>-0.018284</td>\n",
       "      <td>-0.018284</td>\n",
       "      <td>-0.018284</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  btc_Close  btc_Volume  eth_Close  eth_Volume  ltc_Close  \\\n",
       "0 2015-08-07     279.58    42484800   2.770000      164329       4.21   \n",
       "1 2015-08-08     261.00    58533000   0.753325      674188       3.85   \n",
       "2 2015-08-09     265.08    23789600   0.701897      532170       3.90   \n",
       "3 2015-08-10     264.47    20979400   0.708448      405283       3.95   \n",
       "4 2015-08-11     270.39    25433900   1.070000     1463100       4.16   \n",
       "\n",
       "   ltc_Volume  xrp_Close  xrp_Volume  btc_close_off_high     ...      \\\n",
       "0     4192810   0.008152      363643            0.597015     ...       \n",
       "1     4917730   0.008476      678295           -0.969823     ...       \n",
       "2     3064680   0.008808      531969            0.411945     ...       \n",
       "3     2239890   0.008750      472973           -0.155756     ...       \n",
       "4     3426300   0.008591      282461            1.000000     ...       \n",
       "\n",
       "   ltc_30day_ret  xrp_close_off_high  xrp_volatility  xrp_daily_ret  \\\n",
       "0       0.036946            0.987805        0.020449       0.016459   \n",
       "1      -0.087678            0.147059        0.066634       0.038217   \n",
       "2       0.015625            0.914530        0.041372       0.038190   \n",
       "3       0.012821           -0.949686        0.018044      -0.007036   \n",
       "4       0.053165           -1.000000        0.019998      -0.018284   \n",
       "\n",
       "   xrp_7day_ret  xrp_30day_ret  btc_trends  eth_trends  ltc_trends  xrp_trends  \n",
       "0      0.016459       0.016459        29.0        62.0        69.0        78.0  \n",
       "1      0.038217       0.038217        33.0        35.0        42.0        64.0  \n",
       "2      0.038190       0.038190        30.0        42.0        45.0        70.0  \n",
       "3     -0.007036      -0.007036        32.0        38.0        45.0        67.0  \n",
       "4     -0.018284      -0.018284        29.0        40.0        48.0        59.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LSTM Begins\n",
    "symbols_ = [symbol+\"_\" for symbol in list(coin_symbol.values())]\n",
    "\n",
    "model_data = dataset_df\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Parameters\n",
    "window_len = 2 # 2 # 7 # 14 # 30\n",
    "\n",
    "training_set, test_set = model_data[model_data['Date']<split_date], \\\n",
    "                         model_data[model_data['Date']>=datetime.datetime.strptime(split_date, '%Y-%m-%d')-datetime.timedelta(days=window_len)]\n",
    "\n",
    "# we don't need the date columns anymore\n",
    "########### DONT'WE ?? - If we are to cross-validation, we need the dates!! or we just use the index?\n",
    "training_set = training_set.drop('Date', 1)\n",
    "test_set = test_set.drop('Date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['btc_Close',\n",
       "  'btc_Volume',\n",
       "  'eth_Close',\n",
       "  'eth_Volume',\n",
       "  'ltc_Close',\n",
       "  'ltc_Volume',\n",
       "  'xrp_Close',\n",
       "  'xrp_Volume',\n",
       "  'btc_trends',\n",
       "  'eth_trends',\n",
       "  'ltc_trends',\n",
       "  'xrp_trends']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_features = training_set.shape[1]\n",
    "\n",
    "# Columns to be normalized - Instead of traditional normalization aschemes (like MinMax on training_set), \n",
    "# normalize the columns w.r.t to the first element of the window s.t the normalized first element would be 0 \n",
    "# Reference: \n",
    "norm_cols = [[symbol+metric for symbol in symbols_ for metric in ['Close','Volume']]          \n",
    "             +[coin_symbol[coin]+\"_trends\" for coin in coins]]\n",
    "\n",
    "norm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_training_inputs = []\n",
    "for i in range(len(training_set)-window_len):\n",
    "    temp_set = training_set[i:(i+window_len)].copy()\n",
    "    for col in norm_cols:\n",
    "        temp_set.loc[:, col] = temp_set[col]/temp_set[col].iloc[0] - 1\n",
    "    LSTM_training_inputs.append(temp_set)\n",
    "\n",
    "# model output is next price normalised to 10th previous closing price\n",
    "LSTM_training_outputs = training_set[target][window_len:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "LSTM_test_inputs = []\n",
    "for i in range(len(test_set)-window_len):\n",
    "    temp_set = test_set[i:(i+window_len)].copy()\n",
    "    for col in norm_cols:\n",
    "        temp_set.loc[:, col] = temp_set[col]/temp_set[col].iloc[0] - 1\n",
    "    LSTM_test_inputs.append(temp_set)\n",
    "\n",
    "LSTM_test_outputs = test_set[target][window_len:].values\n",
    "\n",
    "print(len(training_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 2, 32) (895, 2, 32)\n"
     ]
    }
   ],
   "source": [
    "# ???  easier to work with numpy arrays rather than pandas dataframes\n",
    "# especially as we now only have numerical data\n",
    "LSTM_training_inputs = [np.array(LSTM_training_input) for LSTM_training_input in LSTM_training_inputs]\n",
    "LSTM_training_inputs = np.array(LSTM_training_inputs)\n",
    "\n",
    "LSTM_test_inputs = [np.array(LSTM_test_inputs) for LSTM_test_inputs in LSTM_test_inputs]\n",
    "LSTM_test_inputs = np.array(LSTM_test_inputs)\n",
    "\n",
    "type(LSTM_test_inputs)\n",
    "print(LSTM_test_inputs.shape, LSTM_training_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasRegressor\n",
    "def create_model(dropout, neurons, activ_func, optimizer):\n",
    "    # use default values\n",
    "    loss= 'mse'\n",
    "    output_size = 1 # TODO: Can we change this to 2 or even 4 (to predict all 4 at a time - {eth, btc}_{volatility, daily_ret})\n",
    "    \n",
    "    print (\"Start model: \", dropout, neurons)\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Add 3 layers of LSTM, followed by a dense layer\n",
    "    model.add(LSTM(neurons[0], return_sequences=True, input_shape=(window_len, no_of_features)))\n",
    "    model.add(Dropout(dropout))\n",
    "    # from keras.layers.normalization import BatchNormalization\n",
    "    # model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LSTM(neurons[1], return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(LSTM(neurons[2]))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    print (\"End compilation of model: \", dropout, neurons)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input shape:  (895, 2, 32)\n",
      "Train output shape:  (895,)\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 3s 19ms/step - loss: 12.7083\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 11.3515\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 9.1115\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 6.1768\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.7803\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 2.9385\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.5986\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.2771\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.4947\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.8769\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 2.0772\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 2.6460\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.8502\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.2757\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.5519\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "150/150 [==============================] - 0s 455us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=adam, score=-1.2505412277759322, total=  11.4s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.4 [10, 8, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 4s 13ms/step - loss: 14.7369\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 11.8758\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 5.7863\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 3.2314\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 2.7978\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 3.0226\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 2.6006\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 2.5842\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 2.4913\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.6473\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 2.4475\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.5146\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.5698\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.4647\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.1944\n",
      "149/149 [==============================] - 0s 3ms/step\n",
      "299/299 [==============================] - 0s 486us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=adam, score=-1.3007810058809768, total=  17.3s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.4 [10, 8, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   29.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 15.3574\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 9.0781\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.0170\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.7154\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.7841\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.6449\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.8232\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.8854\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.5431\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.7032\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.5736\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.2930\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.2556\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.2689\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.2372\n",
      "149/149 [==============================] - 1s 4ms/step\n",
      "448/448 [==============================] - 0s 486us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=adam, score=-0.6711374957289472, total=  21.5s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.4 [10, 8, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   50.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 4s 7ms/step - loss: 12.6167\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.8223\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.8593\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.2265\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.0674\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.6422\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.3959\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.5750\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 2.3072\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 2.3955\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.2398\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 2.0675\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 1.9904\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 1.9994\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 2.0796\n",
      "149/149 [==============================] - 1s 4ms/step\n",
      "597/597 [==============================] - 0s 448us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=adam, score=-0.34117556291776113, total=  26.5s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.4 [10, 8, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 10.7920\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 3.2136\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.8554\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.4575\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 2.6444\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 2.4016\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 2.3867\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 2.2683\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 2.2542\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.9709\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 2.0996\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.7363A: 0s - loss: 1.7\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.8765\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.8459\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.4761\n",
      "149/149 [==============================] - 1s 4ms/step\n",
      "746/746 [==============================] - 0s 437us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=adam, score=-0.33251139721614403, total=  25.4s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 4s 26ms/step - loss: 12.7381\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 11.5237\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 10.2508\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 8.4694\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 6.9570\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 5.3407\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 4.3904\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 3.7281\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.1673\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 2.4091\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.7657\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.4193\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.9936\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.5758\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.9474\n",
      "149/149 [==============================] - 1s 7ms/step\n",
      "150/150 [==============================] - 0s 541us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop, score=-1.4988460466765718, total=  13.0s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 4s 14ms/step - loss: 14.2687\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 11.3836\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 7.3543\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 3.8561\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 2.6530\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 2.9750\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 2.8110\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.6676\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 2.2574\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 2.4870\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 2.3331\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 2.3184\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.5818\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.1717\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.4374\n",
      "149/149 [==============================] - 1s 6ms/step\n",
      "299/299 [==============================] - 0s 416us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop, score=-1.338254442651, total=  17.6s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 5s 11ms/step - loss: 13.9989\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 8.4205\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 4.2550\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.3704\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 2.5626\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 2.7002A: 0s - loss: 2.69\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 2.5789\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.9218\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.3530\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.4950\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.3449\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.0838\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 2.1791\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 2.1579\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 1.9557\n",
      "149/149 [==============================] - 1s 6ms/step\n",
      "448/448 [==============================] - 0s 370us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop, score=-0.7213157687411212, total=  21.1s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 6s 9ms/step - loss: 12.5902\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 5.2170\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 2.9081\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 2.7639\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.6724\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.4895\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.3700\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.2691\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 2.0381\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 2.1153A: 0s - loss: 2.\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 1.8555\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.7734\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 1.8094\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 1.5570\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - ETA: 0s - loss: 1.8087- ETA: 0s -  - 1s 2ms/step - loss: 1.8207\n",
      "149/149 [==============================] - 1s 8ms/step\n",
      "597/597 [==============================] - 0s 411us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop, score=-0.4275905889890238, total=  25.2s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 6s 8ms/step - loss: 11.9132\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 4.8100\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.8573A: 0s - loss: 2.88\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.2158\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.3210\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.0938\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 2.0778\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.9304A:\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.8369\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.6678\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.7293\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.4986\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.4483\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.3389\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.3294\n",
      "149/149 [==============================] - 1s 9ms/step\n",
      "746/746 [==============================] - 0s 413us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop, score=-0.30751462595774826, total=  30.2s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 5s 32ms/step - loss: 12.6002\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 9.8875\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.9044\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.9155\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.6778\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3853\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.7941\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5648\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3634\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.3961\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.7976\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5103\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1982\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.4576\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5086\n",
      "149/149 [==============================] - 1s 10ms/step\n",
      "150/150 [==============================] - 0s 561us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=adam, score=-0.9500255416703705, total=  15.2s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 6s 20ms/step - loss: 13.0224\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 4.0794\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 2.0898\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.8920\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.7939\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.8424\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.7686\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.7553\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.8329\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.4968\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.5615\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.5890\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.5421\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.5086\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.6349\n",
      "149/149 [==============================] - 2s 10ms/step\n",
      "299/299 [==============================] - 0s 446us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=adam, score=-0.9135573846381783, total=  21.0s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 6s 14ms/step - loss: 11.7863\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.5508\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 2.2331\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.0399\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.9591\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.7975\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.9037\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 1.7398\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 1ms/step - loss: 1.6750\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6624\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6458\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6093\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.5748\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6101\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.5834\n",
      "149/149 [==============================] - 2s 11ms/step\n",
      "448/448 [==============================] - 0s 453us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=adam, score=-0.594991283428749, total=  24.1s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 7s 12ms/step - loss: 8.4881\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.0115\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.7362\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.8112\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.8779\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.6554\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.6974\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.6110\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.6678\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.5394\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.4497\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.4878\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 1ms/step - loss: 1.4276\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3092\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3841\n",
      "149/149 [==============================] - 2s 13ms/step\n",
      "597/597 [==============================] - 0s 662us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=adam, score=-0.38270190093141276, total=  28.5s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 7s 10ms/step - loss: 7.6884\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.8361\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 1s 2ms/step - loss: 1.8681\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.6771\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.6601\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.7271A: 0s - \n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.6607\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.4507\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.4598\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.3984\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.2828\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.2621\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.2836\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.2209\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 1s 1ms/step - loss: 1.2678\n",
      "149/149 [==============================] - 2s 11ms/step\n",
      "746/746 [==============================] - 0s 581us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=adam, score=-0.33619573152305293, total=  31.8s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 6s 40ms/step - loss: 11.9761\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 8.8731\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 4.9528\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.5894\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.9014\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5491\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.7486\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.7158\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.7560\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.7100\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3084\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.6502\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5886\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.6145\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.4293\n",
      "149/149 [==============================] - 2s 12ms/step\n",
      "150/150 [==============================] - 0s 491us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop, score=-1.1115862391139038, total=  16.2s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 7s 22ms/step - loss: 11.6170\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 3.5847\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.7592\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.9615\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.8786\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.7208\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.7144\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.7157\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.6829\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.9818\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 0s 1ms/step - loss: 1.6183\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.4068\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.5612A: 0s - los\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.5364\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.4820\n",
      "149/149 [==============================] - 2s 16ms/step\n",
      "299/299 [==============================] - 0s 466us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop, score=-0.9715039464051292, total=  22.9s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 9s 20ms/step - loss: 9.8467\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.1805\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.8418\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.8712\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.1132\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.9362A: 0\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.9723A: 0s - loss: \n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6734\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.5402A: 0s - loss: 1.\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.7713\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6506\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6318\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.4427\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.5470A\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.4018\n",
      "149/149 [==============================] - 2s 15ms/step\n",
      "448/448 [==============================] - 0s 571us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop, score=-0.567872008421277, total=  30.2s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 8s 13ms/step - loss: 9.4250\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.1608\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.8799\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.6631\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.7571\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.5599\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.6698\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.6972\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.5472\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.5079\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3974\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3341\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3929\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.2718\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3247\n",
      "149/149 [==============================] - 2s 15ms/step\n",
      "597/597 [==============================] - 0s 480us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop, score=-0.4128923227873025, total=  29.3s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 9s 12ms/step - loss: 7.8262\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.0482\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.9331\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 1s 2ms/step - loss: 1.7618\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.6780\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.5168\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.4916\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.3475\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.3301\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.1721\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.2657\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.2791\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.2312\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.0943\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.0444\n",
      "149/149 [==============================] - 3s 22ms/step\n",
      "746/746 [==============================] - 0s 476us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop, score=-0.40999736716883295, total=  37.1s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - ETA: 1s - loss: 12.15 - 8s 55ms/step - loss: 11.8465\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.7638\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3254\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.0767\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3177\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2525\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3622\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3543\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.9703\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1387\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.0650\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1615\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.0301\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.0842\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.0606\n",
      "149/149 [==============================] - 2s 17ms/step\n",
      "150/150 [==============================] - 0s 572us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=adam, score=-0.6327082896792648, total=  22.1s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 8s 28ms/step - loss: 10.3911\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.3503\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.6428\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.3503\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.2887\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.3206\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.2686\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.2742\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.2015\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1355\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1998\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1403\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.0500\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.0449\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1771\n",
      "149/149 [==============================] - 3s 20ms/step\n",
      "299/299 [==============================] - 0s 516us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=adam, score=-0.6637162456176425, total=  24.8s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 9s 20ms/step - loss: 7.3036\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.5615\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.4861\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.4268\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.2543\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.2854\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.1240\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.2345\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.1836\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.1905\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.2003\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.0521\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.0477\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.0174\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.0882\n",
      "149/149 [==============================] - 3s 21ms/step\n",
      "448/448 [==============================] - 0s 593us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=adam, score=-0.5637378731629993, total=  31.8s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 8s 14ms/step - loss: 6.0747\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.5273\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3412\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3754\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3168\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.1385\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.1631\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.1475\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.0746\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.1265\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.0684\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.0059\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.1055\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.0344\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.0292\n",
      "149/149 [==============================] - 3s 17ms/step\n",
      "597/597 [==============================] - 0s 487us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=adam, score=-0.392225176846021, total=  34.0s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 9s 12ms/step - loss: 4.4111\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.3086\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.2295\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.1403\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.1018\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 1s 2ms/step - loss: 1.1322\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.0520\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.0229\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.9590\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.9909\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.9443\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.9722\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.0063\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.9562\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.8793\n",
      "149/149 [==============================] - 3s 18ms/step\n",
      "746/746 [==============================] - 0s 488us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=adam, score=-0.3975531223836361, total=  31.9s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 8s 52ms/step - loss: 10.4844\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.4843\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2036\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1431\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.0469\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1399\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1429\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.0434\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1425\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.0380\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.9985\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.9872\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.9090\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.8700\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1380\n",
      "149/149 [==============================] - 3s 18ms/step\n",
      "150/150 [==============================] - 0s 508us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.7885269930698727, total=  18.0s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 9s 30ms/step - loss: 7.5136\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.2901\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1363\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.2211\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.1451\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.1655\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.1011\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.1787\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.1569\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.1032\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 0.9765\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.1164\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.0983\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 0.9988\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 0s 2ms/step - loss: 1.0615\n",
      "149/149 [==============================] - 4s 24ms/step\n",
      "299/299 [==============================] - 0s 523us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.6458454612117486, total=  23.6s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 10s 23ms/step - loss: 5.1315\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.5588\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.2449\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.3957\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.2330\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.1560\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.3085\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.1292\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.1119\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.2644\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.1685\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.1828\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.1299\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.0762\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.0760\n",
      "149/149 [==============================] - 3s 22ms/step\n",
      "448/448 [==============================] - 0s 727us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.568672903432142, total=  32.2s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 11s 18ms/step - loss: 5.0392\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3824\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.2884\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.1594\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.2216\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.1047\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.1563\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.0947\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.1735\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.0214\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.0918\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.0818\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.0680\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 0.9838\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.0129\n",
      "149/149 [==============================] - 5s 32ms/step\n",
      "597/597 [==============================] - 0s 621us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.36050623640318047, total=  38.8s\n",
      "[CV] activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 12s 16ms/step - loss: 4.1722\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.2431\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.2297\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.1142\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.1105\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.0155\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.9436\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 1s 2ms/step - loss: 1.0077\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.0385\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.9331\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.8358\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.8915\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.8983\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.9729\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.7857\n",
      "149/149 [==============================] - 4s 24ms/step\n",
      "746/746 [==============================] - 0s 564us/step\n",
      "[CV]  activ_func=linear, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.3864166678598263, total=  40.8s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 12.9561\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 12.1179\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 10.7364\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 8.9127\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 6.6735\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.5859\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.7810\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.4877\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.1446\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.1664\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.0259\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.2483\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.1724\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.5996\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.7410\n",
      "149/149 [==============================] - 4s 26ms/step\n",
      "150/150 [==============================] - 0s 588us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=adam, score=-1.797952034729439, total=  24.0s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 13s 42ms/step - loss: 14.0328\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 9.9437\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 4.8649\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.7206\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.3765\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.5688\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.5030\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.6316\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.1370\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.5426\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.5165\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.0069\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.1919\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.9286\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.2274\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "299/299 [==============================] - 0s 604us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=adam, score=-1.5840172097336926, total=  30.1s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 11s 24ms/step - loss: 14.9255\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 9.0989\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 4.7396\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.5516\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.5896\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.5790\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.4264\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.0942\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.1490\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.3091\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.2520\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.9150\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.8377\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.8274\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.9429\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "448/448 [==============================] - 0s 667us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=adam, score=-0.7745109920533712, total=  32.8s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 11s 19ms/step - loss: 13.3301\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 5.1673\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.3711\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.4337\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.2118\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.8771\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.3065\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.3673\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.1668\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.7959\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.9387\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.8494\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.8663\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.5102\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.4997A: 0s - \n",
      "149/149 [==============================] - 4s 26ms/step\n",
      "597/597 [==============================] - 0s 625us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=adam, score=-0.5785206218293849, total=  35.8s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 12s 16ms/step - loss: 10.1686\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 3.5983\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 3.4523\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 3.1811\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 3.1044\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.9330\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.9100\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.7263\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.5779\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 1s 2ms/step - loss: 2.2060\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.5344\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.0007\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.9582\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.9774\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.8590\n",
      "149/149 [==============================] - 4s 27ms/step\n",
      "746/746 [==============================] - 0s 599us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=adam, score=-0.303386985655599, total=  39.9s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 12.7388\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 11.8544\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 10.4977\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 9.1288\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 7.4356\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 5.5842\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.7771\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.2778\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.6416\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.9751\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.2035\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.8871\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.0247\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.7242\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.9309\n",
      "149/149 [==============================] - 4s 29ms/step\n",
      "150/150 [==============================] - 0s 769us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop, score=-1.3482844695548883, total=  23.6s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 12s 39ms/step - loss: 14.2726\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 11.9160\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 8.9635\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 5.7118\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 4.1178\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.1302\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.0893\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.1559\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.1403\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.0855\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.1296\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.8733\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.7161\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.7192\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.5482\n",
      "149/149 [==============================] - 4s 27ms/step\n",
      "299/299 [==============================] - 0s 620us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop, score=-1.4210387091808672, total=  27.3s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 11s 25ms/step - loss: 14.6656\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 10.1852\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 5.5714\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 4.2361\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.5518\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.3980\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.3123\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.0455\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.8468\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.9340\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.1272\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.8237\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.6356\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.4914\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.1798\n",
      "149/149 [==============================] - 4s 28ms/step\n",
      "448/448 [==============================] - 0s 575us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop, score=-0.737212302300754, total=  31.1s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 12s 20ms/step - loss: 12.5106\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 6.6840\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 4.2989\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.4168\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.1661\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.9721\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.8816\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.9683\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.6653\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.7031\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.4625\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.2857\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.0490\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.2679\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.0594\n",
      "149/149 [==============================] - 5s 34ms/step\n",
      "597/597 [==============================] - 0s 736us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop, score=-0.6035264641696575, total=  38.9s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 13s 17ms/step - loss: 11.2993\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 4.5755\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 3.6591\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.9110\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.7719\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.5812\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.3989\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.3601\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.1336\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.1824\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.9159\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 1s 2ms/step - loss: 1.7324\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.6993\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.5322\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.4531\n",
      "149/149 [==============================] - 4s 29ms/step\n",
      "746/746 [==============================] - 0s 581us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop, score=-0.3447647607266503, total=  40.0s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 12s 77ms/step - loss: 12.6892\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 10.5870\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.9522\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.2248\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.0975\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.0961\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.0424\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.7879\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.3363\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5336\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.0662\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.7230\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.4056\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.0096\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.9196\n",
      "149/149 [==============================] - 4s 30ms/step\n",
      "150/150 [==============================] - 0s 622us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=adam, score=-1.0177976153040893, total=  24.6s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 13s 42ms/step - loss: 13.2215\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 5.3005\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.8534\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.1766\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.6217\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.7508\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.3075\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.3606\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.4478\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.3778\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.9388\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.2060\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.1329\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.9655\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.9956\n",
      "149/149 [==============================] - 5s 33ms/step\n",
      "299/299 [==============================] - 0s 634us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=adam, score=-1.0540080322515244, total=  30.3s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 13s 28ms/step - loss: 12.7740\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.8141\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.5497\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.3920\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.4513\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.5878\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.5150\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.2063\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.4286\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.0203\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.2678\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.1784\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.8983\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.9302\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.1399\n",
      "149/149 [==============================] - 5s 32ms/step\n",
      "448/448 [==============================] - 0s 662us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=adam, score=-0.5696870684623718, total=  33.8s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 13s 22ms/step - loss: 9.4678\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.8267\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.7593\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.3106\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.1739\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.4113\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.2004A: 0s - loss: 2.18\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.0854\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.0784\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.7794\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.8425\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.9661\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.7680\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.6734\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.6967\n",
      "149/149 [==============================] - 5s 32ms/step\n",
      "597/597 [==============================] - 0s 729us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=adam, score=-0.3706470243882813, total=  39.4s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 14s 19ms/step - loss: 8.1178\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.6030\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.3626\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.1193\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.2699\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.9689\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.8474\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.9066\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.6580\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.7214\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.6575\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.5276\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.5068\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 1s 2ms/step - loss: 1.6220\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.5272\n",
      "149/149 [==============================] - 5s 33ms/step\n",
      "746/746 [==============================] - 0s 652us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=adam, score=-0.3047476941407127, total=  45.8s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 12.5479\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 10.2980\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 6.7354\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.1593\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.4719\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.7074\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.0140\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.3008\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.7273\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.9785\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.1600\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.1905\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.0364\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.2298\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.9748\n",
      "149/149 [==============================] - 5s 34ms/step\n",
      "150/150 [==============================] - 0s 735us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop, score=-1.0673912107544457, total=  28.5s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 15s 49ms/step - loss: 12.7570\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 6.0343\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.4204\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.5002\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.6167\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.1568\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.2704\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.2452\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.0742\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.0248\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.9508\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.0115\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.9758\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.0038\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.8494\n",
      "149/149 [==============================] - 5s 35ms/step\n",
      "299/299 [==============================] - 0s 671us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop, score=-1.0151244849966676, total=  32.3s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 14s 31ms/step - loss: 12.1503\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.7598\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.4786\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.4321\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.6463\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.1799\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.2669\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.3952\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.8954\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.3105\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.9834\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.8475\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.7693\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.7668\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.7831\n",
      "149/149 [==============================] - 5s 35ms/step\n",
      "448/448 [==============================] - 0s 674us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop, score=-0.5857971220608525, total=  35.9s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 15s 25ms/step - loss: 10.0354\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.9923\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.7193\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.5078\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.0935\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.2370\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.1475\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.1797\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.9482\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.8483\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.6809\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.7939\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.6735\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.5675\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.5495\n",
      "149/149 [==============================] - 6s 37ms/step\n",
      "597/597 [==============================] - 0s 675us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop, score=-0.3528383829624661, total=  41.5s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 15s 20ms/step - loss: 7.0785\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.5801\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.1836\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.2305\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 2.0550\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.0196\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.7092\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.6598\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.5736\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.6980\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.4502\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.3604\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.3819\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.2135\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 1.2516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 6s 38ms/step\n",
      "746/746 [==============================] - 0s 657us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop, score=-0.2943960742262386, total=  46.9s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 11.7368\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.7390\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.7142\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3310\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5445\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.4916\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2454\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2463\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3883\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5729\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2892\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3144\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.4102\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2103\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2402\n",
      "149/149 [==============================] - 6s 38ms/step\n",
      "150/150 [==============================] - 0s 702us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=adam, score=-1.034875751541765, total=  29.1s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 15s 50ms/step - loss: 10.8518\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.9503\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.6877\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.5673\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.6365\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.7175\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.3761\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.4285\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.5308\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.3468\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.3581\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.4701\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.3482\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1713\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.4040\n",
      "149/149 [==============================] - 6s 39ms/step\n",
      "299/299 [==============================] - 0s 738us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=adam, score=-0.7054367449459613, total=  34.6s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 17s 37ms/step - loss: 8.5192\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.8962\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6969\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.5801A: 0s - loss: 1\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.4559\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.4582\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6741\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.3684\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.3780\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.3344\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.3325\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.4422\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.4368\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.3717\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.1882\n",
      "149/149 [==============================] - 7s 49ms/step\n",
      "448/448 [==============================] - 0s 743us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=adam, score=-0.5850737614919675, total=  42.2s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 16s 27ms/step - loss: 7.0151\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.0222A: 0s - loss: 2.\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.7429\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.7299\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.7129\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.4884\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3281\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.4036\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3617\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3220\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3645\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3266\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.2445\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3647\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.2828\n",
      "149/149 [==============================] - 7s 45ms/step\n",
      "597/597 [==============================] - 0s 773us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=adam, score=-0.3939171779038222, total=  45.9s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 20s 26ms/step - loss: 5.0074\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.4773\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.6109\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.4076\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.3102\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.4138\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.3947\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 3s 3ms/step - loss: 1.2995\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.2804\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.2405\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.2285\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.1560\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.0782\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.1036\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.0425\n",
      "149/149 [==============================] - 7s 48ms/step\n",
      "746/746 [==============================] - 1s 849us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=adam, score=-0.3216505623703835, total= 1.1min\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.5 [40, 32, 16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 17s 115ms/step - loss: 10.7615\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.1314\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5746\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3623\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5489\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5246\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.8195\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5093\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.4901\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.4156\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1465\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.6225\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.0962\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1025\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.4550\n",
      "149/149 [==============================] - 7s 48ms/step\n",
      "150/150 [==============================] - 0s 876us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.9409018724956768, total=  33.9s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 16s 55ms/step - loss: 9.0009\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.8056\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.7533\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.5747\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.7269\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.6347\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.6675\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.3578\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.4601\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.4390\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.3836\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1876\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.2943\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.2605\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.3263\n",
      "149/149 [==============================] - 7s 44ms/step\n",
      "299/299 [==============================] - 0s 805us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.8818148680581342, total=  37.7s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 17s 38ms/step - loss: 6.9592\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.7513\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.9188\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.8757\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6610\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.5387\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.4599\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.5107\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.4204\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.3653\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.2908\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.3348\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.2155\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.2827\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.3722\n",
      "149/149 [==============================] - 7s 45ms/step\n",
      "448/448 [==============================] - 0s 763us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.5986656048553902, total=  42.1s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 18s 31ms/step - loss: 5.8205\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.8426\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.6165\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.5632\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.4595\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.4024\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.4135\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3164\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3641\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3100A: 0s - loss: \n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.2388\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.3037\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.1318\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.2934\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.1489\n",
      "149/149 [==============================] - 7s 46ms/step\n",
      "597/597 [==============================] - 0s 769us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.48553000303022814, total=  48.8s\n",
      "[CV] activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 19s 26ms/step - loss: 4.1217\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.6373\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.5659\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.3922\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.2931\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.2494\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.2213\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.2803\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.2364\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.0838\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.0308\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.1048\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.9715\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.0402\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.0253\n",
      "149/149 [==============================] - 7s 47ms/step\n",
      "746/746 [==============================] - 1s 792us/step\n",
      "[CV]  activ_func=linear, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.4600115703956393, total=  54.9s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 18s 118ms/step - loss: 12.9314\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 2ms/step - loss: 12.0087\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 10.6953\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 8.8999\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 6.6213\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 5.0613\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.5741\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.4935\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.6809\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.0632\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.3496\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.0759\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.1613\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.3315\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.4614\n",
      "149/149 [==============================] - 7s 49ms/step\n",
      "150/150 [==============================] - 0s 869us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=adam, score=-1.7897471733541297, total=  33.8s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 18s 61ms/step - loss: 13.9801\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 10.7179\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 7.7170\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 5.4515\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 5.0033\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 4.8458\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 4.5326\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 4.7601\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 4.7708\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 4.5948\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 4.3658\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.7741\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.5442\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.8498\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.8015\n",
      "149/149 [==============================] - 8s 57ms/step\n",
      "299/299 [==============================] - 0s 838us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=adam, score=-1.7296111787225577, total=  40.7s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 21s 47ms/step - loss: 15.1484\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 10.4281\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 6.0309\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 5.1462\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 4.7484\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 4.1243A: 0s - los\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 4.2956\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 4.3320\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 4.0742\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 4.0440\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.9300\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.5636\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.4195\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.5120\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.3716\n",
      "149/149 [==============================] - 8s 51ms/step\n",
      "448/448 [==============================] - 0s 754us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=adam, score=-0.871366849681675, total=  48.1s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 23s 39ms/step - loss: 14.5013\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 8.3311\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 4.8175\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 4.6193\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 4.5858\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.9916\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.9233\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.4584\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.8077\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.5697\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.2281\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.3559\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.8922\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 3ms/step - loss: 2.9592\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.8025\n",
      "149/149 [==============================] - 8s 55ms/step\n",
      "597/597 [==============================] - 0s 762us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=adam, score=-0.5154084541503615, total=  55.3s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 21s 28ms/step - loss: 11.8624\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 5.3974\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 4.2894\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 4.2227\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 3.7947\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 3.4430\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 3.2658\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 3.0091\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 3.1859\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.6152\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.5906\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.5172\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.2387\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.2060\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.1484\n",
      "149/149 [==============================] - 8s 54ms/step\n",
      "746/746 [==============================] - 1s 844us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=adam, score=-0.29724979943177043, total=  56.4s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 20s 131ms/step - loss: 12.9693\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 12.3897\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 11.6794\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 2ms/step - loss: 10.7529\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 9.6831\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 9.0012\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.4016A: 0s - loss: 7.71\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 6.3426\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 5.3354\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 4.9694\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 4.2867\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.6114\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.3104\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.1500\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.4355\n",
      "149/149 [==============================] - 8s 54ms/step\n",
      "150/150 [==============================] - 0s 789us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop, score=-1.9416822235056217, total=  37.7s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 20s 66ms/step - loss: 14.0933\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 11.8324\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 8.9643\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 6.2944\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 5.0132\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 4.9203\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 4.4899\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.9091\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.5745\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.7554\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.6980\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.3906\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.5105\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.8352\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.0220\n",
      "149/149 [==============================] - 8s 55ms/step\n",
      "299/299 [==============================] - 0s 791us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop, score=-1.6225254957207897, total=  42.1s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 21s 47ms/step - loss: 15.1664\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 11.7856\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 7.8132\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 5.2772\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 4.4050\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 4.0880\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.6928\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.6196\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.8479\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.2454\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.2725\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.0729\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.9329\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.0630\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.7187\n",
      "149/149 [==============================] - 8s 57ms/step\n",
      "448/448 [==============================] - 0s 815us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop, score=-0.774331366455795, total=  48.2s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 21s 36ms/step - loss: 13.8522\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 8.3687\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 5.4886\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 4.5192\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 4.0712\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.6407\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.6332\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.2774\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.2701\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.1155\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.8232\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.6264\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.4799\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.3383\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.2496\n",
      "149/149 [==============================] - 9s 60ms/step\n",
      "597/597 [==============================] - 1s 863us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop, score=-0.46990419734869426, total=  53.7s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 25s 34ms/step - loss: 12.8427\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 7.6445\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 4.2810\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 3.8484\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 3.2441\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 3.5471\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.8967\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.8090\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.5931\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.3806\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.1438\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.0712\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.9220\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.7905\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 1.6366\n",
      "149/149 [==============================] - 9s 59ms/step\n",
      "746/746 [==============================] - 1s 778us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop, score=-0.49340241168619403, total= 1.1min\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 21s 143ms/step - loss: 12.4900\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 10.4524\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 7.1504\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.8929\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.0795\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 2ms/step - loss: 2.9197\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.1143\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.6172\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.6804\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.8889\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.4907\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.8222\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.6817\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.9373\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.7300\n",
      "149/149 [==============================] - 9s 61ms/step\n",
      "150/150 [==============================] - 0s 815us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=adam, score=-1.2614999289480633, total=  39.9s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 22s 74ms/step - loss: 13.4741\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 7.1653\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.4023\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.6982\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.2517\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.2843\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.0000\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.9275\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.6160\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.0301\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.7732\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.0591\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.6399\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.6649\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.6214\n",
      "149/149 [==============================] - 10s 66ms/step\n",
      "299/299 [==============================] - 0s 832us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=adam, score=-1.2130918481805981, total=  46.2s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 23s 51ms/step - loss: 12.8672\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 4.3722\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.4240\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.2749\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.4794\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.3198\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.8663\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.7438\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.8160\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.4293\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.7543\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.6721\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.7643\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.4073\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.2858\n",
      "149/149 [==============================] - 10s 64ms/step\n",
      "448/448 [==============================] - 0s 846us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=adam, score=-0.6126097274706668, total=  52.0s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 24s 40ms/step - loss: 10.7258\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.5988\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 3.3717\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.8593\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.9120\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 1s 3ms/step - loss: 2.7090\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.7727\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.9277\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.6097\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.6913\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.5078\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.4673\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.2241\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 2.2319\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.9938\n",
      "149/149 [==============================] - 10s 68ms/step\n",
      "597/597 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=adam, score=-0.39972808094532697, total=  59.1s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 26s 35ms/step - loss: 8.8272\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.9203\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 2.9237\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.6835\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.7285\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.7397\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.4601\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.3126\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.3982\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.0187\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.1251\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.9190\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.8063\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.7224\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.6954\n",
      "149/149 [==============================] - 11s 71ms/step\n",
      "746/746 [==============================] - 1s 888us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=adam, score=-0.31147141149580077, total= 1.2min\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 24s 160ms/step - loss: 12.3639\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 9.7663\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 6.8210\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 4.3583\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 3.0279\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 3.0153\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.5318\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 2ms/step - loss: 3.0729\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.7403\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.0848\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.5473\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.3951\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.4058\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.6323\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 2.6537\n",
      "149/149 [==============================] - 11s 71ms/step\n",
      "150/150 [==============================] - 0s 916us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop, score=-1.2263243538421273, total=  48.4s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 25s 83ms/step - loss: 13.7203\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 9.2186\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 4.5319\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.3665\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.3750\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.6551\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 3.2060\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.6605\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.7952\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.9030\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.4251\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.4631\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.4793\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.2247\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 2.1810\n",
      "149/149 [==============================] - 11s 71ms/step\n",
      "299/299 [==============================] - 0s 858us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop, score=-1.350210153916538, total=  50.1s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 26s 58ms/step - loss: 13.6388\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 6.7547\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.9687\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 3.7091\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 3.3562\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 3.3291\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.7945\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.5788\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.7250\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.5076\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.5571\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.4747\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.3741\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.3455\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.0066\n",
      "149/149 [==============================] - 11s 73ms/step\n",
      "448/448 [==============================] - 0s 889us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop, score=-0.6556509315167498, total=  58.0s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 28s 46ms/step - loss: 11.7012\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 4.1831\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 3.5724\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.9761\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 1s 3ms/step - loss: 2.6913\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.7448\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.1861\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.3058\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.4202\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.9838\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.1344\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.0607\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 1s 3ms/step - loss: 2.0332\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 1s 2ms/step - loss: 1.7638\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 1s 3ms/step - loss: 1.7756\n",
      "149/149 [==============================] - 11s 74ms/step\n",
      "597/597 [==============================] - 1s 882us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop, score=-0.4900749924611425, total= 1.1min\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 28s 37ms/step - loss: 9.1805\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.9506\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.7276\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.6563\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.5066\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.3472\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.0780\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.0485\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.9310\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.7959\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.7021\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.7847\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.5580\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.3816\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.3395\n",
      "149/149 [==============================] - 11s 75ms/step\n",
      "746/746 [==============================] - 1s 892us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop, score=-0.331666627561286, total= 1.2min\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 27s 179ms/step - loss: 12.2942\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 6.9476\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 2.2859\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 2.1256\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.7531\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.8969\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.7044\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 2.0424\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.8852\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 3ms/step - loss: 1.7467\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.7304\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.6776\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.5131\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.7615\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.6026\n",
      "149/149 [==============================] - 12s 77ms/step\n",
      "150/150 [==============================] - 0s 969us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=adam, score=-0.9393316519340412, total=  49.9s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 12.8033\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 3.6448\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.4203\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.2443\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.2744\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.0364\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.9556\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.6153\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.8659\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.7995\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.0573\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.8502\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.7079\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.8463\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.7083\n",
      "149/149 [==============================] - 11s 77ms/step\n",
      "299/299 [==============================] - 0s 902us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=adam, score=-1.0376606441584209, total=  56.1s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 28s 63ms/step - loss: 9.2205\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.5652\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.2129\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.5223\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.0853\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.1122\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.8371\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.7975\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.0144\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.8229\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.7550\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.6861\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.6999\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.6663\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.6504\n",
      "149/149 [==============================] - 12s 81ms/step\n",
      "448/448 [==============================] - 0s 920us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=adam, score=-0.5792004232038588, total= 1.1min\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 30s 50ms/step - loss: 7.3171\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.0541\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.1429\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.0385\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.0377\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.9440\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.8469\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.8175\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.7602\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.7612\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.6174\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.5687\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.6613\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.5400\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.5072\n",
      "149/149 [==============================] - 13s 87ms/step\n",
      "597/597 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=adam, score=-0.34762407849299026, total= 1.2min\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 31s 42ms/step - loss: 6.3884\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.2497\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.9270\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.6814\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.7999\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.5156\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.7755\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.5677\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.4728\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.5073\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.3811\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.5698\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.3631\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.3491\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2665\n",
      "149/149 [==============================] - 15s 102ms/step\n",
      "746/746 [==============================] - 1s 945us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=adam, score=-0.34403831056700457, total= 1.4min\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 11.7495\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 6.0430\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 2.3525\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.8376\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.9161\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 2.0572\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 2.0287\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.7695\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.8429\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.7642\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.9309\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 3ms/step - loss: 1.7194\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.3500\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.5548\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 1.6104\n",
      "149/149 [==============================] - 13s 88ms/step\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.9366077508702374, total=  52.4s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 29s 96ms/step - loss: 10.4522\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.6405\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.7383\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.4491\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.2151\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.8534\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.8629\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.7844\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.5432\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.7990\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.6791\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.7396\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.6908\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.7823\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.4998\n",
      "149/149 [==============================] - 13s 85ms/step\n",
      "299/299 [==============================] - 0s 969us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.8973063458532295, total=  58.4s\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 31s 70ms/step - loss: 8.7186\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.1634\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.1034\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.3676\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.9243\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.0655\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.7676\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.7797\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 2.0039\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.6638\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.6015\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.6976\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.6527\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.4753\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 1.5355\n",
      "149/149 [==============================] - 14s 91ms/step\n",
      "448/448 [==============================] - 0s 944us/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.563275990870175, total= 1.1min\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 31s 52ms/step - loss: 6.9762\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.3374\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.1071\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 2.0559\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.9565\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.7544\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.6845\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.7263\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.6963\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.5361\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.5483\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.5618\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.4647\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.3536\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 1.3916\n",
      "149/149 [==============================] - 13s 90ms/step\n",
      "597/597 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.3421517814190796, total= 1.2min\n",
      "[CV] activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 34s 46ms/step - loss: 5.6687\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 2.1150\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.9532\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.7142\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.7328\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 3s 3ms/step - loss: 1.4897\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.5095\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.4914\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.3929\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.3546\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.2561\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.3270\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2109\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.1749\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 1.1529\n",
      "149/149 [==============================] - 14s 94ms/step\n",
      "746/746 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=linear, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop, score=-0.4810695620316187, total= 1.6min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 32s 211ms/step - loss: 12.8711\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 11.7727\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 10.0862\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 8.5737\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.8624\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.5918\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.5175\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.4126\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.4178\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.3176\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.4020\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.3650\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.3257\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 3ms/step - loss: 7.3772\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.4523\n",
      "149/149 [==============================] - 14s 92ms/step\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=adam, score=-10.126664302493102, total=  55.9s\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 32s 108ms/step - loss: 14.4701\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 11.3587\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 9.4930\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 9.0513\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.9112\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.9659\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8544\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8373\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8447\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7744\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8044\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8518\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8104\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8703\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8382\n",
      "149/149 [==============================] - 14s 95ms/step\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=adam, score=-10.892203423800884, total= 1.0min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 34s 76ms/step - loss: 14.1422\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 11.0416\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 10.1715\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.7397\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.7679\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.6547\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.6663\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.5682\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.6415\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.5260\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.5741\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.5507\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.6069\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4983\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.5038\n",
      "149/149 [==============================] - 15s 99ms/step\n",
      "448/448 [==============================] - 0s 982us/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=adam, score=-7.889968340828915, total= 1.2min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 34s 57ms/step - loss: 13.0253\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.8249\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.4924\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.2631\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.2744\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.2731\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.2618\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1483\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1279\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1355\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1468\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1759\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1546\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1349\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1351\n",
      "149/149 [==============================] - 15s 98ms/step\n",
      "597/597 [==============================] - 1s 974us/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=adam, score=-4.455554072488875, total= 1.3min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 36s 48ms/step - loss: 11.4619\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.6201\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.4251\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.2972\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.2856\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.3017\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.2461\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.2477\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.2709\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.2580\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.2110\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.2356\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1887\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1821\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.2077\n",
      "149/149 [==============================] - 15s 102ms/step\n",
      "746/746 [==============================] - 1s 992us/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=adam, score=-3.1155760224233537, total= 1.4min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 34s 225ms/step - loss: 12.7455\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 11.5810\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 10.5294\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 9.4288\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 8.6905\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 8.1278\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 8.0033\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.7388\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.5513\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.5799\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.4649\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.4416\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.3777\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.3430\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2753\n",
      "149/149 [==============================] - 15s 99ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop, score=-10.138205899488206, total=  58.8s\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 34s 113ms/step - loss: 14.0057\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 11.4351\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 9.8078\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 9.1633\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 9.1296\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8733\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8176\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7934\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7356\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8111\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7252\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7259\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7090\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7656\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7437\n",
      "149/149 [==============================] - 15s 98ms/step\n",
      "299/299 [==============================] - 0s 976us/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop, score=-10.890519599786542, total= 1.1min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 35s 78ms/step - loss: 14.2720\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 10.8881\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.8312\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.6703\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5306\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 2s 3ms/step - loss: 9.5252\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.5721\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4974\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4935\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 3ms/step - loss: 9.5012\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4501\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4944A: \n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4751\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4581\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4354\n",
      "149/149 [==============================] - 16s 107ms/step\n",
      "448/448 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop, score=-7.889165011028315, total= 1.3min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 36s 60ms/step - loss: 12.4293\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.6788\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.2602\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.2068\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1357\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1035\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0846\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1319\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0927\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1021\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0517\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0946\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0705\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0734\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0573\n",
      "149/149 [==============================] - 16s 106ms/step\n",
      "597/597 [==============================] - 1s 1ms/step: \n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop, score=-4.4550712764663185, total= 1.3min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.4 [10, 8, 4]\n",
      "End compilation of model:  0.4 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 37s 50ms/step - loss: 12.1085\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.8095\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.3656\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.2751\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.2325\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1922\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1609\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1660\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1625\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1454\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1521\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1366\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1322\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1247\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1262\n",
      "149/149 [==============================] - 16s 108ms/step\n",
      "746/746 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[10, 8, 4], optimizer=rmsprop, score=-3.1153068286460517, total= 1.5min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 36s 241ms/step - loss: 12.5043\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 10.2073\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.8680\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.3766\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2884\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2634\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2456\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2419\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2391\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2134\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.1977\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.1926\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2114\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2723\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.1767\n",
      "149/149 [==============================] - 17s 113ms/step\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=adam, score=-10.126501236985995, total= 1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 37s 122ms/step - loss: 13.8910\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 9.6070\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7761\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7459\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7178\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6970\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6831\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7025\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6803\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6919\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6608\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6689\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6693\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7071\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6991\n",
      "149/149 [==============================] - 16s 110ms/step\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=adam, score=-10.891150173724897, total= 1.2min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 39s 86ms/step - loss: 12.7078\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.6881\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.5815\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4712\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4407\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4417\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4341\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4205\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 3ms/step - loss: 9.4211\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 3ms/step - loss: 9.4034\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4091\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4234\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 2s 3ms/step - loss: 9.4099\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4296\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 3ms/step - loss: 9.4049\n",
      "149/149 [==============================] - 17s 115ms/step\n",
      "448/448 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=adam, score=-7.889268067059101, total= 1.3min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 45s 76ms/step - loss: 11.6176\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.1334\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0601\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0427\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0401\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0455\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0437\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0370\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0428\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0397\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0236\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0337\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0236\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0267\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0232\n",
      "149/149 [==============================] - 17s 112ms/step\n",
      "597/597 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=adam, score=-4.455117436863432, total= 1.6min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 40s 54ms/step - loss: 10.4505\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1920\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1420\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1282\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1287\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1364\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1333\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1336\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1311\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1283\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1166\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1147\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1268\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1085\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1231\n",
      "149/149 [==============================] - 18s 121ms/step\n",
      "746/746 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=adam, score=-3.115338967950552, total= 1.6min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 41s 273ms/step - loss: 12.4751\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 10.3473\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 8.4346\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.5928\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2898\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2566\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2306\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2465\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.1795\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.2086\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.1855\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.1961\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.1784\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.1727\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 7.1808\n",
      "149/149 [==============================] - 17s 116ms/step\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop, score=-10.12519355108274, total= 1.2min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 41s 137ms/step - loss: 13.3150\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 9.6329\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8238\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7063\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.7064\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6816\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6634\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6679\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6608\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6650\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6565\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6442\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6538\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6538\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.6450\n",
      "149/149 [==============================] - 19s 125ms/step\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop, score=-10.890285875973285, total= 1.3min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 42s 93ms/step - loss: 12.3738\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5049\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4166\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.3972\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.3977\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.3949\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4014\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.3921\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.3955\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.3939\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.3890\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.3908A: 0s\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.4008\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1s 3ms/step - loss: 9.3886\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 3ms/step - loss: 9.3872\n",
      "149/149 [==============================] - 18s 120ms/step\n",
      "448/448 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop, score=-7.88909657369524, total= 1.4min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 42s 70ms/step - loss: 11.6584\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1604\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0490\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0372\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0241\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0267\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0216\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0192\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0260\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0290\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0207\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0173\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0157\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0209\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 3ms/step - loss: 9.0144\n",
      "149/149 [==============================] - 19s 125ms/step\n",
      "597/597 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop, score=-4.45506597045284, total= 1.5min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.4 [20, 16, 8]\n",
      "End compilation of model:  0.4 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 43s 58ms/step - loss: 9.7368\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1496\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1230\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1265\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1100\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1178\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1057\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1097\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1057\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 8.1043\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 3s 3ms/step - loss: 8.1036\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1072\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1079\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1038\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 3s 3ms/step - loss: 8.1059\n",
      "149/149 [==============================] - 19s 130ms/step\n",
      "746/746 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[20, 16, 8], optimizer=rmsprop, score=-3.1153044900638145, total= 1.7min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 45s 299ms/step - loss: 12.0149\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 8.0876\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2281\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 7.1889\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1719\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1820\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1685\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1656\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1647\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 7.1643\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1632\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 7.1659\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1636\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1630\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.1621\n",
      "149/149 [==============================] - 21s 143ms/step\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=adam, score=-10.124803875916756, total= 1.4min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 46s 153ms/step - loss: 11.7529\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6828\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6533\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6448\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6425\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6430\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6419\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6423\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6393\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6399\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6394\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6393\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6393\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6399\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6390\n",
      "149/149 [==============================] - 20s 136ms/step\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=adam, score=-10.890309445809997, total= 1.5min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 45s 101ms/step - loss: 11.7332\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4110\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3955\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3937\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3935\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3896\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3908\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3896\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3891\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3899\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3884\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3894\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3881\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3928\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3890\n",
      "149/149 [==============================] - 21s 143ms/step\n",
      "448/448 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=adam, score=-7.889132978132107, total= 1.6min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 52s 88ms/step - loss: 10.3702\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0289\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0214\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0165\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0165\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0158\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0194\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0158\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0158\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0157\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0148\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0150\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0148\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0137\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0155\n",
      "149/149 [==============================] - 21s 141ms/step\n",
      "597/597 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=adam, score=-4.455078880258855, total= 1.9min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 53s 71ms/step - loss: 9.3828\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1120\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1082\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1050\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1061\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1064\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1046\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1043\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1039\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1034\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1040\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1035\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1033\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1033\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 8.1034\n",
      "149/149 [==============================] - 22s 145ms/step\n",
      "746/746 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=adam, score=-3.1153137331840974, total= 2.0min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 47s 311ms/step - loss: 10.2343\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.4520\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1878\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1783\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.1645\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.1631\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.1647\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.1619\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.1614\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.1607\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.1608\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.1608\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.1607\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.1621\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.1607\n",
      "149/149 [==============================] - 20s 136ms/step\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop, score=-10.12466007591094, total= 1.3min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 47s 157ms/step - loss: 10.7612\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6777\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6418\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6393\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6385\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6383\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6378\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6383\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6380\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6377\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6382\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6377\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6378\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6377\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6381\n",
      "149/149 [==============================] - 22s 145ms/step\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop, score=-10.890237104172675, total= 1.5min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 50s 111ms/step - loss: 11.1008\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3971\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3890\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3881\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3872\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3872\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3870\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3869\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3870\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3869\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3869\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3869\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3869\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3868\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3869\n",
      "149/149 [==============================] - 22s 151ms/step\n",
      "448/448 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop, score=-7.889096112859329, total= 1.7min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 50s 83ms/step - loss: 10.1044\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0154\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0145\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0132\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0132\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0131\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0132\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0131\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0131\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0130\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0130\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0131\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0130\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0130\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0130\n",
      "149/149 [==============================] - 24s 159ms/step\n",
      "597/597 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop, score=-4.455065567221418, total= 1.9min\n",
      "[CV] activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.4 [40, 32, 16]\n",
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 52s 69ms/step - loss: 9.0522\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1062\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1041\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1032\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1028\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1027\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1028\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1027\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1027\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1028\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1027\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1027\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1027\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1027\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1027\n",
      "149/149 [==============================] - 24s 161ms/step\n",
      "746/746 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.4, neurons=[40, 32, 16], optimizer=rmsprop, score=-3.1153044900638145, total= 2.1min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 50s 335ms/step - loss: 13.1035\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 12.1308\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 11.2499\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 10.1882\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 9.2959\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 8.6102\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 8.2220\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 8.0687\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.9213\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 7.8430\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.7287\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.7233\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 7.6258\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 7.4670\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 7.5436\n",
      "149/149 [==============================] - 23s 152ms/step\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=adam, score=-10.12834326852888, total= 1.4min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 50s 169ms/step - loss: 14.0492\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 11.6858\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 10.2430\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.6602\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.2207\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.2519\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 3ms/step - loss: 9.1454\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.0808\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.0343\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.0238\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.8887\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.9760\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 9.0105\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.9258\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8744\n",
      "149/149 [==============================] - 23s 157ms/step\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=adam, score=-10.893554508286034, total= 1.6min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 55s 122ms/step - loss: 14.8592\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 2s 3ms/step - loss: 11.6512\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 2s 3ms/step - loss: 10.5196\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 2s 3ms/step - loss: 10.1016\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 10.0118\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.8731\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.7840\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.7218\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.9365\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.7795\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.7496\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.6894\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.6635\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.6348\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.6032\n",
      "149/149 [==============================] - 25s 170ms/step\n",
      "448/448 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=adam, score=-7.891932249069214, total= 1.8min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 55s 92ms/step - loss: 13.8428\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - ETA: 0s - loss: 10.58 - 2s 4ms/step - loss: 10.5595\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.6628\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.4243\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.4459\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.4167\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.3635\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.3372\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.3033\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.2928\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.3164\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.2710\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.2077\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.2589\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1935\n",
      "149/149 [==============================] - 25s 169ms/step\n",
      "597/597 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=adam, score=-4.455673396987403, total= 1.9min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 57s 76ms/step - loss: 11.8277\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.9777\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.5887\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.4917\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.5023\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.4536\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.3726\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.3445\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.3230\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.3021\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2781\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2836\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2847\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2585\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2462\n",
      "149/149 [==============================] - 25s 170ms/step\n",
      "746/746 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=adam, score=-3.115672185116966, total= 2.2min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 56s 370ms/step - loss: 12.9784\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 12.3078\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 11.4316\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 10.5406\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 9.7302\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 8.9465\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 8.2988\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.9833\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.8358\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.6484\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.6005\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.4635\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.4999\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.4224\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.5041\n",
      "149/149 [==============================] - 28s 185ms/step\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop, score=-10.137832942425005, total= 1.6min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 57s 189ms/step - loss: 14.1888\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 11.6288\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.8624\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.3209\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.1793\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.0835\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.9611\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.8678\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 4ms/step - loss: 8.8341\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.9517\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.8398\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.8391\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 8.8391\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.8202\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.8169\n",
      "149/149 [==============================] - 27s 180ms/step\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop, score=-10.890483901004663, total= 1.7min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 58s 129ms/step - loss: 14.5434\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 11.3254\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 10.1383\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.8341\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.7936\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.6997\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5769\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5869\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5720\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5845\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5471\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5272\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4833\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4631\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4860\n",
      "149/149 [==============================] - 26s 174ms/step\n",
      "448/448 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop, score=-7.889119161055392, total= 1.9min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 59s 99ms/step - loss: 14.1511\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 10.9313\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.6283\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.2948\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.2813\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1644\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.2016\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1518\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1645\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1365\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1139\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0898\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0897\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0871\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0788\n",
      "149/149 [==============================] - 27s 183ms/step\n",
      "597/597 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop, score=-4.45506924430796, total= 2.0min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.5 [10, 8, 4]\n",
      "End compilation of model:  0.5 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 62s 83ms/step - loss: 11.6749\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.9810\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.4547\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.3251\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2794\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2755\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2698\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2391\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2333\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2098\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1789\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1722\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1495\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1542\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1531\n",
      "149/149 [==============================] - 27s 182ms/step\n",
      "746/746 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[10, 8, 4], optimizer=rmsprop, score=-3.1153045436679916, total= 2.2min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 61s 408ms/step - loss: 12.3085\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 10.1243\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 8.2210\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.6847\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.4953\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.3623\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.4315\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.3669\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.2829\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2778\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2941\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.2681\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2259\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2099\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2293\n",
      "149/149 [==============================] - 29s 193ms/step\n",
      "150/150 [==============================] - 0s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=adam, score=-10.125311025837124, total= 1.7min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 62s 208ms/step - loss: 13.8228\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.7560\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.8667\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.8142\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.7521\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.7731\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.7432\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.7087\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.7092\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6946\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6661\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6999\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6924\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6803\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.7130\n",
      "149/149 [==============================] - 28s 190ms/step\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=adam, score=-10.890466536451505, total= 1.9min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 63s 141ms/step - loss: 13.4891\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.8447\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5842\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4802\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4941\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4755\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4637\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4489\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4614\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4297\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4216\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4176\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4506\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4242\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4617\n",
      "149/149 [==============================] - 29s 193ms/step\n",
      "448/448 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=adam, score=-7.889207494338887, total= 2.0min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 66s 110ms/step - loss: 12.5588\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.3279\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1716\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1449\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1152\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0999\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0881\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0603\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0703\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0662\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0787\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0524\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0456\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0566\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0688\n",
      "149/149 [==============================] - 30s 199ms/step\n",
      "597/597 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=adam, score=-4.455169380111182, total= 2.2min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 66s 89ms/step - loss: 10.5369\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2766\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1920\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1709\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1479\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1377\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1209\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1508\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1176\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1251\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1649\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1307\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1179\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1400\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1523\n",
      "149/149 [==============================] - 30s 202ms/step\n",
      "746/746 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=adam, score=-3.1153092368337134, total= 2.4min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 66s 441ms/step - loss: 12.6046\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 10.9211\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 9.1245\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.9362\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.6263\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.4755\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2982\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2792\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2597\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.2460\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.3073\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2707\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2069\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2465\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2215\n",
      "149/149 [==============================] - 30s 200ms/step\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop, score=-10.125329907308489, total= 1.8min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 67s 225ms/step - loss: 12.8576\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.4588\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.8899\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.7786\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.7047\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.7234\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6696\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6477\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6446\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6857\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6725\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6487\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6583\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6552\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6623\n",
      "149/149 [==============================] - 31s 208ms/step\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop, score=-10.890246516106112, total= 2.0min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 69s 154ms/step - loss: 12.6713\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.8118\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4757\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4569\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4545\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4466\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.3991\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4192\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4107\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4126\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4042\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4147\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4299\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4040\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4064\n",
      "149/149 [==============================] - 31s 209ms/step\n",
      "448/448 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop, score=-7.889097941801852, total= 2.2min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 70s 118ms/step - loss: 11.6961\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1952\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0806\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0683\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0687\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.0339\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0378\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0429\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0364\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0423\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0323\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0397A: 0s -\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0293\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0280\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.0166\n",
      "149/149 [==============================] - 33s 219ms/step\n",
      "597/597 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop, score=-4.4550659928545855, total= 2.4min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.5 [20, 16, 8]\n",
      "End compilation of model:  0.5 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 73s 98ms/step - loss: 10.0992\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1751\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1565\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1369\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1255\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1430\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1180\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1212\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1087\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1156\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1105\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1220\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1172\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1121\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1057\n",
      "149/149 [==============================] - 33s 225ms/step\n",
      "746/746 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[20, 16, 8], optimizer=rmsprop, score=-3.1153044900638145, total= 2.5min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 69s 463ms/step - loss: 12.4329\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 9.2830\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.3862\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.2533\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1844\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.2144\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1696\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1728\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1839\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1703\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1692\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1730\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1687\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1704\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1765\n",
      "149/149 [==============================] - 33s 220ms/step\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=adam, score=-10.124800976490814, total= 2.0min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 74s 249ms/step - loss: 11.7971\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 8.6995\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 8.6606\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 8.6526\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 8.6477\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6455\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 8.6488\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 8.6498\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6460\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6448\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6408\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 8.6450\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 8.6451\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 8.6423\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 2s 6ms/step - loss: 8.6393\n",
      "149/149 [==============================] - 33s 221ms/step\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=adam, score=-10.890247975419832, total= 2.3min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 77s 172ms/step - loss: 11.7970\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4384\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4092\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4055\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3975\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3946\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3928\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3909\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3917\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3987\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 9.3908\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 9.3914\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3928\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3933\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3889\n",
      "149/149 [==============================] - 34s 229ms/step\n",
      "448/448 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=adam, score=-7.889111006819962, total= 2.5min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 76s 127ms/step - loss: 10.9852\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0436\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0327\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0231\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0219\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0181\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0209\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0166\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0168\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 3s 6ms/step - loss: 9.0222\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0181\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0168\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0152\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0140\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0149\n",
      "149/149 [==============================] - 33s 220ms/step\n",
      "597/597 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=adam, score=-4.455071036447615, total= 2.6min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 81s 109ms/step - loss: 9.4491\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1229\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1148\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 4s 6ms/step - loss: 8.1117\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1086\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1088\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1083\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1071\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1047\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1048\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1060\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1065\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 4s 6ms/step - loss: 8.1055\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1039\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1036\n",
      "149/149 [==============================] - 35s 235ms/step\n",
      "746/746 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=adam, score=-3.1153076959136348, total= 2.9min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 77s 512ms/step - loss: 11.6762\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 8.4555\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.4034\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.2719\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1963\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1781\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1782\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1801\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1672\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1674\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 7.1669\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 7.1660\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 7.1633\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1645\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.1614\n",
      "149/149 [==============================] - 35s 237ms/step\n",
      "150/150 [==============================] - 0s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop, score=-10.124685101861122, total= 2.1min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 86s 287ms/step - loss: 11.2312\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.7208\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6519\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6465\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6412\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6488\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6382\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6379\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6393\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6383\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6385\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6379\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6381\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6379\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6380\n",
      "149/149 [==============================] - 34s 229ms/step\n",
      "299/299 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop, score=-10.890237104172675, total= 2.4min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 79s 176ms/step - loss: 10.8049\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4089\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3890\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3882\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 6ms/step - loss: 9.3886\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3873\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3871\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3876\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 9.3870\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3871\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3869\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3871\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3872\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3877\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.3871\n",
      "149/149 [==============================] - 36s 239ms/step\n",
      "448/448 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop, score=-7.889096112859329, total= 2.5min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 81s 136ms/step - loss: 10.3369\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 3s 6ms/step - loss: 9.0285\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0213\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0144\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0148\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0137\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0134\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 4s 6ms/step - loss: 9.0133\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 3s 6ms/step - loss: 9.0138\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 3s 6ms/step - loss: 9.0134\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0162\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0131\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0133\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0131\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 3s 6ms/step - loss: 9.0131\n",
      "149/149 [==============================] - 36s 240ms/step\n",
      "597/597 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop, score=-4.455065567221418, total= 2.8min\n",
      "[CV] activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.5 [40, 32, 16]\n",
      "End compilation of model:  0.5 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 83s 111ms/step - loss: 9.1275\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1099\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 4s 6ms/step - loss: 8.1042\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1037\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1051\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1030\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1029\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1029\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 4s 6ms/step - loss: 8.1032\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 5s 6ms/step - loss: 8.1029\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 4s 6ms/step - loss: 8.1027\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 4s 6ms/step - loss: 8.1027\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 4s 6ms/step - loss: 8.1027\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 4s 6ms/step - loss: 8.1027\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 4s 6ms/step - loss: 8.1027\n",
      "149/149 [==============================] - 35s 236ms/step\n",
      "746/746 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.5, neurons=[40, 32, 16], optimizer=rmsprop, score=-3.1153044900638145, total= 3.0min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 83s 555ms/step - loss: 12.8070\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 12.0368\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 10.9808\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 10.1298\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 9.4748\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 8.9815\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 8.2180\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 8.2051A: 0s - lo\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 8.0500\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 8.2642\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 8.0113\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.8748\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.8586\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.8546\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.8342\n",
      "149/149 [==============================] - 44s 292ms/step\n",
      "150/150 [==============================] - 0s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=adam, score=-10.131576192459004, total= 2.4min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 84s 282ms/step - loss: 14.6658\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 12.9024\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 10.9628\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 10.1037\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.7587\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.5308\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.5238\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.2357\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.3832\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.2231\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.2491\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.1748\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.1862\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.0758\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 9.0574\n",
      "149/149 [==============================] - 38s 255ms/step\n",
      "299/299 [==============================] - 0s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=adam, score=-10.892563960696227, total= 2.4min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.6 [10, 8, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 91s 202ms/step - loss: 14.9952\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 12.3512\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 10.9473\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 10.4997\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 10.2835\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 10.0786\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 10.1001\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.9924\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.9881\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.8146\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.8061\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.8666\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.7767\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.8179\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.7790\n",
      "149/149 [==============================] - 39s 260ms/step\n",
      "448/448 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=adam, score=-7.892493812829856, total= 2.7min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 89s 150ms/step - loss: 13.5568\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 4s 6ms/step - loss: 10.5847\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 3s 6ms/step - loss: 10.0889\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.8587\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.6524\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.6422\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.4420\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.4467\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.4920\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.4384\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.4371\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.3309\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.2975\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.3078\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.2765\n",
      "149/149 [==============================] - 43s 287ms/step\n",
      "597/597 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=adam, score=-4.455281657660567, total= 3.0min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=adam \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 115s 154ms/step - loss: 12.7249\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 9.4825\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 9.0262\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.8834\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.7347\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.5983\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.6179\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.5233\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 8.4651\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 8.4275\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.4061\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 8.3311\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.3582\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 4s 6ms/step - loss: 8.3256\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2641\n",
      "149/149 [==============================] - 46s 308ms/step\n",
      "746/746 [==============================] - 2s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=adam, score=-3.116791362730449, total= 3.6min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 97s 644ms/step - loss: 12.9210\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 12.2030\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 11.3702\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 10.6008\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 9.5318\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 9.2036\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 8.5507\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 8.3520\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 8.1426\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.9465\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.8169\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.8202\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.7104\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.5931\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.6636\n",
      "149/149 [==============================] - 39s 263ms/step\n",
      "150/150 [==============================] - 0s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop, score=-10.139603102767227, total= 2.5min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 93s 312ms/step - loss: 14.3480\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 12.5929\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 11.2514\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 10.0584\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 9.6212\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 9.4509\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 9.2808\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 9.1504\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 9.0754\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 9.1732\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.9837\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.9199\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 9.0115\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.9534\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.9540\n",
      "149/149 [==============================] - 41s 276ms/step\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop, score=-10.890439567949947, total= 2.7min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 91s 204ms/step - loss: 14.9979\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 2s 4ms/step - loss: 12.5107\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 10.9565\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 10.3848\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 10.0180\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.9277\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.8503\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.7844\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.6704\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.6985\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.6395\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5342\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5970\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5407\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4921\n",
      "149/149 [==============================] - 41s 272ms/step\n",
      "448/448 [==============================] - 1s 1ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop, score=-7.8891190026430476, total= 2.7min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 96s 160ms/step - loss: 13.8510\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 10.8857\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.7388\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.5614\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.5500\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.3421\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.3511\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.2883\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.2288\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.2110\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.2204\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1530\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1455\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 3s 4ms/step - loss: 9.1104\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 2s 4ms/step - loss: 9.1044\n",
      "149/149 [==============================] - 40s 270ms/step\n",
      "597/597 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop, score=-4.4550659288495975, total= 2.9min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop \n",
      "Start model:  0.6 [10, 8, 4]\n",
      "End compilation of model:  0.6 [10, 8, 4]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 98s 132ms/step - loss: 12.1204\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 9.7157\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 8.8682\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.5877\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.4509\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.3462\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.3493\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 5s 7ms/step - loss: 8.3092A: 0s - \n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.2455\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2210\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2118\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 8.1800\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.1679\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 8.1532\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1453\n",
      "149/149 [==============================] - 50s 334ms/step\n",
      "746/746 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[10, 8, 4], optimizer=rmsprop, score=-3.1153046188738522, total= 3.4min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 95s 635ms/step - loss: 12.4824\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 10.9300\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 8.9343\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 8.0521\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.5880\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.5775\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.5686\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.5200\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.3650\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.4033\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.3339\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.3062\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.2793\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.2999\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 7.3186\n",
      "149/149 [==============================] - 46s 307ms/step\n",
      "150/150 [==============================] - 0s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=adam, score=-10.125997095300047, total= 2.6min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 101s 338ms/step - loss: 13.9651\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 10.5375\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 9.2588\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.9425\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.9032\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.8801\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.7980\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.8634\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.8877\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.7550\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.7571\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.7970\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.7628\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.7508\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 8.6854\n",
      "149/149 [==============================] - 46s 310ms/step\n",
      "299/299 [==============================] - 0s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=adam, score=-10.890422811444173, total= 2.9min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 96s 215ms/step - loss: 14.2327\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 10.4428\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 9.8212\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 3s 6ms/step - loss: 9.6096\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 9.6327\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 9.6196\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.5528\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.5773\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4860\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.5000\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.5088\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5018\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4919\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.4913\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 9.5452\n",
      "149/149 [==============================] - 44s 295ms/step\n",
      "448/448 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=adam, score=-7.889415547351709, total= 3.0min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 99s 166ms/step - loss: 12.9562\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.5608\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.2654\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.2697\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.1807\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.1340\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.1565\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.1612\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.1017\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 4s 6ms/step - loss: 9.1812\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 4s 7ms/step - loss: 9.1010\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 3s 6ms/step - loss: 9.1446\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.1129\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0838\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0793\n",
      "149/149 [==============================] - 47s 319ms/step\n",
      "597/597 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=adam, score=-4.455163942887479, total= 3.2min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=adam \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 108s 145ms/step - loss: 10.9391\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 8.4908\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.2921\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.2763\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2527\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.2225\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 8.2507\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 8.2223\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.2044\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 8.1789\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 8.1988\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1806\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1832\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 5s 6ms/step - loss: 8.1741\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1751\n",
      "149/149 [==============================] - 52s 347ms/step\n",
      "746/746 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=adam, score=-3.1153131411379618, total= 3.6min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 96s 639ms/step - loss: 12.6838\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 11.1426\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 9.1538\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 8.1293\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.7290\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.4597\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 7.4713\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 7.2960\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.4017\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.2239\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.3827\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.2777\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.2422\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.2715\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 7.2871\n",
      "149/149 [==============================] - 43s 291ms/step\n",
      "150/150 [==============================] - 0s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop, score=-10.124860923562274, total= 2.6min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 95s 319ms/step - loss: 13.6544\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 10.6404\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 9.2328\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.8897\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.8623\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.7537\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.8178\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.7921\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 2s 6ms/step - loss: 8.7735\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.7481\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.7015\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.7336\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.6788\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 1s 5ms/step - loss: 8.7089\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 2s 5ms/step - loss: 8.6875\n",
      "149/149 [==============================] - 43s 291ms/step\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop, score=-10.89024383109688, total= 2.7min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 99s 221ms/step - loss: 13.8923\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 10.4766\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.7168\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.5543\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4839\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4938\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4834\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4840\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4659\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4506\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4663\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4855\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 9.4442\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4289\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 9.4181\n",
      "149/149 [==============================] - 52s 352ms/step\n",
      "448/448 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop, score=-7.889101761299492, total= 3.1min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 119s 199ms/step - loss: 12.7474\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.6074\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.1993\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.1389\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.1177\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0761\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0741\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0661\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0714\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0738\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0664\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0504\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0491\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0409\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 3s 5ms/step - loss: 9.0311\n",
      "149/149 [==============================] - 54s 363ms/step\n",
      "597/597 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop, score=-4.455066293678028, total= 3.7min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop \n",
      "Start model:  0.6 [20, 16, 8]\n",
      "End compilation of model:  0.6 [20, 16, 8]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 122s 163ms/step - loss: 11.4476\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.4940\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.3002\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.2233\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 4s 6ms/step - loss: 8.2033\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 4s 6ms/step - loss: 8.1493\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1612\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1503\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1554\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1301\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1285\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1420\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1273\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1265\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 8.1223\n",
      "149/149 [==============================] - 53s 356ms/step\n",
      "746/746 [==============================] - 2s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[20, 16, 8], optimizer=rmsprop, score=-3.115304493264064, total= 3.9min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 127s 843ms/step - loss: 11.9947\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 9.0914\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 7.5464\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.3505\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 7.2205\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 7.2037\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 7.1976\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 7.1872\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 7.1762\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 7.1863\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 7.1919\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 7.1845\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 7.1775\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 7.2133\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 7.1942\n",
      "149/149 [==============================] - 64s 430ms/step\n",
      "150/150 [==============================] - 0s 3ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=adam, score=-10.124696091517507, total= 3.6min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 153s 513ms/step - loss: 12.4931\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.9249\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6982\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6696\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 3s 10ms/step - loss: 8.6522\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 4s 12ms/step - loss: 8.6651\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 3s 9ms/step - loss: 8.6456\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6421\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 2s 7ms/step - loss: 8.6469\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6510\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6400\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 3s 9ms/step - loss: 8.6447\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 3s 10ms/step - loss: 8.6516\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 3s 9ms/step - loss: 8.6478\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 3s 10ms/step - loss: 8.6409\n",
      "149/149 [==============================] - 60s 400ms/step\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=adam, score=-10.8902442471293, total= 4.3min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 142s 318ms/step - loss: 12.4473\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.4880\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.4198\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.4312\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.4062\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.3933\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.4177\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 4s 9ms/step - loss: 9.3912\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.3948\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.3950\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.3964\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.3918\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.3920\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.3926\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 9.4038A\n",
      "149/149 [==============================] - 65s 438ms/step\n",
      "448/448 [==============================] - 1s 3ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=adam, score=-7.889103476633162, total= 4.5min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 140s 235ms/step - loss: 11.4839\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 5s 9ms/step - loss: 9.0911\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 7s 11ms/step - loss: 9.0531\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0295\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0433\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 5s 9ms/step - loss: 9.0331\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 6s 10ms/step - loss: 9.0339\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 5s 9ms/step - loss: 9.0190\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0194\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0206\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0237\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 5s 9ms/step - loss: 9.0212\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 5s 9ms/step - loss: 9.0288\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 5s 9ms/step - loss: 9.0158\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 5s 9ms/step - loss: 9.0295\n",
      "149/149 [==============================] - 65s 433ms/step\n",
      "597/597 [==============================] - 2s 3ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=adam, score=-4.455067448968055, total= 6.2min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=adam \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 133s 179ms/step - loss: 9.5987\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 7s 9ms/step - loss: 8.1444\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 6s 9ms/step - loss: 8.1215\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1166\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1130\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 6s 9ms/step - loss: 8.1171\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1105\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1166\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1084\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1083\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1115\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 6s 9ms/step - loss: 8.1087\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1100\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 7s 9ms/step - loss: 8.1069\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 7s 9ms/step - loss: 8.1052\n",
      "149/149 [==============================] - 63s 421ms/step\n",
      "746/746 [==============================] - 2s 3ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=adam, score=-3.115304967701035, total= 4.8min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 120s 799ms/step - loss: 12.0238\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 9.1812\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.7301\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.4069\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.2352\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.1853\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.1997\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.1801\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.1708\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.1806\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.1735\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.1712\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.1627\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.1737\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.1638\n",
      "149/149 [==============================] - 57s 380ms/step\n",
      "150/150 [==============================] - 0s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop, score=-10.124671628811216, total= 3.3min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - 128s 429ms/step - loss: 12.1375\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 3s 8ms/step - loss: 8.9484\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.7049\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6474\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6542\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6449\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6427\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6424\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6424\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6442\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6472\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6395\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6396\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6399\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 2s 8ms/step - loss: 8.6383\n",
      "149/149 [==============================] - 55s 370ms/step\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop, score=-10.890237404996117, total= 3.7min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "448/448 [==============================] - 123s 276ms/step - loss: 11.7128\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.4475\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.3964\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.4021\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.3975\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.3901\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.3920\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.3885\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.3886\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 4s 8ms/step - loss: 9.3878\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.3932\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.3889\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.3880\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.3899\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 9.3877\n",
      "149/149 [==============================] - 55s 368ms/step\n",
      "448/448 [==============================] - 1s 3ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop, score=-7.889096112859329, total= 3.9min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "597/597 [==============================] - 129s 216ms/step - loss: 10.8982\n",
      "Epoch 2/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0456\n",
      "Epoch 3/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0208\n",
      "Epoch 4/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0228\n",
      "Epoch 5/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0184\n",
      "Epoch 6/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0164\n",
      "Epoch 7/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0161\n",
      "Epoch 8/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0150\n",
      "Epoch 9/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0242\n",
      "Epoch 10/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0227\n",
      "Epoch 11/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0140\n",
      "Epoch 12/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0168\n",
      "Epoch 13/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0134\n",
      "Epoch 14/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0134\n",
      "Epoch 15/15\n",
      "597/597 [==============================] - 5s 8ms/step - loss: 9.0132\n",
      "149/149 [==============================] - 56s 375ms/step\n",
      "597/597 [==============================] - 2s 3ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop, score=-4.455065567221418, total= 4.3min\n",
      "[CV] activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop \n",
      "Start model:  0.6 [40, 32, 16]\n",
      "End compilation of model:  0.6 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "746/746 [==============================] - 137s 183ms/step - loss: 9.6988\n",
      "Epoch 2/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1366\n",
      "Epoch 3/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1194\n",
      "Epoch 4/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1086\n",
      "Epoch 5/15\n",
      "746/746 [==============================] - 6s 9ms/step - loss: 8.1103\n",
      "Epoch 6/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1117\n",
      "Epoch 7/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1079\n",
      "Epoch 8/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1031\n",
      "Epoch 9/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1034\n",
      "Epoch 10/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1134\n",
      "Epoch 11/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1032\n",
      "Epoch 12/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1029\n",
      "Epoch 13/15\n",
      "746/746 [==============================] - ETA: 0s - loss: 8.077 - 6s 8ms/step - loss: 8.1031\n",
      "Epoch 14/15\n",
      "746/746 [==============================] - 7s 9ms/step - loss: 8.1029\n",
      "Epoch 15/15\n",
      "746/746 [==============================] - 6s 8ms/step - loss: 8.1063\n",
      "149/149 [==============================] - 61s 410ms/step\n",
      "746/746 [==============================] - 2s 2ms/step\n",
      "[CV]  activ_func=tanh, dropout=0.6, neurons=[40, 32, 16], optimizer=rmsprop, score=-3.1153044900638145, total= 4.8min\n",
      "Start model:  0.4 [40, 32, 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed: 271.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End compilation of model:  0.4 [40, 32, 16]\n",
      "Epoch 1/15\n",
      "895/895 [==============================] - 142s 159ms/step - loss: 3.8595\n",
      "Epoch 2/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 1.3534\n",
      "Epoch 3/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 1.1807\n",
      "Epoch 4/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 1.0302\n",
      "Epoch 5/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 1.0502\n",
      "Epoch 6/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 1.0147\n",
      "Epoch 7/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 0.9675\n",
      "Epoch 8/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 0.9151\n",
      "Epoch 9/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 0.9486\n",
      "Epoch 10/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 0.9357\n",
      "Epoch 11/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 0.8346\n",
      "Epoch 12/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 0.8793\n",
      "Epoch 13/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 0.8966\n",
      "Epoch 14/15\n",
      "895/895 [==============================] - 8s 8ms/step - loss: 0.8436\n",
      "Epoch 15/15\n",
      "895/895 [==============================] - 7s 8ms/step - loss: 0.8183\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "early_stopping_monitor = keras.callbacks.EarlyStopping(patience=2)\n",
    "# model.fit(predictors, target, validation_split=0.3, epochs=100, callbacks=[early_stopping_monitor])\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=4, epochs=15) #, callbacks=[early_stopping_monitor]) \n",
    "\n",
    "##############################################################\n",
    "# grid search: dropout, neurons, optimizer, activation\n",
    "dropout = [0.4, 0.5, 0.6] # [0.25, 0.5, 0.75]\n",
    "neurons = [[10, 8, 4], [20, 16, 8], [40, 32, 16]] # [80, 64, 32], [160, 128, 64]\n",
    "activations = ['linear', 'tanh'] # , 'linear'] # , 'sigmoid']\n",
    "optimizer = ['adam', 'rmsprop'] #, 'adam']\n",
    "param_space = dict(dropout=dropout, neurons=neurons, activ_func=activations, optimizer=optimizer)\n",
    "##############################################################\n",
    "\n",
    "tseries_cv = TimeSeriesSplit(n_splits=5).split(LSTM_training_inputs)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_space, n_jobs=1, cv=tseries_cv, verbose=5)\n",
    "\n",
    "print (\"Train input shape: \", LSTM_training_inputs.shape)\n",
    "print (\"Train output shape: \", LSTM_training_outputs.shape)\n",
    "\n",
    "grid_result = grid.fit(LSTM_training_inputs, LSTM_training_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax1 = plt.subplots(1,1)\n",
    "\n",
    "# ax1.plot(bt_history.epoch, bt_history.history['loss'])\n",
    "# ax1.set_title('Training Error')\n",
    "\n",
    "# if bt_model.loss == 'mae':\n",
    "#     ax1.set_ylabel('Mean Absolute Error (MAE)',fontsize=12)\n",
    "# elif bt_model.loss == 'mse':\n",
    "#     ax1.set_ylabel('Mean Squared Error (MSE)',fontsize=12)\n",
    "# else:\n",
    "#     ax1.set_ylabel('Model Loss',fontsize=12)\n",
    "# ax1.set_xlabel('# Epochs',fontsize=12)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveeno\\AppData\\Local\\Continuum\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\praveeno\\AppData\\Local\\Continuum\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\praveeno\\AppData\\Local\\Continuum\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\praveeno\\AppData\\Local\\Continuum\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\praveeno\\AppData\\Local\\Continuum\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\praveeno\\AppData\\Local\\Continuum\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\praveeno\\AppData\\Local\\Continuum\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>active_func</th>\n",
       "      <th>dropout</th>\n",
       "      <th>neurons</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[10, 8, 4]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-0.704431</td>\n",
       "      <td>-0.779229</td>\n",
       "      <td>0.076439</td>\n",
       "      <td>0.423623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[10, 8, 4]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-0.737379</td>\n",
       "      <td>-0.858704</td>\n",
       "      <td>0.083348</td>\n",
       "      <td>0.479227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[20, 16, 8]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-0.549860</td>\n",
       "      <td>-0.635494</td>\n",
       "      <td>0.037642</td>\n",
       "      <td>0.257439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[20, 16, 8]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-0.552116</td>\n",
       "      <td>-0.694770</td>\n",
       "      <td>0.047631</td>\n",
       "      <td>0.292223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[40, 32, 16]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-0.459336</td>\n",
       "      <td>-0.529988</td>\n",
       "      <td>0.027593</td>\n",
       "      <td>0.114971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[40, 32, 16]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-0.462160</td>\n",
       "      <td>-0.549994</td>\n",
       "      <td>0.020269</td>\n",
       "      <td>0.160685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[10, 8, 4]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-0.874317</td>\n",
       "      <td>-1.007678</td>\n",
       "      <td>0.127096</td>\n",
       "      <td>0.581596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[10, 8, 4]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-0.778627</td>\n",
       "      <td>-0.890965</td>\n",
       "      <td>0.093748</td>\n",
       "      <td>0.423016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[20, 16, 8]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-0.575517</td>\n",
       "      <td>-0.663377</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>0.316635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[20, 16, 8]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-0.604644</td>\n",
       "      <td>-0.663109</td>\n",
       "      <td>0.025029</td>\n",
       "      <td>0.324208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[40, 32, 16]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-0.517324</td>\n",
       "      <td>-0.608191</td>\n",
       "      <td>0.054089</td>\n",
       "      <td>0.253010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[40, 32, 16]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-0.528671</td>\n",
       "      <td>-0.673385</td>\n",
       "      <td>0.054383</td>\n",
       "      <td>0.200703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[10, 8, 4]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-1.020172</td>\n",
       "      <td>-1.040677</td>\n",
       "      <td>0.118356</td>\n",
       "      <td>0.615304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[10, 8, 4]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-0.948888</td>\n",
       "      <td>-1.060369</td>\n",
       "      <td>0.091957</td>\n",
       "      <td>0.607396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[20, 16, 8]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-0.656597</td>\n",
       "      <td>-0.759680</td>\n",
       "      <td>0.051475</td>\n",
       "      <td>0.402366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[20, 16, 8]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-0.688806</td>\n",
       "      <td>-0.810785</td>\n",
       "      <td>0.071526</td>\n",
       "      <td>0.405001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[40, 32, 16]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-0.556198</td>\n",
       "      <td>-0.649571</td>\n",
       "      <td>0.046297</td>\n",
       "      <td>0.291221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[40, 32, 16]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-0.534304</td>\n",
       "      <td>-0.644082</td>\n",
       "      <td>0.024815</td>\n",
       "      <td>0.234076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[10, 8, 4]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-8.461284</td>\n",
       "      <td>-7.295993</td>\n",
       "      <td>0.776019</td>\n",
       "      <td>3.060791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[10, 8, 4]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-8.462474</td>\n",
       "      <td>-7.297654</td>\n",
       "      <td>0.772492</td>\n",
       "      <td>3.062666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[20, 16, 8]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-8.460711</td>\n",
       "      <td>-7.295475</td>\n",
       "      <td>0.775786</td>\n",
       "      <td>3.060632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[20, 16, 8]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-8.460253</td>\n",
       "      <td>-7.294989</td>\n",
       "      <td>0.776080</td>\n",
       "      <td>3.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[40, 32, 16]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-8.460214</td>\n",
       "      <td>-7.294928</td>\n",
       "      <td>0.776192</td>\n",
       "      <td>3.060130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[40, 32, 16]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-8.460156</td>\n",
       "      <td>-7.294873</td>\n",
       "      <td>0.776227</td>\n",
       "      <td>3.060089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[10, 8, 4]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-8.462334</td>\n",
       "      <td>-7.297035</td>\n",
       "      <td>0.776082</td>\n",
       "      <td>3.061447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[10, 8, 4]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-8.462397</td>\n",
       "      <td>-7.297562</td>\n",
       "      <td>0.772578</td>\n",
       "      <td>3.062587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[20, 16, 8]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-8.460367</td>\n",
       "      <td>-7.295093</td>\n",
       "      <td>0.776097</td>\n",
       "      <td>3.060248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[20, 16, 8]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-8.460269</td>\n",
       "      <td>-7.295009</td>\n",
       "      <td>0.776041</td>\n",
       "      <td>3.060216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[40, 32, 16]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-8.460189</td>\n",
       "      <td>-7.294908</td>\n",
       "      <td>0.776189</td>\n",
       "      <td>3.060117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[40, 32, 16]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-8.460160</td>\n",
       "      <td>-7.294878</td>\n",
       "      <td>0.776220</td>\n",
       "      <td>3.060094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[10, 8, 4]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-8.463106</td>\n",
       "      <td>-7.297741</td>\n",
       "      <td>0.774970</td>\n",
       "      <td>3.061602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[10, 8, 4]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-8.462693</td>\n",
       "      <td>-7.297906</td>\n",
       "      <td>0.772068</td>\n",
       "      <td>3.062906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[20, 16, 8]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-8.460520</td>\n",
       "      <td>-7.295263</td>\n",
       "      <td>0.775955</td>\n",
       "      <td>3.060372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[20, 16, 8]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-8.460192</td>\n",
       "      <td>-7.294915</td>\n",
       "      <td>0.776172</td>\n",
       "      <td>3.060128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[40, 32, 16]</td>\n",
       "      <td>adam</td>\n",
       "      <td>-8.460166</td>\n",
       "      <td>-7.294883</td>\n",
       "      <td>0.776218</td>\n",
       "      <td>3.060098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[40, 32, 16]</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>-8.460158</td>\n",
       "      <td>-7.294875</td>\n",
       "      <td>0.776223</td>\n",
       "      <td>3.060092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   active_func  dropout       neurons optimizer  mean_train_score  \\\n",
       "0       linear      0.4    [10, 8, 4]      adam         -0.704431   \n",
       "1       linear      0.4    [10, 8, 4]   rmsprop         -0.737379   \n",
       "2       linear      0.4   [20, 16, 8]      adam         -0.549860   \n",
       "3       linear      0.4   [20, 16, 8]   rmsprop         -0.552116   \n",
       "4       linear      0.4  [40, 32, 16]      adam         -0.459336   \n",
       "5       linear      0.4  [40, 32, 16]   rmsprop         -0.462160   \n",
       "6       linear      0.5    [10, 8, 4]      adam         -0.874317   \n",
       "7       linear      0.5    [10, 8, 4]   rmsprop         -0.778627   \n",
       "8       linear      0.5   [20, 16, 8]      adam         -0.575517   \n",
       "9       linear      0.5   [20, 16, 8]   rmsprop         -0.604644   \n",
       "10      linear      0.5  [40, 32, 16]      adam         -0.517324   \n",
       "11      linear      0.5  [40, 32, 16]   rmsprop         -0.528671   \n",
       "12      linear      0.6    [10, 8, 4]      adam         -1.020172   \n",
       "13      linear      0.6    [10, 8, 4]   rmsprop         -0.948888   \n",
       "14      linear      0.6   [20, 16, 8]      adam         -0.656597   \n",
       "15      linear      0.6   [20, 16, 8]   rmsprop         -0.688806   \n",
       "16      linear      0.6  [40, 32, 16]      adam         -0.556198   \n",
       "17      linear      0.6  [40, 32, 16]   rmsprop         -0.534304   \n",
       "18        tanh      0.4    [10, 8, 4]      adam         -8.461284   \n",
       "19        tanh      0.4    [10, 8, 4]   rmsprop         -8.462474   \n",
       "20        tanh      0.4   [20, 16, 8]      adam         -8.460711   \n",
       "21        tanh      0.4   [20, 16, 8]   rmsprop         -8.460253   \n",
       "22        tanh      0.4  [40, 32, 16]      adam         -8.460214   \n",
       "23        tanh      0.4  [40, 32, 16]   rmsprop         -8.460156   \n",
       "24        tanh      0.5    [10, 8, 4]      adam         -8.462334   \n",
       "25        tanh      0.5    [10, 8, 4]   rmsprop         -8.462397   \n",
       "26        tanh      0.5   [20, 16, 8]      adam         -8.460367   \n",
       "27        tanh      0.5   [20, 16, 8]   rmsprop         -8.460269   \n",
       "28        tanh      0.5  [40, 32, 16]      adam         -8.460189   \n",
       "29        tanh      0.5  [40, 32, 16]   rmsprop         -8.460160   \n",
       "30        tanh      0.6    [10, 8, 4]      adam         -8.463106   \n",
       "31        tanh      0.6    [10, 8, 4]   rmsprop         -8.462693   \n",
       "32        tanh      0.6   [20, 16, 8]      adam         -8.460520   \n",
       "33        tanh      0.6   [20, 16, 8]   rmsprop         -8.460192   \n",
       "34        tanh      0.6  [40, 32, 16]      adam         -8.460166   \n",
       "35        tanh      0.6  [40, 32, 16]   rmsprop         -8.460158   \n",
       "\n",
       "    mean_test_score  std_train_score  std_test_score  \n",
       "0         -0.779229         0.076439        0.423623  \n",
       "1         -0.858704         0.083348        0.479227  \n",
       "2         -0.635494         0.037642        0.257439  \n",
       "3         -0.694770         0.047631        0.292223  \n",
       "4         -0.529988         0.027593        0.114971  \n",
       "5         -0.549994         0.020269        0.160685  \n",
       "6         -1.007678         0.127096        0.581596  \n",
       "7         -0.890965         0.093748        0.423016  \n",
       "8         -0.663377         0.029438        0.316635  \n",
       "9         -0.663109         0.025029        0.324208  \n",
       "10        -0.608191         0.054089        0.253010  \n",
       "11        -0.673385         0.054383        0.200703  \n",
       "12        -1.040677         0.118356        0.615304  \n",
       "13        -1.060369         0.091957        0.607396  \n",
       "14        -0.759680         0.051475        0.402366  \n",
       "15        -0.810785         0.071526        0.405001  \n",
       "16        -0.649571         0.046297        0.291221  \n",
       "17        -0.644082         0.024815        0.234076  \n",
       "18        -7.295993         0.776019        3.060791  \n",
       "19        -7.297654         0.772492        3.062666  \n",
       "20        -7.295475         0.775786        3.060632  \n",
       "21        -7.294989         0.776080        3.060200  \n",
       "22        -7.294928         0.776192        3.060130  \n",
       "23        -7.294873         0.776227        3.060089  \n",
       "24        -7.297035         0.776082        3.061447  \n",
       "25        -7.297562         0.772578        3.062587  \n",
       "26        -7.295093         0.776097        3.060248  \n",
       "27        -7.295009         0.776041        3.060216  \n",
       "28        -7.294908         0.776189        3.060117  \n",
       "29        -7.294878         0.776220        3.060094  \n",
       "30        -7.297741         0.774970        3.061602  \n",
       "31        -7.297906         0.772068        3.062906  \n",
       "32        -7.295263         0.775955        3.060372  \n",
       "33        -7.294915         0.776172        3.060128  \n",
       "34        -7.294883         0.776218        3.060098  \n",
       "35        -7.294875         0.776223        3.060092  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(grid_result.cv_results_)\n",
    "df = pd.DataFrame(grid_result.cv_results_)\n",
    "# df['params'] = df['params'].values # Use apply() or lambda()\n",
    "# pd.set_option('max_colwidth',200)\n",
    "\n",
    "df['active_func'] = [ x['activ_func'] for x in df['params'].values]\n",
    "df['dropout'] = [ x['dropout'] for x in df['params'].values]\n",
    "df['neurons'] = [ x['neurons'] for x in df['params'].values]\n",
    "df['optimizer'] = [ x['optimizer'] for x in df['params'].values]\n",
    "df.drop(columns='params', inplace=True)\n",
    "\n",
    "df[['active_func', 'dropout', 'neurons', 'optimizer', 'mean_train_score', 'mean_test_score', 'std_train_score', 'std_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['linear', 0.4, [40, 32, 16], 'adam'])\n",
      "-0.5299881415379127\n"
     ]
    }
   ],
   "source": [
    "bt_model = grid_result.best_estimator_\n",
    "print(grid_result.best_params_.values())\n",
    "print(grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis\n",
    "\n",
    "Add random noise (with normal distribution) to training and test inputs, and study the mean & variance of the final model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 10\n",
    "lstm_test_mse = []\n",
    "lstm_train_mse = []\n",
    "\n",
    "for i in range(num_iter):\n",
    "    training_set_rand = training_set + 2*(-0.5+np.random.rand(*training_set.shape))*training_set.std().values/1000 # + 2*(-0.5+np.random.rand(*training_set.shape))*training_set.std().values/10\n",
    "    test_set_rand = test_set + 2*(-0.5+np.random.rand(*test_set.shape))*test_set.std().values/1000\n",
    "\n",
    "    LSTM_training_inputs_rand = []\n",
    "    for i in range(len(training_set_rand)-window_len):\n",
    "        temp_set = training_set_rand[i:(i+window_len)].copy()\n",
    "        for col in norm_cols:\n",
    "            temp_set.loc[:, col] = temp_set[col]/temp_set[col].iloc[0] - 1\n",
    "        LSTM_training_inputs_rand.append(temp_set)\n",
    "        \n",
    "    LSTM_test_inputs_rand = []\n",
    "    for i in range(len(test_set_rand)-window_len):\n",
    "        temp_set = test_set_rand[i:(i+window_len)].copy()\n",
    "        for col in norm_cols:\n",
    "            temp_set.loc[:, col] = temp_set[col]/temp_set[col].iloc[0] - 1\n",
    "        LSTM_test_inputs_rand.append(temp_set)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    LSTM_training_inputs_rand = [np.array(LSTM_training_input) for LSTM_training_input in LSTM_training_inputs_rand]\n",
    "    LSTM_training_inputs_rand = np.array(LSTM_training_inputs_rand)\n",
    "\n",
    "    LSTM_test_inputs_rand = [np.array(LSTM_test_inputs) for LSTM_test_inputs in LSTM_test_inputs_rand]\n",
    "    LSTM_test_inputs_rand = np.array(LSTM_test_inputs_rand)\n",
    "\n",
    "    lstm_test_mse.append(np.mean(np.square(bt_model.predict(LSTM_test_inputs_rand)-(test_set[target].values[window_len:]))))\n",
    "    lstm_train_mse.append(np.mean(np.square(bt_model.predict(LSTM_training_inputs_rand)-(training_set[target].values[window_len:]))))\n",
    "\n",
    "print (lstm_test_mse)\n",
    "print (lstm_train_mse)\n",
    "\n",
    "print (np.mean(lstm_test_mse), np.std(lstm_test_mse))\n",
    "print (np.mean(lstm_train_mse), np.std(lstm_train_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.mean(lstm_test_mse), np.std(lstm_test_mse))\n",
    "print (np.mean(lstm_train_mse), np.std(lstm_train_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mse=np.mean(np.square(bt_model.predict(LSTM_training_inputs)-(training_set[target].values[window_len:])))\n",
    "print(lstm_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = [a for a in range(10)]\n",
    "sns.barplot(x=x_, y=lstm_test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=x_, y=lstm_train_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1)\n",
    "LSTM_test_outputs = training_set[target][window_len:].values\n",
    "ax1.set_xticks([datetime.date(2018,i+1,1) for i in range(12)])\n",
    "ax1.set_xticklabels([datetime.date(2018,i+1,1).strftime('%b %d %Y')  for i in range(12)])\n",
    "ax1.plot(model_data[model_data['Date']>= split_date]['Date'].astype(datetime.datetime),\n",
    "         test_set[target][window_len:], label='Actual')\n",
    "ax1.plot(model_data[model_data['Date']>= split_date]['Date'].astype(datetime.datetime),\n",
    "         (bt_model.predict(LSTM_test_inputs)), \n",
    "         label='Predicted')\n",
    "lstm_mse=np.mean(np.square(bt_model.predict(LSTM_test_inputs)-(test_set[target].values[window_len:])))\n",
    "ax1.annotate('MSE: %.4f'%lstm_mse, xy=(0.75, 0.9),  xycoords='axes fraction', xytext=(0.75, 0.9), textcoords='axes fraction')\n",
    "ax1.set_title('Test Set: Single Timepoint Prediction',fontsize=13)\n",
    "ax1.set_ylabel('Bitcoin Volatilty',fontsize=12)\n",
    "ax1.legend(bbox_to_anchor=(0.1, 1), loc=2, borderaxespad=0., prop={'size': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.set_xticks([datetime.date(2018,i+1,1) for i in range(12)])\n",
    "ax1.set_xticklabels([datetime.date(2018,i+1,1).strftime('%b %d %Y')  for i in range(12)])\n",
    "ax1.plot(model_data[model_data['Date']< split_date]['Date'][window_len:].astype(datetime.datetime),\n",
    "         training_set[target][window_len:], label='Actual')\n",
    "ax1.plot(model_data[model_data['Date']< split_date]['Date'][window_len:].astype(datetime.datetime),\n",
    "         (bt_model.predict(LSTM_training_inputs)), \n",
    "         label='Predicted')\n",
    "ax1.annotate('MSE: %.4f'%np.mean(np.square(bt_model.predict(LSTM_training_inputs)-\\\n",
    "            (training_set[target].values[window_len:]))), \n",
    "             xy=(0.75, 0.9),  xycoords='axes fraction',\n",
    "            xytext=(0.75, 0.9), textcoords='axes fraction')\n",
    "ax1.set_title('Training Set: Single Timepoint Prediction',fontsize=13)\n",
    "ax1.set_ylabel('Bitcoin Volatility',fontsize=12)\n",
    "ax1.legend(bbox_to_anchor=(0.1, 1), loc=2, borderaxespad=0., prop={'size': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values = bt_model.predict(LSTM_training_inputs)\n",
    "max(pred_values)\n",
    "min(pred_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (bm1_mse)\n",
    "print (bm2_mse)\n",
    "print (lstm_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = create_model(0.5, [10, 8, 4], 'linear', 'adam')\n",
    "\n",
    "temp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log (Bitcoin Volatility) :\n",
    "\n",
    "{'activ_func': 'linear', 'dropout': 0.4, 'neurons': [20, 16, 8]}\n",
    "7.188424481804465\n",
    "0.2821991334719368\n",
    "0.2323832191539962\n",
    "\n",
    "Log (Ethereum Volatility):\n",
    "\n",
    "7.075934943743348\n",
    "0.26612587735504156\n",
    "0.250099288542878\n",
    "\n",
    "Bitcoin Daily returns:\n",
    "\n",
    "0.0030647863135465233\n",
    "0.006363817757120959\n",
    "0.003059795171523061\n",
    "{'activ_func': 'linear', 'dropout': 0.4, 'neurons': [10, 8, 4]}\n",
    "\n",
    "Ethereum Daily returns:\n",
    "\n",
    "{'activ_func': 'linear', 'dropout': 0.5, 'neurons': [10, 8, 4]}\n",
    "0.003542452975106516\n",
    "0.007433466612293294\n",
    "0.003664957524689988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(1.0, index=[1,2,3,4,5], columns=list('ABC') )\n",
    "df['B']=20*df['B']\n",
    "df['C']=500*df['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.random.rand(*df.shape)\n",
    "print(temp)\n",
    "print(temp*(df.mean().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
